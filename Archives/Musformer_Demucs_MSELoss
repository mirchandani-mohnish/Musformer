{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10005918,"sourceType":"datasetVersion","datasetId":6159348}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-05T18:42:00.167450Z","iopub.execute_input":"2025-04-05T18:42:00.167769Z","iopub.status.idle":"2025-04-05T18:42:01.340407Z","shell.execute_reply.started":"2025-04-05T18:42:00.167748Z","shell.execute_reply":"2025-04-05T18:42:01.334200Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/musdb18-music-source-separation-dataset/The Long Wait - Dark Horses.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Raft Monk - Tiring.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/BKS - Too Much.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Georgia Wonder - Siren.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/The Sunshine Garcia Band - For I Am The Moon.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Enda Reilly - Cur An Long Ag Seol.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Buitraker - Revo X.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/We Fell From The Sky - Not You.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/The Mountaineering Club - Mallory.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Skelpolu - Resurrection.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Secretariat - Over The Top.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Bobby Nobody - Stitch Up.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Arise - Run Run Run.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Carlos Gonzalez - A Place For Us.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Forkupines - Semantics.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/The Easton Ellises - Falcon 69.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Lyndsey Ollard - Catching Up.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Triviul feat. The Fiend - Widow.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Louis Cressy Band - Good Time.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Motor Tapes - Shore.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/AM Contra - Heart Peripheral.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Signe Jakobsen - What Have You Done To Me.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Moosmusic - Big Dummy Shake.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/M.E.R.C. Music - Knockout.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/The Doppler Shift - Atrophy.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Detsky Sad - Walkie Talkie.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/PR - Happy Daze.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Timboz - Pony.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/PR - Oh No.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Mu - Too Bright.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Hollow Ground - Ill Fate.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/The Easton Ellises (Baumi) - SDRNR.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Speak Softly - Like Horses.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Sambasevam Shanmugam - Kaathaadi.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Tom McKenzie - Directions.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Secretariat - Borderline.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Side Effects Project - Sing With Me.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Nerve 9 - Pray For The Rain.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Zeno - Signs.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Girls Under Glass - We Feel Alright.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Cristina Vane - So Easy.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Speak Softly - Broken Man.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/BKS - Bulldozer.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Punkdisco - Oral Hygiene.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Al James - Schoolboy Facination.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Dark Ride - Burning Bridges.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Drumtracks - Ghost Bitch.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Aimee Norwich - Child.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/James May - If You Say.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Rockabilly.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Steven Clark - Bounty.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Giselle - Moss.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Strand Of Oaks - Spacestation.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Patrick Talbot - Set Me Free.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Bill Chudziak - Children Of No-one.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Angela Thomas Wade - Milk Cow Blues.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Grants - PunchDrunk.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Grunge.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Traffic Experiment - Once More (With Feeling).stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Beatles.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Auctioneer - Our Future Faces.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Clara Berry And Wooldog - Air Traffic.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Patrick Talbot - A Reason To Leave.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/The Districts - Vermont.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Leaf - Come Around.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/North To Alaska - All The Same.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Skelpolu - Human Mistakes.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Dreamers Of The Ghetto - Heavy Love.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/ANiMAL - Rockshow.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Faces On Film - Waiting For Ga.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Snowmine - Curfews.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Swinging Steaks - Lost My Way.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Triviul - Dorothy.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Gospel.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Clara Berry And Wooldog - Stella.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Disco.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Reggae.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/The So So Glos - Emergency.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Leaf - Wicked.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/St Vitus - Word Gets Around.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Celestial Shore - Die For Us.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Young Griffo - Facade.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/AvaLuna - Waterduct.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Punk.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Actions - One Minute Smile.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Young Griffo - Blood To Bone.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Tim Taler - Stalker.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Hendrix.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Leaf - Summerghost.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Hop Along - Sister Cities.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/James May - All Souls Moon.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Meaxic - You Listen.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Country2.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/ANiMAL - Clinic A.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Traffic Experiment - Sirens.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Britpop.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Rock.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Chris Durban - Celebrate.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Triviul - Angelsaint.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/James May - On The Line.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/A Classic Education - NightOwl.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Skelpolu - Together Alone.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Titanium - Haunted Age.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Alexander Ross - Goodbye Bolero.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Secret Mountains - High Horse.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Wall Of Death - Femme.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Fergessen - The Wind.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Alexander Ross - Velvet Curtain.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Johnny Lokke - Whisper To A Scream.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Meaxic - Take A Step.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Jay Menon - Through My Eyes.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Flags - 54.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Clara Berry And Wooldog - Waltz For My Victims.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/ANiMAL - Easy Tiger.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Fergessen - Back From The Start.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Hollow Ground - Left Blind.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Sweet Lights - You Let Me Down.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Port St Willow - Stay Even.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Helado Negro - Mitad Del Mundo.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Black Bloc - If You Want Success.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Young Griffo - Pennies.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Voelund - Comfort Lives In Belief.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Fergessen - Nos Palpitants.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Creepoid - OldTree.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Actions - South Of The Water.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Lushlife - Toynbee Suite.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Matthew Entwistle - Dont You Ever.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/The Scarlet Brand - Les Fleurs Du Mal.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Country1.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/James May - Dont Let Go.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - 80s Rock.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Atlantis Bound - It Was My Fault For Waiting.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Invisible Familiars - Disturbing Wildlife.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Cnoc An Tursa - Bannockburn.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Hezekiah Jones - Borrowed Heart.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/BigTroubles - Phantom.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Remember December - C U Next Time.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Night Panther - Fire.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/The Long Wait - Back Home To Blue.stem.mp4\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install musdb\n!pip install mir_eval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T18:42:01.341693Z","iopub.execute_input":"2025-04-05T18:42:01.342100Z","iopub.status.idle":"2025-04-05T18:42:10.617662Z","shell.execute_reply.started":"2025-04-05T18:42:01.342075Z","shell.execute_reply":"2025-04-05T18:42:10.616848Z"}},"outputs":[{"name":"stdout","text":"Collecting musdb\n  Downloading musdb-0.4.2-py2.py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.10/dist-packages (from musdb) (1.26.4)\nCollecting stempeg>=0.2.3 (from musdb)\n  Downloading stempeg-0.2.3-py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: pyaml in /usr/local/lib/python3.10/dist-packages (from musdb) (25.1.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from musdb) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.7->musdb) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.7->musdb) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.7->musdb) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.7->musdb) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.7->musdb) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.7->musdb) (2.4.1)\nCollecting ffmpeg-python>=0.2.0 (from stempeg>=0.2.3->musdb)\n  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml->musdb) (6.0.2)\nRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python>=0.2.0->stempeg>=0.2.3->musdb) (1.0.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.7->musdb) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.7->musdb) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.7->musdb) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.7->musdb) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.7->musdb) (2024.2.0)\nDownloading musdb-0.4.2-py2.py3-none-any.whl (13 kB)\nDownloading stempeg-0.2.3-py3-none-any.whl (963 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\nInstalling collected packages: ffmpeg-python, stempeg, musdb\nSuccessfully installed ffmpeg-python-0.2.0 musdb-0.4.2 stempeg-0.2.3\nCollecting mir_eval\n  Downloading mir_eval-0.8.2-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from mir_eval) (1.26.4)\nRequirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mir_eval) (1.13.1)\nRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mir_eval) (4.4.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.15.4->mir_eval) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.15.4->mir_eval) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.15.4->mir_eval) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.15.4->mir_eval) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.15.4->mir_eval) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.15.4->mir_eval) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.15.4->mir_eval) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.15.4->mir_eval) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.15.4->mir_eval) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.15.4->mir_eval) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.15.4->mir_eval) (2024.2.0)\nDownloading mir_eval-0.8.2-py3-none-any.whl (102 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.8/102.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: mir_eval\nSuccessfully installed mir_eval-0.8.2\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"\n%%capture\n# Installing SpeechBrain via pip\nBRANCH = 'develop'\n!python -m pip install git+https://github.com/speechbrain/speechbrain.git@$BRANCH\n\n# Clone SpeechBrain repository\n!git clone https://github.com/speechbrain/speechbrain/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T18:42:10.619386Z","iopub.execute_input":"2025-04-05T18:42:10.619738Z","iopub.status.idle":"2025-04-05T18:42:30.719947Z","shell.execute_reply.started":"2025-04-05T18:42:10.619694Z","shell.execute_reply":"2025-04-05T18:42:30.719008Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"db_path = '/kaggle/input/musdb18-music-source-separation-dataset'\noutput_path = '/kaggle/working'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T18:42:30.720933Z","iopub.execute_input":"2025-04-05T18:42:30.721168Z","iopub.status.idle":"2025-04-05T18:42:30.724978Z","shell.execute_reply.started":"2025-04-05T18:42:30.721147Z","shell.execute_reply":"2025-04-05T18:42:30.724187Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import os\nimport numpy as np\nnp.float_ = np.float64\nimport musdb\n\nMUS_DB_PATH = db_path\n\nmus = musdb.DB(root=MUS_DB_PATH)\nmus_train = musdb.DB(root=MUS_DB_PATH,subsets=\"train\", split=\"train\")\nmus_valid = musdb.DB(root=MUS_DB_PATH,subsets=\"train\", split=\"valid\")\nmus_test = musdb.DB(root=MUS_DB_PATH,subsets=\"test\")\nprint(mus_train[0])\nprint(mus_test[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T18:42:30.725836Z","iopub.execute_input":"2025-04-05T18:42:30.726139Z","iopub.status.idle":"2025-04-05T18:43:08.161924Z","shell.execute_reply.started":"2025-04-05T18:42:30.726119Z","shell.execute_reply":"2025-04-05T18:43:08.160822Z"}},"outputs":[{"name":"stdout","text":"A Classic Education - NightOwl\nAM Contra - Heart Peripheral\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%file models.py\n\nimport torch\nfrom torch import nn\nfrom speechbrain.nnet.CNN import Conv1d, ConvTranspose1d\n# from speechbrain.nnet.activations import GLU\nfrom speechbrain.lobes.models.beats import GLU_Linear\nfrom torch.nn import GLU\nfrom speechbrain.nnet.RNN import LSTM\nfrom speechbrain.nnet.linear import Linear\n\nclass EncoderBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv = Conv1d(\n            out_channels=out_channels,\n            in_channels=in_channels,\n            kernel_size=8,\n            stride=4,\n            # default_padding=2,\n            skip_transpose=True,  \n        )\n        self.glu_conv = Conv1d(\n            out_channels=2*out_channels,  \n            in_channels=out_channels,\n            kernel_size=1,\n            stride=1,\n            skip_transpose=True,\n        )\n        self.relu = torch.nn.ReLU()\n        self.glu = GLU(dim=1)\n\n    def forward(self, x):\n        # print(x.size())\n        x = self.relu(self.conv(x))\n        # print(x.size())\n        x = self.glu(self.glu_conv(x))\n        # print(x.size())\n        return x\n\nclass DecoderBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.glu_conv = Conv1d(\n            out_channels=2*in_channels,\n            in_channels=in_channels,\n            kernel_size=1,\n            stride=1,\n            skip_transpose=True,\n        )\n        self.conv_tr = ConvTranspose1d(\n            out_channels=out_channels,\n            in_channels=in_channels,  # After GLU split\n            kernel_size=8,\n            stride=4,\n            # padding=2,\n            # output_padding=2,\n            skip_transpose=True,\n        )\n        self.glu = GLU(dim=1)\n        self.relu = torch.nn.ReLU()\n\n    def forward(self, x, skip=None):\n        \n        # print(x.size())\n        x = self.glu(self.glu_conv(x))\n        # print(x.size())\n        x = self.relu(self.conv_tr(x))\n        # print(x.size())\n        return x\n\n\n\n\nclass SourceSeparator(nn.Module):\n    def __init__(self, in_channels, out_channels=2, num_sources=4):\n        \"\"\"\n        Args:\n            C_in: Input channels from last decoder (typically 8)\n            C_out: Output channels per source (2 for stereo)\n            num_sources: Number of sources to separate (e.g. 4 for vocals, drums, bass, other)\n        \"\"\"\n        super().__init__()\n        # Final linear layer (no activation)\n        self.output_proj = Linear(\n            input_size=in_channels,\n            n_neurons=num_sources * out_channels,  # 4 sources * 2 channels = 8\n            bias=True\n        )\n        self.num_sources = num_sources\n        self.out_channels = out_channels\n\n    def forward(self, x):\n        \"\"\"\n        Input: [batch, C_in, time]\n        Output: [batch, num_sources, out_channels, time]\n        \"\"\"\n        # Permute to [batch, time, features]\n        # print(x.size())\n        x = x.permute(0, 2, 1)\n        \n        # Project to source waveforms\n        x = self.output_proj(x)  # [batch, time, num_sources*out_channels]\n        # print(x.size())\n        \n        # Reshape to separated sources\n        x = x.view(x.size(0), -1, self.num_sources, self.out_channels)\n        x = x.permute(0, 2, 1, 3)\n        # print(x.size())\n        # Return as [batch, sources, channels, time]\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T21:05:12.021952Z","iopub.execute_input":"2025-04-05T21:05:12.022278Z","iopub.status.idle":"2025-04-05T21:05:12.029049Z","shell.execute_reply.started":"2025-04-05T21:05:12.022252Z","shell.execute_reply":"2025-04-05T21:05:12.028213Z"}},"outputs":[{"name":"stdout","text":"Overwriting models.py\n","output_type":"stream"}],"execution_count":252},{"cell_type":"code","source":"%%file hparams.yaml\n\n# ################################\n# Model: Demucs for source separation\n# https://hal.science/hal-02379796/document\n# Dataset : Musdb\n# ################################\n# Basic parameters\nseed: 1234\n__set_seed: !apply:speechbrain.utils.seed_everything [!ref <seed>]\n\n# Data params (unchanged from DPRNN)\ndata_folder: !PLACEHOLDER\n\nexperiment_name: demucs\noutput_folder: !ref /kaggle/working/results/<experiment_name>/<seed>\ntrain_log: !ref <output_folder>/train_log.txt\nsave_folder: !ref <output_folder>/save\ntrain_data: !ref <output_folder>/train.json\nvalid_data: !ref <output_folder>/valid.json\ntest_data: !ref <output_folder>/test.json\nskip_prep: False\ndb_path: '/kaggle/input/musdb18-music-source-separation-dataset'\n\n\n# Experiment params \nprecision: fp16\nnum_spks: 2\n\ninstrumental_classification: False\nnoprogressbar: False\nsave_audio: True \nsample_rate: 16000\nn_audio_to_save: 10\n\n####################### Training Parameters ####################################\n\nN_epochs: 150\nbatch_size: 1\nlr: 0.00015\nclip_grad_norm: 5\nloss_upper_lim: 999999\nlimit_training_signal_len: False\ntraining_signal_len: 32000000\n\n\n# Data augmentation (unchanged)\nuse_wavedrop: False\nuse_rand_shift: False\nmin_shift: -8000\nmax_shift: 8000\n\n\n# Frequency/time drop (unchanged)\ndrop_freq: !new:speechbrain.augment.time_domain.DropFreq\n    drop_freq_low: 0\n    drop_freq_high: 1\n    drop_freq_count_low: 1\n    drop_freq_count_high: 3\n    drop_freq_width: 0.05\n\ndrop_chunk: !new:speechbrain.augment.time_domain.DropChunk\n    drop_length_low: 1000\n    drop_length_high: 2000\n    drop_count_low: 1\n    drop_count_high: 5\n\nthreshold_byloss: True\nthreshold: -30\n\n################ Demucs Specific Parameters #############################\n## for Demucs V3/4\n# # Fourier Transform Parameters\n# n_fft: 2048\n# hop_length: 512\n\n\nkernel_size: 16\n# kernel_stride: 8\n\n# Dataloader options (unchanged)\ndataloader_opts:\n    batch_size: !ref <batch_size>\n    num_workers: 3\n\n######################## Network Definition ####################################\n\n\nEncoder1: !new:models.EncoderBlock\n    in_channels: 2\n    # kernel_size: !ref <kernel_size>\n    out_channels: 64\n\n\nEncoder2: !new:models.EncoderBlock\n    in_channels: 64\n    # kernel_size: !ref <kernel_size>\n    out_channels: 128\n\n\nEncoder3: !new:models.EncoderBlock\n    in_channels: 128\n    # kernel_size: !ref <kernel_size>\n    out_channels: 256\n\n\nEncoder4: !new:models.EncoderBlock\n    in_channels: 256\n    # kernel_size: !ref <kernel_size>\n    out_channels: 512\n\n\nEncoder5: !new:models.EncoderBlock\n    in_channels: 512\n    # kernel_size: !ref <kernel_size>\n    out_channels: 1024\n\n\nEncoder6: !new:models.EncoderBlock\n    in_channels: 1024\n    # kernel_size: !ref <kernel_size>\n    out_channels: 2048\n\n\n\n\nDecoder6: !new:models.DecoderBlock\n    in_channels: 2048\n    out_channels: 1024\n    # # kernel_size: !ref <kernel_size>\n    # stride: !ref <kernel_stride>\n    \n\nDecoder5: !new:models.DecoderBlock\n    in_channels: 1024\n    out_channels: 512\n    # # kernel_size: !ref <kernel_size>\n    # stride: !ref <kernel_stride>\n    \n\nDecoder4: !new:models.DecoderBlock\n    in_channels: 512\n    out_channels: 256\n    # kernel_size: !ref <kernel_size>\n    # stride: !ref <kernel_stride>\n    \n\nDecoder3: !new:models.DecoderBlock\n    in_channels: 256\n    out_channels: 128\n    # kernel_size: !ref <kernel_size>\n    # stride: !ref <kernel_stride>\n    \n\nDecoder2: !new:models.DecoderBlock\n    in_channels: 128\n    out_channels: 64\n    # kernel_size: !ref <kernel_size>\n    # stride: !ref <kernel_stride>\n    \n\nDecoder1: !new:models.DecoderBlock\n    in_channels: 64\n    out_channels: 8\n    # kernel_size: !ref <kernel_size>\n    # stride: !ref <kernel_stride>\n    \n\nLinear: !new:speechbrain.nnet.linear.Linear\n    input_size: 4096\n    bias: False\n    n_neurons: 2048\n\nBiLSTM: !new:speechbrain.nnet.RNN.LSTM\n    hidden_size: 2048\n    input_size: 2048\n    num_layers: 2\n    bidirectional: True\n    # batch_first: True\n\nLinearSeparator: !new:models.SourceSeparator\n    in_channels: 8\n    out_channels: 2\n    num_sources: !ref <num_spks>\n\n\n######################## Remaining Config ######################################\noptimizer: !name:torch.optim.Adam\n    lr: !ref <lr>\n    weight_decay: 0\n\nloss: !name:speechbrain.nnet.losses.mse_loss\n\nlr_scheduler: !new:speechbrain.nnet.schedulers.ReduceLROnPlateau\n    factor: 0.5\n    patience: 2\n    dont_halve_until_epoch: 85\n\nepoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n    limit: !ref <N_epochs>\n\nmodules:\n    encoder1: !ref <Encoder1>\n    encoder2: !ref <Encoder2>\n    encoder3: !ref <Encoder3>\n    encoder4: !ref <Encoder4>\n    encoder5: !ref <Encoder5>\n    encoder6: !ref <Encoder6>\n    lstm: !ref <BiLSTM>\n    linear: !ref <Linear>\n    decoder6: !ref <Decoder6>\n    decoder5: !ref <Decoder5>\n    decoder4: !ref <Decoder4>\n    decoder3: !ref <Decoder3>\n    decoder2: !ref <Decoder2>\n    decoder1: !ref <Decoder1>\n    linearSeparator: !ref <LinearSeparator>\n\ncheckpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n    checkpoints_dir: !ref <save_folder>\n    recoverables:\n        encoder1: !ref <Encoder1>\n        encoder2: !ref <Encoder2>\n        encoder3: !ref <Encoder3>\n        encoder4: !ref <Encoder4>\n        encoder5: !ref <Encoder5>\n        encoder6: !ref <Encoder6>\n        lstm: !ref <BiLSTM>\n        linear: !ref <Linear>\n        decoder6: !ref <Decoder6>\n        decoder5: !ref <Decoder5>\n        decoder4: !ref <Decoder4>\n        decoder3: !ref <Decoder3>\n        decoder2: !ref <Decoder2>\n        decoder1: !ref <Decoder1>\n        # linearSeparator: !ref <LinearSeparator>\n        counter: !ref <epoch_counter>\n\n\ntrain_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n    save_file: !ref <train_log>","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T21:05:12.056300Z","iopub.execute_input":"2025-04-05T21:05:12.056630Z","iopub.status.idle":"2025-04-05T21:05:12.063286Z","shell.execute_reply.started":"2025-04-05T21:05:12.056603Z","shell.execute_reply":"2025-04-05T21:05:12.062076Z"}},"outputs":[{"name":"stdout","text":"Overwriting hparams.yaml\n","output_type":"stream"}],"execution_count":253},{"cell_type":"code","source":"%%file train.py\n#!/usr/bin/env/python3\n\"\"\"Recipe for training a neural speech separation system on the wsjmix\ndataset. The system employs an encoder, a decoder, and a masking network.\n\nTo run this recipe, do the following:\n> python train.py hparams/sepformer.yaml\n> python train.py hparams/dualpath_rnn.yaml\n> python train.py hparams/convtasnet.yaml\n\nThe experiment file is flexible enough to support different neural\nnetworks. By properly changing the parameter files, you can try\ndifferent architectures. The script supports both wsj2mix and\nwsj3mix.\n\n\nAuthors\n * Cem Subakan 2020\n * Mirco Ravanelli 2020\n * Samuele Cornell 2020\n * Mirko Bronzi 2020\n * Jianyuan Zhong 2020\n\"\"\"\n## CHECKPOINT\nimport csv\nimport os\nimport sys\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport torchaudio\nfrom hyperpyyaml import load_hyperpyyaml\nfrom tqdm import tqdm\n\nimport speechbrain as sb\nimport speechbrain.nnet.schedulers as schedulers\nfrom speechbrain.utils.distributed import run_on_main\nfrom speechbrain.utils.logger import get_logger\nfrom speechbrain.nnet.CNN import Conv1d, ConvTranspose1d\n# from speechbrain.nnet.activations import GLU\nfrom speechbrain.lobes.models.beats import GLU_Linear\nfrom torch.nn import GLU\nfrom speechbrain.nnet.RNN import LSTM\nfrom speechbrain.nnet.linear import Linear\nfrom models import EncoderBlock, DecoderBlock\nfrom speechbrain.nnet.losses import get_si_snr_with_pitwrapper\nimport musdb\n\n# Define training procedure\nclass DemucsSeparation(sb.Brain):\n    # def on_fit_start(self):\n        \n    #     self.encoder1 = EncoderBlock(C_in=2, C_out=64)\n    #     self.encoder2 = EncoderBlock(C_in=64, C_out=128)\n    #     self.encoder3 = EncoderBlock(C_in=128, C_out=256)\n    #     self.encoder4 = EncoderBlock(C_in=256, C_out=512)\n    #     self.encoder5 = EncoderBlock(C_in=512, C_out=1024)\n    #     self.encoder6 = EncoderBlock(C_in=1024, C_out=2048)\n\n    #     # Bidirectional LSTM (hidden_size=2048, 2 layers)\n    #     self.lstm = LSTM(\n    #         input_size=2048,\n    #         hidden_size=2048,\n    #         num_layers=2,\n    #         bidirectional=True\n    #     )\n        \n    #     # Linear layer (4096 -> 2048)\n    #     self.linear = Linear(input_size=4096, n_neurons=2048)\n\n    #     # Decoder path (matches image specs)\n    #     self.decoder6 = DecoderBlock(C_in=2048, C_out=1024)\n    #     self.decoder5 = DecoderBlock(C_in=1024, C_out=512)\n    #     self.decoder4 = DecoderBlock(C_in=512, C_out=256)\n    #     self.decoder3 = DecoderBlock(C_in=256, C_out=128)\n    #     self.decoder2 = DecoderBlock(C_in=128, C_out=64)\n    #     self.decoder1 = DecoderBlock(C_in=64, C_out=8)  # 4*2 channels\n        \n    def compute_forward(self, mix, targets, stage, noise=None):\n        \"\"\"Forward computations from the mixture to the separated signals.\"\"\"\n\n        # Unpack lists and put tensors in the right device\n        mix, mix_lens = mix\n        mix, mix_lens = mix.to(self.device), mix_lens.to(self.device)\n\n        # Convert targets to tensor\n        # print([targets[i][0].size() for i in range(self.hparams.num_spks)])\n        targets = torch.cat(\n            [targets[i][0].unsqueeze(-1) for i in range(self.hparams.num_spks)],\n            dim=-1,\n        ).to(self.device)\n\n        \n        # Add speech distortions\n        if stage == sb.Stage.TRAIN:\n            with torch.no_grad():\n\n                if self.hparams.use_wavedrop:\n                    mix = self.hparams.drop_chunk(mix, mix_lens)\n                    mix = self.hparams.drop_freq(mix)\n\n                if self.hparams.limit_training_signal_len:\n                    mix, targets = self.cut_signals(mix, targets)\n        \n\n        # Separation\n        \n        mix_enc_1 = self.modules.encoder1(mix)\n        \n        mix_enc_2 = self.modules.encoder2(mix_enc_1)\n        \n        mix_enc_3 = self.modules.encoder3(mix_enc_2)\n        mix_enc_4 = self.modules.encoder4(mix_enc_3)\n        mix_enc_5 = self.modules.encoder5(mix_enc_4)\n        mix_enc_6 = self.modules.encoder6(mix_enc_5)\n\n        lstm_in = mix_enc_6.permute(0,2,1)\n        lstm_out, _ = self.modules.lstm(lstm_in) # outputs both -- outputs as well as hidden states -- we dont need hidden states\n        # print(lstm_out.size())\n        lin_out = self.modules.linear(lstm_out) \n        # print(lin_out.size())\n        lin_out = lin_out.permute(0,2,1)\n        \n        mix_dec_6 = self.modules.decoder6(lin_out)\n        mix_dec_5 = self.modules.decoder5(mix_dec_6)\n        mix_dec_4 = self.modules.decoder4(mix_dec_5)\n        mix_dec_3 = self.modules.decoder3(mix_dec_4)\n        mix_dec_2 = self.modules.decoder2(mix_dec_3)\n        mix_dec_1 = self.modules.decoder1(mix_dec_2)\n\n        mix_out = self.modules.linearSeparator(mix_dec_1)\n        #  mix_dec_6 = self.modules.decoder6(lin_out + mix_enc_6)\n        # mix_dec_5 = self.modules.decoder5(mix_dec_6 + mix_enc_5)\n        # mix_dec_4 = self.modules.decoder4(mix_dec_5 + mix_enc_4)\n        # mix_dec_3 = self.modules.decoder3(mix_dec_4 + mix_enc_3)\n        # mix_dec_2 = self.modules.decoder2(mix_dec_3 + mix_enc_2)\n        # mix_dec_1 = self.modules.decoder1(mix_dec_2 + mix_enc_1)\n        \n        \n\n\n    \n        \n        # mix_w = self.hparams.Encoder(mix)\n        # est_mask = self.hparams.MaskNet(mix_w)\n        # mix_w = torch.stack([mix_w] * self.hparams.num_spks)\n        # sep_h = mix_w * est_mask\n\n        # # Decoding\n        \n        est_source = mix_out\n        # est_source = torch.cat(\n        #     [\n        #         mix_out[0][i].unsqueeze(-1)\n        #         for i in range(self.hparams.num_spks)\n        #     ],\n        #     dim=-1,\n        # )\n              \n        \n        # T changed after conv1d in encoder, fix it here\n        T_origin = targets.size(2)\n        T_est = est_source.size(2)\n        print(\"\")\n        print(T_origin)\n        print(T_est)\n        print(mix.size())\n        \n        if T_origin > T_est:\n            est_source = F.pad(est_source, (0, 0, T_origin - T_est, 0))\n        else:\n            est_source = est_source[:, : , :T_origin, :]\n\n        print(\"------Compute forward---------\")\n        print(est_source.size())\n        print(targets.size())\n#         torch.Size([1, 2, 2749780, 2])\n# torch.Size([1, 2, 2739955, 2])\n# in compute objective rn\n# torch.Size([1, 2, 2739955, 2])\n# torch.Size([1, 2, 2749780, 2])\n        # time.sleep(100000)\n        \n        return est_source, targets\n\n    def compute_objectives(self, predictions, targets):\n        \"\"\"Computes the sinr loss\"\"\"\n        print(\"in compute objective rn\")\n        print(targets.size())\n        print(predictions.size())\n        return self.hparams.loss(targets, predictions)\n## CHECKPOINT\n    def fit_batch(self, batch):\n        \"\"\"Trains one batch\"\"\"\n\n        # Unpacking batch list\n        mixture = batch.mix_sig\n        targets = [batch.voc_sig, batch.inst_sig]\n\n        with self.training_ctx:\n            predictions, targets = self.compute_forward(\n                mixture, targets, sb.Stage.TRAIN\n            )\n            \n            loss = self.compute_objectives(predictions, targets)\n\n            # hard threshold the easy dataitems\n            if self.hparams.threshold_byloss:\n                th = self.hparams.threshold\n                loss = loss[loss > th]\n                if loss.nelement() > 0:\n                    loss = loss.mean()\n            else:\n                loss = loss.mean()\n\n        if loss.nelement() > 0 and loss < self.hparams.loss_upper_lim:\n            self.scaler.scale(loss).backward()\n            if self.hparams.clip_grad_norm >= 0:\n                self.scaler.unscale_(self.optimizer)\n                torch.nn.utils.clip_grad_norm_(\n                    self.modules.parameters(),\n                    self.hparams.clip_grad_norm,\n                )\n            self.scaler.step(self.optimizer)\n            self.scaler.update()\n        else:\n            self.nonfinite_count += 1\n            logger.info(\n                \"infinite loss or empty loss! it happened {} times so far - skipping this batch\".format(\n                    self.nonfinite_count\n                )\n            )\n            loss.data = torch.tensor(0.0).to(self.device)\n        self.optimizer.zero_grad()\n\n        return loss.detach().cpu()\n\n    def evaluate_batch(self, batch, stage):\n        \"\"\"Computations needed for validation/test batches\"\"\"\n        snt_id = batch.track_id\n        mixture = batch.mix_sig\n        targets = [batch.voc_sig, batch.inst_sig]\n        \n\n        with torch.no_grad():\n            predictions, targets = self.compute_forward(mixture, targets, stage)\n            loss = self.compute_objectives(predictions, targets)\n\n        # Manage audio file saving\n        if stage == sb.Stage.TEST and self.hparams.save_audio:\n            if hasattr(self.hparams, \"n_audio_to_save\"):\n                if self.hparams.n_audio_to_save > 0:\n                    self.save_audio(snt_id[0], mixture, targets, predictions)\n                    self.hparams.n_audio_to_save += -1\n            else:\n                self.save_audio(snt_id[0], mixture, targets, predictions)\n\n        return loss.mean().detach()\n\n    def on_stage_end(self, stage, stage_loss, epoch):\n        \"\"\"Gets called at the end of a epoch.\"\"\"\n        # Compute/store important stats\n        stage_stats = {\"si-snr\": stage_loss}\n        if stage == sb.Stage.TRAIN:\n            self.train_stats = stage_stats\n\n        # Perform end-of-iteration things, like annealing, logging, etc.\n        if stage == sb.Stage.VALID:\n            # Learning rate annealing\n            if isinstance(\n                self.hparams.lr_scheduler, schedulers.ReduceLROnPlateau\n            ):\n                current_lr, next_lr = self.hparams.lr_scheduler(\n                    [self.optimizer], epoch, stage_loss\n                )\n                schedulers.update_learning_rate(self.optimizer, next_lr)\n            else:\n                # if we do not use the reducelronplateau, we do not change the lr\n                current_lr = self.hparams.optimizer.optim.param_groups[0][\"lr\"]\n\n            self.hparams.train_logger.log_stats(\n                stats_meta={\"epoch\": epoch, \"lr\": current_lr},\n                train_stats=self.train_stats,\n                valid_stats=stage_stats,\n            )\n            self.checkpointer.save_and_keep_only(\n                meta={\"si-snr\": stage_stats[\"si-snr\"]}, min_keys=[\"si-snr\"]\n            )\n        elif stage == sb.Stage.TEST:\n            self.hparams.train_logger.log_stats(\n                stats_meta={\"Epoch loaded\": self.hparams.epoch_counter.current},\n                test_stats=stage_stats,\n            )\n\n    def cut_signals(self, mixture, targets):\n        \"\"\"This function selects a random segment of a given length within the mixture.\n        The corresponding targets are selected accordingly\"\"\"\n        randstart = torch.randint(\n            0,\n            1 + max(0, mixture.shape[1] - self.hparams.training_signal_len),\n            (1,),\n        ).item()\n        targets = targets[\n            :, randstart : randstart + self.hparams.training_signal_len, :\n        ]\n        mixture = mixture[\n            :, randstart : randstart + self.hparams.training_signal_len\n        ]\n        return mixture, targets\n\n    def reset_layer_recursively(self, layer):\n        \"\"\"Reinitializes the parameters of the neural networks\"\"\"\n        if hasattr(layer, \"reset_parameters\"):\n            layer.reset_parameters()\n        for child_layer in layer.modules():\n            if layer != child_layer:\n                self.reset_layer_recursively(child_layer)\n\n    def save_results(self, test_data):\n        \"\"\"This script computes the SDR and SI-SNR metrics and saves\n        them into a csv file\"\"\"\n\n        # This package is required for SDR computation\n        from mir_eval.separation import bss_eval_sources\n\n        # Create folders where to store audio\n        save_file = os.path.join(self.hparams.output_folder, \"test_results.csv\")\n\n        # Variable init\n        all_sdrs = []\n        all_sdrs_i = []\n        all_sisnrs = []\n        all_sisnrs_i = []\n        csv_columns = [\"snt_id\", \"sdr\", \"sdr_i\", \"si-snr\", \"si-snr_i\"]\n\n        test_loader = sb.dataio.dataloader.make_dataloader(\n            test_data, **self.hparams.dataloader_opts\n        )\n\n        with open(save_file, \"w\", newline=\"\", encoding=\"utf-8\") as results_csv:\n            writer = csv.DictWriter(results_csv, fieldnames=csv_columns)\n            writer.writeheader()\n\n            # Loop over all test sentence\n            with tqdm(test_loader, dynamic_ncols=True) as t:\n                for i, batch in enumerate(t):\n                    # Apply Separation\n                    mixture, mix_len = batch.mix_sig\n                    snt_id = batch.track_id\n                    targets = [batch.voc_sig, batch.inst_sig]\n                    \n\n                    with torch.no_grad():\n                        predictions, targets = self.compute_forward(\n                            batch.mix_sig, targets, sb.Stage.TEST\n                        )\n\n                    # Compute SI-SNR\n                    predictions = predictions.permute(0,2,1,3).squeeze(dim=-1)\n                    targets = targets.permute(0,2,1,3).squeeze(dim=-1)\n                    print(predictions.size())\n                    print(targets.size())\n                    sisnr = get_si_snr_with_pitwrapper(predictions, targets)\n\n                    # Compute SI-SNR improvement\n                    mixture_signal = torch.stack(\n                        [mixture] * self.hparams.num_spks, dim=-1\n                    ).permute(0,2,1,3).squeeze(dim=-1)\n                    print(\"---------------------\")\n                    print(mixture.size())\n                    print(mixture_signal.size())\n\n                    mixture_signal = mixture_signal.to(targets.device)\n                    sisnr_baseline = get_si_snr_with_pitwrapper(\n                        mixture_signal, targets\n                    )\n                    sisnr_i = sisnr - sisnr_baseline\n\n                    # Compute SDR\n                    sdr, _, _, _ = bss_eval_sources(\n                        targets[0].mean(dim=1).t().cpu().numpy(),\n                        predictions[0].mean(dim=1).t().detach().cpu().numpy(),\n                    )\n\n                    sdr_baseline, _, _, _ = bss_eval_sources(\n                        targets[0].mean(dim=1).t().cpu().numpy(),\n                        mixture_signal[0].mean(dim=1).t().detach().cpu().numpy(),\n                    )\n\n                    sdr_i = sdr.mean() - sdr_baseline.mean()\n\n                    # Saving on a csv file\n                    row = {\n                        \"snt_id\": snt_id[0],\n                        \"sdr\": sdr.mean(),\n                        \"sdr_i\": sdr_i,\n                        \"si-snr\": -sisnr.item(),\n                        \"si-snr_i\": -sisnr_i.item(),\n                    }\n                    writer.writerow(row)\n\n                    # Metric Accumulation\n                    all_sdrs.append(sdr.mean())\n                    all_sdrs_i.append(sdr_i.mean())\n                    all_sisnrs.append(-sisnr.item())\n                    all_sisnrs_i.append(-sisnr_i.item())\n\n                row = {\n                    \"snt_id\": \"avg\",\n                    \"sdr\": np.array(all_sdrs).mean(),\n                    \"sdr_i\": np.array(all_sdrs_i).mean(),\n                    \"si-snr\": np.array(all_sisnrs).mean(),\n                    \"si-snr_i\": np.array(all_sisnrs_i).mean(),\n                }\n                writer.writerow(row)\n\n        logger.info(\"Mean SISNR is {}\".format(np.array(all_sisnrs).mean()))\n        logger.info(\"Mean SISNRi is {}\".format(np.array(all_sisnrs_i).mean()))\n        logger.info(\"Mean SDR is {}\".format(np.array(all_sdrs).mean()))\n        logger.info(\"Mean SDRi is {}\".format(np.array(all_sdrs_i).mean()))\n\n    def save_audio(self, snt_id, mixture, targets, predictions):\n        \"saves the test audio (mixture, targets, and estimated sources) on disk\"\n\n        # Create output folder\n        \n        save_path = os.path.join(self.hparams.save_folder, \"audio_results\")\n        if not os.path.exists(save_path):\n            os.mkdir(save_path)\n\n        for ns in range(self.hparams.num_spks):\n            # Estimated source\n            signal = predictions[0,: , :, ns]\n            signal = signal / signal.abs().max()\n            print(signal.size())\n            save_file = os.path.join(\n                save_path, \"item{}_source{}hat.wav\".format(snt_id, ns + 1)\n            )\n            torchaudio.save(\n                save_file, signal.cpu(), self.hparams.sample_rate\n            )\n\n            # Original source\n            signal = targets[0, :, : , ns]\n            signal = signal / signal.abs().max()\n            save_file = os.path.join(\n                save_path, \"item{}_source{}.wav\".format(snt_id, ns + 1)\n            )\n            torchaudio.save(\n                save_file, signal.cpu(), self.hparams.sample_rate\n            )\n\n        # Mixture\n        signal = mixture[0][0, :]\n        signal = signal / signal.abs().max()\n        print(signal.size())\n        save_file = os.path.join(save_path, \"item{}_mix.wav\".format(snt_id))\n        torchaudio.save(\n            save_file, signal.cpu(), self.hparams.sample_rate\n        )\n\n\n# def dataio_prep(hparams):\n#     \"\"\"Creates data processing pipeline\"\"\"\n\n#     # 1. Define datasets\n#     train_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n#         csv_path=hparams[\"train_data\"],\n#         replacements={\"data_root\": hparams[\"data_folder\"]},\n#     )\n\n#     valid_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n#         csv_path=hparams[\"valid_data\"],\n#         replacements={\"data_root\": hparams[\"data_folder\"]},\n#     )\n\n#     test_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n#         csv_path=hparams[\"test_data\"],\n#         replacements={\"data_root\": hparams[\"data_folder\"]},\n#     )\n\n#     datasets = [train_data, valid_data, test_data]\n\n#     # 2. Provide audio pipelines\n\n#     @sb.utils.data_pipeline.takes(\"mix_wav\")\n#     @sb.utils.data_pipeline.provides(\"mix_sig\")\n#     def audio_pipeline_mix(mix_wav):\n#         mix_sig = sb.dataio.dataio.read_audio(mix_wav)\n#         return mix_sig\n\n#     @sb.utils.data_pipeline.takes(\"s1_wav\")\n#     @sb.utils.data_pipeline.provides(\"s1_sig\")\n#     def audio_pipeline_s1(s1_wav):\n#         s1_sig = sb.dataio.dataio.read_audio(s1_wav)\n#         return s1_sig\n\n#     @sb.utils.data_pipeline.takes(\"s2_wav\")\n#     @sb.utils.data_pipeline.provides(\"s2_sig\")\n#     def audio_pipeline_s2(s2_wav):\n#         s2_sig = sb.dataio.dataio.read_audio(s2_wav)\n#         return s2_sig\n\n#     if hparams[\"num_spks\"] == 3:\n\n#         @sb.utils.data_pipeline.takes(\"s3_wav\")\n#         @sb.utils.data_pipeline.provides(\"s3_sig\")\n#         def audio_pipeline_s3(s3_wav):\n#             s3_sig = sb.dataio.dataio.read_audio(s3_wav)\n#             return s3_sig\n\n#     sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_mix)\n#     sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_s1)\n#     sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_s2)\n#     if hparams[\"num_spks\"] == 3:\n#         sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_s3)\n#         sb.dataio.dataset.set_output_keys(\n#             datasets, [\"id\", \"mix_sig\", \"s1_sig\", \"s2_sig\", \"s3_sig\"]\n#         )\n#     else:\n#         sb.dataio.dataset.set_output_keys(\n#             datasets, [\"id\", \"mix_sig\", \"s1_sig\", \"s2_sig\"]\n#         )\n\n#     return train_data, valid_data, test_data\n\n## CHECKPOINT\ndef dataio_prep(hparams):\n    \"\"\"Creates data processing pipeline\"\"\"\n\n    # 1. Define datasets\n\n    # datasets = {}\n    # data_info = {\n    #     \"train\": hparams[\"train_annotation\"],\n    #     \"valid\": hparams[\"valid_annotation\"],\n    #     \"test\": hparams[\"test_annotation\"],\n    # }\n\n        \n    MUS_DB_PATH = hparams[\"db_path\"]\n    \n    mus = musdb.DB(root=MUS_DB_PATH)\n    \n    mus_train = musdb.DB(root=MUS_DB_PATH,subsets=\"train\", split=\"train\")\n    mus_valid = musdb.DB(root=MUS_DB_PATH,subsets=\"train\", split=\"valid\")\n    mus_test = musdb.DB(root=MUS_DB_PATH,subsets=\"test\")\n\n\n        \n    def create_json(mus_obj):\n      json_dict = {}\n      for i, track in enumerate(mus_obj):\n        \n        file_name = track.name\n        file_path = track.path\n        file_rate = track.rate\n        \n        json_dict[file_name] = {\n                  \"track\": track\n          }\n        \n        return json_dict\n          \n    train_obj = create_json(mus_train)\n    test_obj = create_json(mus_test)\n    valid_obj = create_json(mus_valid)\n    \n   \n    \n    \n  \n    def convert_musdb_to_torch(track, target_sr=8000, chunk_size_seconds=1):\n        \"\"\"\n        Converts a musdb track to a PyTorch tensor with efficient resampling.\n    \n        Args:\n            track: A musdb track object (e.g., `mus_train[0]`).\n            target_sr (int): The target sampling rate for resampling.\n            chunk_size_seconds (int): Number of seconds per processing chunk.\n    \n        Returns:\n            torch.Tensor: The resampled waveform tensor of shape (num_channels, num_samples).\n        \"\"\"\n        # Convert to tensor and move channels first (PyTorch format)\n        audio_tensor = torch.from_numpy(track.audio).float().permute(1, 0)  # Shape: (num_channels, num_samples)\n        \n        orig_sr = track.rate  # Original sample rate\n        \n        chunk_size = orig_sr * chunk_size_seconds  # Convert chunk size to samples\n    \n        resampled_chunks = []\n    \n        for i in range(0, audio_tensor.shape[1], chunk_size):\n            chunk = audio_tensor[:, i:i + chunk_size]  # Extract chunk\n            resampled_chunk = torchaudio.functional.resample(chunk, orig_freq=orig_sr, new_freq=target_sr)\n            resampled_chunks.append(resampled_chunk)\n    \n        # Concatenate back the processed chunks\n        # print(\"PROCESSING CHUNKS\")\n        resampled_audio = torch.cat(resampled_chunks, dim=1)\n        # print(resampled_audio.shape)\n        resampled_audio = resampled_audio #.mean(dim=0, keepdim=False) # need 2 channels for demucs\n        # print(resampled_audio.shape)\n        # print(resampled_audio.shape)\n        return resampled_audio\n    \n    \n    @sb.utils.data_pipeline.takes(\"track\")\n    @sb.utils.data_pipeline.provides(\"track_id\",\"mix_sig\", \"voc_sig\", \"inst_sig\")\n    def audio_pipeline_mix(track):\n        # mix_sig = torchaudio.functional.resample(torch.from_numpy(track.audio), track.rate, hparams[\"sample_rate\"])\n\n        # voc_sig = torchaudio.functional.resample(torch.from_numpy(track.targets['vocals'].audio), track.rate, hparams[\"sample_rate\"])\n\n        # inst_sig = torchaudio.functional.resample(torch.from_numpy(track.targets['accompaniment'].audio), track.rate, hparams[\"sample_rate\"])\n         #.squeeze(dim=0) \n        mix_sig = convert_musdb_to_torch(track, hparams[\"sample_rate\"], chunk_size_seconds=1)\n        voc_sig = convert_musdb_to_torch(track.targets[\"vocals\"], hparams[\"sample_rate\"], chunk_size_seconds=1)\n        inst_sig = convert_musdb_to_torch(track.targets[\"accompaniment\"], hparams[\"sample_rate\"], chunk_size_seconds=1)\n        track_id = track.name\n        \n        return track_id, mix_sig, voc_sig, inst_sig\n\n\n    \n    \n    train_data = sb.dataio.dataset.DynamicItemDataset(train_obj, dynamic_items=[audio_pipeline_mix], output_keys=[\"track_id\",\"mix_sig\", \"voc_sig\", \"inst_sig\"])\n    valid_data = sb.dataio.dataset.DynamicItemDataset(valid_obj, dynamic_items=[audio_pipeline_mix], output_keys=[\"track_id\",\"mix_sig\", \"voc_sig\", \"inst_sig\"])\n    test_data = sb.dataio.dataset.DynamicItemDataset(test_obj, dynamic_items=[audio_pipeline_mix], output_keys=[\"track_id\",\"mix_sig\", \"voc_sig\", \"inst_sig\"])\n    datasets = [train_data, valid_data, test_data]\n    \n    \n    return datasets\n\nif __name__ == \"__main__\":\n    # Load hyperparameters file with command-line overrides\n    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n    with open(hparams_file, encoding=\"utf-8\") as fin:\n        hparams = load_hyperpyyaml(fin, overrides)\n\n    # Initialize ddp (useful only for multi-GPU DDP training)\n    sb.utils.distributed.ddp_init_group(run_opts)\n\n    # Logger info\n    logger = get_logger(__name__)\n\n    # Create experiment directory\n    sb.create_experiment_directory(\n        experiment_directory=hparams[\"output_folder\"],\n        hyperparams_to_save=hparams_file,\n        overrides=overrides,\n    )\n\n    # Update precision to bf16 if the device is CPU and precision is fp16\n    if run_opts.get(\"device\") == \"cpu\" and hparams.get(\"precision\") == \"fp16\":\n        hparams[\"precision\"] = \"bf16\"\n\n\n \n    train_data, valid_data, test_data = dataio_prep(hparams)\n\n   \n    # Brain class initialization\n    separator = DemucsSeparation(\n        modules=hparams[\"modules\"],\n        opt_class=hparams[\"optimizer\"],\n        hparams=hparams,\n        run_opts=run_opts,\n        checkpointer=hparams[\"checkpointer\"],\n    )\n\n  \n    # Training\n    separator.fit(\n        separator.hparams.epoch_counter,\n        train_data,\n        valid_data,\n        train_loader_kwargs=hparams[\"dataloader_opts\"],\n        valid_loader_kwargs=hparams[\"dataloader_opts\"],\n    )\n\n    # Eval\n    separator.evaluate(test_data, min_key=\"si-snr\")\n    separator.save_results(test_data)\n    ## CHECKPOINT","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T21:05:12.135290Z","iopub.execute_input":"2025-04-05T21:05:12.135635Z","iopub.status.idle":"2025-04-05T21:05:12.145031Z","shell.execute_reply.started":"2025-04-05T21:05:12.135605Z","shell.execute_reply":"2025-04-05T21:05:12.143964Z"}},"outputs":[{"name":"stdout","text":"Overwriting train.py\n","output_type":"stream"}],"execution_count":254},{"cell_type":"code","source":"# To start from scratch, you need to remove the output folder.\n# Otherwise, speechbrain starts from the last valid checkpoint.\n#!rm -rf ./results/AudioMNIST/Autoencoder/\n## CHECKPOINT\n!python train.py hparams.yaml --data_folder=db_path\n# !torchrun --standalone --nproc_per_node=2 train.py hparams.yaml --data_folder=db_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T21:05:12.147226Z","iopub.execute_input":"2025-04-05T21:05:12.147496Z","iopub.status.idle":"2025-04-05T21:58:07.523298Z","shell.execute_reply.started":"2025-04-05T21:05:12.147473Z","shell.execute_reply":"2025-04-05T21:58:07.522095Z"}},"outputs":[{"name":"stdout","text":"speechbrain.utils.quirks - Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\nspeechbrain.utils.quirks - Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\nspeechbrain.core - Beginning experiment!\nspeechbrain.core - Experiment folder: /kaggle/working/results/demucs/1234\nspeechbrain.core - Info: precision arg from hparam file is used\nspeechbrain.core - Info: noprogressbar arg from hparam file is used\nspeechbrain.core - Gradscaler enabled: `True`\nspeechbrain.core - Using training precision: `--precision=fp16`\nspeechbrain.core - Using evaluation precision: `--eval_precision=fp32`\nspeechbrain.core - DemucsSeparation Model Statistics:\n* Total Number of Trainable Parameters: 243.3M\n* Total Number of Parameters: 243.3M\n* Trainable Parameters represent 100.0000% of the total size.\nspeechbrain.utils.checkpoints - Loading a checkpoint from /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+19-39-59+00\n/usr/local/lib/python3.10/dist-packages/speechbrain/utils/checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state_dict = torch.load(path, map_location=device)\nspeechbrain.utils.epoch_loop - Going into epoch 11\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.75s/it, train_loss=0.0645]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.53s/it]\nspeechbrain.utils.train_logger - epoch: 11, lr: 1.50e-04 - train si-snr: 6.45e-02 - valid si-snr: 5.73e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-06-17+00\nspeechbrain.utils.epoch_loop - Going into epoch 12\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.53s/it, train_loss=0.0641]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.75s/it]\nspeechbrain.utils.train_logger - epoch: 12, lr: 1.50e-04 - train si-snr: 6.41e-02 - valid si-snr: 5.69e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-06-37+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-06-17+00\nspeechbrain.utils.epoch_loop - Going into epoch 13\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.03s/it, train_loss=0.0637]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.57s/it]\nspeechbrain.utils.train_logger - epoch: 13, lr: 1.50e-04 - train si-snr: 6.37e-02 - valid si-snr: 5.66e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-06-57+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-06-37+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+19-39-59+00\nspeechbrain.utils.epoch_loop - Going into epoch 14\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.17s/it, train_loss=0.0634]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.57s/it]\nspeechbrain.utils.train_logger - epoch: 14, lr: 1.50e-04 - train si-snr: 6.34e-02 - valid si-snr: 5.62e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-07-18+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-06-57+00\nspeechbrain.utils.epoch_loop - Going into epoch 15\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|███████████████████████████| 1/1 [00:06<00:00,  6.98s/it, train_loss=0.063]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.50s/it]\nspeechbrain.utils.train_logger - epoch: 15, lr: 1.50e-04 - train si-snr: 6.30e-02 - valid si-snr: 5.59e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-07-38+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-07-18+00\nspeechbrain.utils.epoch_loop - Going into epoch 16\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.23s/it, train_loss=0.0626]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.71s/it]\nspeechbrain.utils.train_logger - epoch: 16, lr: 1.50e-04 - train si-snr: 6.26e-02 - valid si-snr: 5.55e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-08-01+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-07-38+00\nspeechbrain.utils.epoch_loop - Going into epoch 17\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.53s/it, train_loss=0.0623]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.68s/it]\nspeechbrain.utils.train_logger - epoch: 17, lr: 1.50e-04 - train si-snr: 6.23e-02 - valid si-snr: 5.51e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-08-22+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-08-01+00\nspeechbrain.utils.epoch_loop - Going into epoch 18\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.32s/it, train_loss=0.0619]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.65s/it]\nspeechbrain.utils.train_logger - epoch: 18, lr: 1.50e-04 - train si-snr: 6.19e-02 - valid si-snr: 5.48e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-08-42+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-08-22+00\nspeechbrain.utils.epoch_loop - Going into epoch 19\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.01s/it, train_loss=0.0616]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.75s/it]\nspeechbrain.utils.train_logger - epoch: 19, lr: 1.50e-04 - train si-snr: 6.16e-02 - valid si-snr: 5.44e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-09-03+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-08-42+00\nspeechbrain.utils.epoch_loop - Going into epoch 20\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.31s/it, train_loss=0.0612]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.90s/it]\nspeechbrain.utils.train_logger - epoch: 20, lr: 1.50e-04 - train si-snr: 6.12e-02 - valid si-snr: 5.41e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-09-23+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-09-03+00\nspeechbrain.utils.epoch_loop - Going into epoch 21\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.13s/it, train_loss=0.0608]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.67s/it]\nspeechbrain.utils.train_logger - epoch: 21, lr: 1.50e-04 - train si-snr: 6.08e-02 - valid si-snr: 5.37e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-09-45+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-09-23+00\nspeechbrain.utils.epoch_loop - Going into epoch 22\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.33s/it, train_loss=0.0605]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.69s/it]\nspeechbrain.utils.train_logger - epoch: 22, lr: 1.50e-04 - train si-snr: 6.05e-02 - valid si-snr: 5.33e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-10-05+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-09-45+00\nspeechbrain.utils.epoch_loop - Going into epoch 23\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.02s/it, train_loss=0.0601]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.61s/it]\nspeechbrain.utils.train_logger - epoch: 23, lr: 1.50e-04 - train si-snr: 6.01e-02 - valid si-snr: 5.30e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-10-26+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-10-05+00\nspeechbrain.utils.epoch_loop - Going into epoch 24\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.10s/it, train_loss=0.0598]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.74s/it]\nspeechbrain.utils.train_logger - epoch: 24, lr: 1.50e-04 - train si-snr: 5.98e-02 - valid si-snr: 5.26e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-10-46+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-10-26+00\nspeechbrain.utils.epoch_loop - Going into epoch 25\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.18s/it, train_loss=0.0594]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.69s/it]\nspeechbrain.utils.train_logger - epoch: 25, lr: 1.50e-04 - train si-snr: 5.94e-02 - valid si-snr: 5.23e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-11-07+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-10-46+00\nspeechbrain.utils.epoch_loop - Going into epoch 26\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|███████████████████████████| 1/1 [00:07<00:00,  7.08s/it, train_loss=0.059]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.74s/it]\nspeechbrain.utils.train_logger - epoch: 26, lr: 1.50e-04 - train si-snr: 5.90e-02 - valid si-snr: 5.19e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-11-27+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-11-07+00\nspeechbrain.utils.epoch_loop - Going into epoch 27\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.39s/it, train_loss=0.0587]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.60s/it]\nspeechbrain.utils.train_logger - epoch: 27, lr: 1.50e-04 - train si-snr: 5.87e-02 - valid si-snr: 5.15e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-11-48+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-11-27+00\nspeechbrain.utils.epoch_loop - Going into epoch 28\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.13s/it, train_loss=0.0583]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.58s/it]\nspeechbrain.utils.train_logger - epoch: 28, lr: 1.50e-04 - train si-snr: 5.83e-02 - valid si-snr: 5.11e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-12-09+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-11-48+00\nspeechbrain.utils.epoch_loop - Going into epoch 29\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|███████████████████████████| 1/1 [00:07<00:00,  7.26s/it, train_loss=0.058]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.93s/it]\nspeechbrain.utils.train_logger - epoch: 29, lr: 1.50e-04 - train si-snr: 5.80e-02 - valid si-snr: 5.08e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-12-29+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-12-09+00\nspeechbrain.utils.epoch_loop - Going into epoch 30\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.20s/it, train_loss=0.0576]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.70s/it]\nspeechbrain.utils.train_logger - epoch: 30, lr: 1.50e-04 - train si-snr: 5.76e-02 - valid si-snr: 5.04e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-12-50+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-12-29+00\nspeechbrain.utils.epoch_loop - Going into epoch 31\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.27s/it, train_loss=0.0571]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.67s/it]\nspeechbrain.utils.train_logger - epoch: 31, lr: 1.50e-04 - train si-snr: 5.71e-02 - valid si-snr: 5.00e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-13-11+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-12-50+00\nspeechbrain.utils.epoch_loop - Going into epoch 32\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.53s/it, train_loss=0.0568]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.72s/it]\nspeechbrain.utils.train_logger - epoch: 32, lr: 1.50e-04 - train si-snr: 5.68e-02 - valid si-snr: 4.95e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-13-31+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-13-11+00\nspeechbrain.utils.epoch_loop - Going into epoch 33\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.50s/it, train_loss=0.0563]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.71s/it]\nspeechbrain.utils.train_logger - epoch: 33, lr: 1.50e-04 - train si-snr: 5.63e-02 - valid si-snr: 4.91e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-13-52+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-13-31+00\nspeechbrain.utils.epoch_loop - Going into epoch 34\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.37s/it, train_loss=0.0559]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.73s/it]\nspeechbrain.utils.train_logger - epoch: 34, lr: 1.50e-04 - train si-snr: 5.59e-02 - valid si-snr: 4.87e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-14-13+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-13-52+00\nspeechbrain.utils.epoch_loop - Going into epoch 35\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.45s/it, train_loss=0.0555]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.84s/it]\nspeechbrain.utils.train_logger - epoch: 35, lr: 1.50e-04 - train si-snr: 5.55e-02 - valid si-snr: 4.82e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-14-34+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-14-13+00\nspeechbrain.utils.epoch_loop - Going into epoch 36\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|███████████████████████████| 1/1 [00:07<00:00,  7.37s/it, train_loss=0.055]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.69s/it]\nspeechbrain.utils.train_logger - epoch: 36, lr: 1.50e-04 - train si-snr: 5.50e-02 - valid si-snr: 4.77e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-14-54+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-14-34+00\nspeechbrain.utils.epoch_loop - Going into epoch 37\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.35s/it, train_loss=0.0546]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.94s/it]\nspeechbrain.utils.train_logger - epoch: 37, lr: 1.50e-04 - train si-snr: 5.46e-02 - valid si-snr: 4.72e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-15-15+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-14-54+00\nspeechbrain.utils.epoch_loop - Going into epoch 38\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|███████████████████████████| 1/1 [00:07<00:00,  7.56s/it, train_loss=0.054]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.67s/it]\nspeechbrain.utils.train_logger - epoch: 38, lr: 1.50e-04 - train si-snr: 5.40e-02 - valid si-snr: 4.67e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-15-37+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-15-15+00\nspeechbrain.utils.epoch_loop - Going into epoch 39\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.48s/it, train_loss=0.0535]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.67s/it]\nspeechbrain.utils.train_logger - epoch: 39, lr: 1.50e-04 - train si-snr: 5.35e-02 - valid si-snr: 4.61e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-15-58+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-15-37+00\nspeechbrain.utils.epoch_loop - Going into epoch 40\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.52s/it, train_loss=0.0529]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.84s/it]\nspeechbrain.utils.train_logger - epoch: 40, lr: 1.50e-04 - train si-snr: 5.29e-02 - valid si-snr: 4.54e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-16-19+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-15-58+00\nspeechbrain.utils.epoch_loop - Going into epoch 41\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.50s/it, train_loss=0.0522]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.75s/it]\nspeechbrain.utils.train_logger - epoch: 41, lr: 1.50e-04 - train si-snr: 5.22e-02 - valid si-snr: 4.47e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-16-41+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-16-19+00\nspeechbrain.utils.epoch_loop - Going into epoch 42\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.63s/it, train_loss=0.0515]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.82s/it]\nspeechbrain.utils.train_logger - epoch: 42, lr: 1.50e-04 - train si-snr: 5.15e-02 - valid si-snr: 4.39e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-17-02+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-16-41+00\nspeechbrain.utils.epoch_loop - Going into epoch 43\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.77s/it, train_loss=0.0507]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.84s/it]\nspeechbrain.utils.train_logger - epoch: 43, lr: 1.50e-04 - train si-snr: 5.07e-02 - valid si-snr: 4.31e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-17-23+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-17-02+00\nspeechbrain.utils.epoch_loop - Going into epoch 44\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.61s/it, train_loss=0.0499]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.61s/it]\nspeechbrain.utils.train_logger - epoch: 44, lr: 1.50e-04 - train si-snr: 4.99e-02 - valid si-snr: 4.22e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-17-45+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-17-23+00\nspeechbrain.utils.epoch_loop - Going into epoch 45\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|███████████████████████████| 1/1 [00:07<00:00,  7.40s/it, train_loss=0.049]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.67s/it]\nspeechbrain.utils.train_logger - epoch: 45, lr: 1.50e-04 - train si-snr: 4.90e-02 - valid si-snr: 4.11e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-18-06+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-17-45+00\nspeechbrain.utils.epoch_loop - Going into epoch 46\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.49s/it, train_loss=0.0479]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.72s/it]\nspeechbrain.utils.train_logger - epoch: 46, lr: 1.50e-04 - train si-snr: 4.79e-02 - valid si-snr: 3.95e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-18-26+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-18-06+00\nspeechbrain.utils.epoch_loop - Going into epoch 47\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.77s/it, train_loss=0.0463]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.92s/it]\nspeechbrain.utils.train_logger - epoch: 47, lr: 1.50e-04 - train si-snr: 4.63e-02 - valid si-snr: 3.68e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-18-49+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-18-26+00\nspeechbrain.utils.epoch_loop - Going into epoch 48\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.58s/it, train_loss=0.0436]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.83s/it]\nspeechbrain.utils.train_logger - epoch: 48, lr: 1.50e-04 - train si-snr: 4.36e-02 - valid si-snr: 3.17e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-19-10+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-18-49+00\nspeechbrain.utils.epoch_loop - Going into epoch 49\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.76s/it, train_loss=0.0385]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.79s/it]\nspeechbrain.utils.train_logger - epoch: 49, lr: 1.50e-04 - train si-snr: 3.85e-02 - valid si-snr: 3.79e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-19-31+00\nspeechbrain.utils.epoch_loop - Going into epoch 50\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:09<00:00,  9.02s/it, train_loss=0.0447]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.06s/it]\nspeechbrain.utils.train_logger - epoch: 50, lr: 1.50e-04 - train si-snr: 4.47e-02 - valid si-snr: 2.81e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-19-53+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-19-31+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-19-10+00\nspeechbrain.utils.epoch_loop - Going into epoch 51\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.17s/it, train_loss=0.0349]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.05s/it]\nspeechbrain.utils.train_logger - epoch: 51, lr: 1.50e-04 - train si-snr: 3.49e-02 - valid si-snr: 3.02e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-20-16+00\nspeechbrain.utils.epoch_loop - Going into epoch 52\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|███████████████████████████| 1/1 [00:09<00:00,  9.13s/it, train_loss=0.037]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.04s/it]\nspeechbrain.utils.train_logger - epoch: 52, lr: 1.50e-04 - train si-snr: 3.70e-02 - valid si-snr: 3.14e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-20-38+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-20-16+00\nspeechbrain.utils.epoch_loop - Going into epoch 53\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.38s/it, train_loss=0.0382]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.18s/it]\nspeechbrain.utils.train_logger - epoch: 53, lr: 1.50e-04 - train si-snr: 3.82e-02 - valid si-snr: 3.19e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-21-00+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-20-38+00\nspeechbrain.utils.epoch_loop - Going into epoch 54\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.31s/it, train_loss=0.0387]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.14s/it]\nspeechbrain.utils.train_logger - epoch: 54, lr: 1.50e-04 - train si-snr: 3.87e-02 - valid si-snr: 3.17e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-21-22+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-21-00+00\nspeechbrain.utils.epoch_loop - Going into epoch 55\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.02s/it, train_loss=0.0385]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.03s/it]\nspeechbrain.utils.train_logger - epoch: 55, lr: 1.50e-04 - train si-snr: 3.85e-02 - valid si-snr: 3.13e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-21-44+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-21-22+00\nspeechbrain.utils.epoch_loop - Going into epoch 56\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.30s/it, train_loss=0.0381]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.31s/it]\nspeechbrain.utils.train_logger - epoch: 56, lr: 1.50e-04 - train si-snr: 3.81e-02 - valid si-snr: 3.04e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-22-06+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-21-44+00\nspeechbrain.utils.epoch_loop - Going into epoch 57\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.08s/it, train_loss=0.0372]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.04s/it]\nspeechbrain.utils.train_logger - epoch: 57, lr: 1.50e-04 - train si-snr: 3.72e-02 - valid si-snr: 2.93e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-22-28+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-22-06+00\nspeechbrain.utils.epoch_loop - Going into epoch 58\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.27s/it, train_loss=0.0361]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.24s/it]\nspeechbrain.utils.train_logger - epoch: 58, lr: 1.50e-04 - train si-snr: 3.61e-02 - valid si-snr: 2.76e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-22-51+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-19-53+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-22-28+00\nspeechbrain.utils.epoch_loop - Going into epoch 59\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.55s/it, train_loss=0.0345]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.03s/it]\nspeechbrain.utils.train_logger - epoch: 59, lr: 1.50e-04 - train si-snr: 3.45e-02 - valid si-snr: 2.55e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-23-14+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-22-51+00\nspeechbrain.utils.epoch_loop - Going into epoch 60\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.15s/it, train_loss=0.0324]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.27s/it]\nspeechbrain.utils.train_logger - epoch: 60, lr: 1.50e-04 - train si-snr: 3.24e-02 - valid si-snr: 2.35e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-23-36+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-23-14+00\nspeechbrain.utils.epoch_loop - Going into epoch 61\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.15s/it, train_loss=0.0303]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.21s/it]\nspeechbrain.utils.train_logger - epoch: 61, lr: 1.50e-04 - train si-snr: 3.03e-02 - valid si-snr: 2.51e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-23-58+00\nspeechbrain.utils.epoch_loop - Going into epoch 62\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|███████████████████████████| 1/1 [00:08<00:00,  8.56s/it, train_loss=0.032]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.29s/it]\nspeechbrain.utils.train_logger - epoch: 62, lr: 1.50e-04 - train si-snr: 3.20e-02 - valid si-snr: 2.39e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-24-20+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-23-58+00\nspeechbrain.utils.epoch_loop - Going into epoch 63\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.25s/it, train_loss=0.0308]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.31s/it]\nspeechbrain.utils.train_logger - epoch: 63, lr: 1.50e-04 - train si-snr: 3.08e-02 - valid si-snr: 2.21e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-24-42+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-24-20+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-23-36+00\nspeechbrain.utils.epoch_loop - Going into epoch 64\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.02s/it, train_loss=0.0289]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.26s/it]\nspeechbrain.utils.train_logger - epoch: 64, lr: 1.50e-04 - train si-snr: 2.89e-02 - valid si-snr: 2.19e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-25-05+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-24-42+00\nspeechbrain.utils.epoch_loop - Going into epoch 65\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.24s/it, train_loss=0.0287]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.12s/it]\nspeechbrain.utils.train_logger - epoch: 65, lr: 1.50e-04 - train si-snr: 2.87e-02 - valid si-snr: 2.19e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-25-27+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-25-05+00\nspeechbrain.utils.epoch_loop - Going into epoch 66\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.39s/it, train_loss=0.0287]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.28s/it]\nspeechbrain.utils.train_logger - epoch: 66, lr: 1.50e-04 - train si-snr: 2.87e-02 - valid si-snr: 2.17e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-25-49+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-25-27+00\nspeechbrain.utils.epoch_loop - Going into epoch 67\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.20s/it, train_loss=0.0285]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.29s/it]\nspeechbrain.utils.train_logger - epoch: 67, lr: 1.50e-04 - train si-snr: 2.85e-02 - valid si-snr: 2.12e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-26-12+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-25-49+00\nspeechbrain.utils.epoch_loop - Going into epoch 68\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|███████████████████████████| 1/1 [00:08<00:00,  8.36s/it, train_loss=0.028]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.43s/it]\nspeechbrain.utils.train_logger - epoch: 68, lr: 1.50e-04 - train si-snr: 2.80e-02 - valid si-snr: 2.05e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-26-34+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-26-12+00\nspeechbrain.utils.epoch_loop - Going into epoch 69\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.22s/it, train_loss=0.0274]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.43s/it]\nspeechbrain.utils.train_logger - epoch: 69, lr: 1.50e-04 - train si-snr: 2.74e-02 - valid si-snr: 1.98e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-26-56+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-26-34+00\nspeechbrain.utils.epoch_loop - Going into epoch 70\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.31s/it, train_loss=0.0266]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.37s/it]\nspeechbrain.utils.train_logger - epoch: 70, lr: 1.50e-04 - train si-snr: 2.66e-02 - valid si-snr: 1.93e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-27-19+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-26-56+00\nspeechbrain.utils.epoch_loop - Going into epoch 71\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.41s/it, train_loss=0.0261]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.20s/it]\nspeechbrain.utils.train_logger - epoch: 71, lr: 1.50e-04 - train si-snr: 2.61e-02 - valid si-snr: 1.90e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-27-41+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-27-19+00\nspeechbrain.utils.epoch_loop - Going into epoch 72\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.42s/it, train_loss=0.0258]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.43s/it]\nspeechbrain.utils.train_logger - epoch: 72, lr: 1.50e-04 - train si-snr: 2.58e-02 - valid si-snr: 1.89e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-28-04+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-27-41+00\nspeechbrain.utils.epoch_loop - Going into epoch 73\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.43s/it, train_loss=0.0257]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.36s/it]\nspeechbrain.utils.train_logger - epoch: 73, lr: 1.50e-04 - train si-snr: 2.57e-02 - valid si-snr: 1.86e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-28-26+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-28-04+00\nspeechbrain.utils.epoch_loop - Going into epoch 74\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.27s/it, train_loss=0.0254]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.24s/it]\nspeechbrain.utils.train_logger - epoch: 74, lr: 1.50e-04 - train si-snr: 2.54e-02 - valid si-snr: 1.80e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-28-48+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-28-26+00\nspeechbrain.utils.epoch_loop - Going into epoch 75\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:10<00:00, 10.39s/it, train_loss=0.0248]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.34s/it]\nspeechbrain.utils.train_logger - epoch: 75, lr: 1.50e-04 - train si-snr: 2.48e-02 - valid si-snr: 1.75e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-29-13+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-28-48+00\nspeechbrain.utils.epoch_loop - Going into epoch 76\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.20s/it, train_loss=0.0243]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.23s/it]\nspeechbrain.utils.train_logger - epoch: 76, lr: 1.50e-04 - train si-snr: 2.43e-02 - valid si-snr: 1.71e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-29-35+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-29-13+00\nspeechbrain.utils.epoch_loop - Going into epoch 77\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.19s/it, train_loss=0.0239]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.59s/it]\nspeechbrain.utils.train_logger - epoch: 77, lr: 1.50e-04 - train si-snr: 2.39e-02 - valid si-snr: 1.69e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-29-58+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-29-35+00\nspeechbrain.utils.epoch_loop - Going into epoch 78\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.24s/it, train_loss=0.0237]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.41s/it]\nspeechbrain.utils.train_logger - epoch: 78, lr: 1.50e-04 - train si-snr: 2.37e-02 - valid si-snr: 1.66e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-30-20+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-29-58+00\nspeechbrain.utils.epoch_loop - Going into epoch 79\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.16s/it, train_loss=0.0234]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.17s/it]\nspeechbrain.utils.train_logger - epoch: 79, lr: 1.50e-04 - train si-snr: 2.34e-02 - valid si-snr: 1.63e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-30-42+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-30-20+00\nspeechbrain.utils.epoch_loop - Going into epoch 80\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.41s/it, train_loss=0.0231]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.24s/it]\nspeechbrain.utils.train_logger - epoch: 80, lr: 1.50e-04 - train si-snr: 2.31e-02 - valid si-snr: 1.59e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-31-05+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-30-42+00\nspeechbrain.utils.epoch_loop - Going into epoch 81\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.17s/it, train_loss=0.0227]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.32s/it]\nspeechbrain.utils.train_logger - epoch: 81, lr: 1.50e-04 - train si-snr: 2.27e-02 - valid si-snr: 1.55e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-31-27+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-31-05+00\nspeechbrain.utils.epoch_loop - Going into epoch 82\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.33s/it, train_loss=0.0223]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.36s/it]\nspeechbrain.utils.train_logger - epoch: 82, lr: 1.50e-04 - train si-snr: 2.23e-02 - valid si-snr: 1.52e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-31-50+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-31-27+00\nspeechbrain.utils.epoch_loop - Going into epoch 83\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|███████████████████████████| 1/1 [00:08<00:00,  8.64s/it, train_loss=0.022]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.42s/it]\nspeechbrain.utils.train_logger - epoch: 83, lr: 1.50e-04 - train si-snr: 2.20e-02 - valid si-snr: 1.49e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-32-13+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-31-50+00\nspeechbrain.utils.epoch_loop - Going into epoch 84\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.30s/it, train_loss=0.0217]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.42s/it]\nspeechbrain.utils.train_logger - epoch: 84, lr: 1.50e-04 - train si-snr: 2.17e-02 - valid si-snr: 1.47e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-32-35+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-32-13+00\nspeechbrain.utils.epoch_loop - Going into epoch 85\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.31s/it, train_loss=0.0215]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.24s/it]\nspeechbrain.utils.train_logger - epoch: 85, lr: 1.50e-04 - train si-snr: 2.15e-02 - valid si-snr: 1.44e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-32-57+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-32-35+00\nspeechbrain.utils.epoch_loop - Going into epoch 86\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.33s/it, train_loss=0.0212]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.53s/it]\nspeechbrain.utils.train_logger - epoch: 86, lr: 1.50e-04 - train si-snr: 2.12e-02 - valid si-snr: 1.41e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-33-20+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-32-57+00\nspeechbrain.utils.epoch_loop - Going into epoch 87\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.33s/it, train_loss=0.0209]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.48s/it]\nspeechbrain.utils.train_logger - epoch: 87, lr: 1.50e-04 - train si-snr: 2.09e-02 - valid si-snr: 1.38e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-33-43+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-33-20+00\nspeechbrain.utils.epoch_loop - Going into epoch 88\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.19s/it, train_loss=0.0206]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.24s/it]\nspeechbrain.utils.train_logger - epoch: 88, lr: 1.50e-04 - train si-snr: 2.06e-02 - valid si-snr: 1.36e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-34-05+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-33-43+00\nspeechbrain.utils.epoch_loop - Going into epoch 89\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.97s/it, train_loss=0.0204]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.46s/it]\nspeechbrain.utils.train_logger - epoch: 89, lr: 1.50e-04 - train si-snr: 2.04e-02 - valid si-snr: 1.34e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-34-27+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-34-05+00\nspeechbrain.utils.epoch_loop - Going into epoch 90\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.72s/it, train_loss=0.0202]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.34s/it]\nspeechbrain.utils.train_logger - epoch: 90, lr: 1.50e-04 - train si-snr: 2.02e-02 - valid si-snr: 1.32e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-34-50+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-34-27+00\nspeechbrain.utils.epoch_loop - Going into epoch 91\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|████████████████████████████| 1/1 [00:08<00:00,  8.42s/it, train_loss=0.02]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.46s/it]\nspeechbrain.utils.train_logger - epoch: 91, lr: 1.50e-04 - train si-snr: 2.00e-02 - valid si-snr: 1.29e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-35-13+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-34-50+00\nspeechbrain.utils.epoch_loop - Going into epoch 92\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.35s/it, train_loss=0.0197]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.28s/it]\nspeechbrain.utils.train_logger - epoch: 92, lr: 1.50e-04 - train si-snr: 1.97e-02 - valid si-snr: 1.27e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-35-35+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-35-13+00\nspeechbrain.utils.epoch_loop - Going into epoch 93\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.38s/it, train_loss=0.0195]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.33s/it]\nspeechbrain.utils.train_logger - epoch: 93, lr: 1.50e-04 - train si-snr: 1.95e-02 - valid si-snr: 1.25e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-35-58+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-35-35+00\nspeechbrain.utils.epoch_loop - Going into epoch 94\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.44s/it, train_loss=0.0193]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.44s/it]\nspeechbrain.utils.train_logger - epoch: 94, lr: 1.50e-04 - train si-snr: 1.93e-02 - valid si-snr: 1.24e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-36-21+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-35-58+00\nspeechbrain.utils.epoch_loop - Going into epoch 95\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.13s/it, train_loss=0.0192]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.52s/it]\nspeechbrain.utils.train_logger - epoch: 95, lr: 1.50e-04 - train si-snr: 1.92e-02 - valid si-snr: 1.22e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-36-43+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-36-21+00\nspeechbrain.utils.epoch_loop - Going into epoch 96\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|███████████████████████████| 1/1 [00:08<00:00,  8.07s/it, train_loss=0.019]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.25s/it]\nspeechbrain.utils.train_logger - epoch: 96, lr: 1.50e-04 - train si-snr: 1.90e-02 - valid si-snr: 1.21e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-37-05+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-36-43+00\nspeechbrain.utils.epoch_loop - Going into epoch 97\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.41s/it, train_loss=0.0189]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.13s/it]\nspeechbrain.utils.train_logger - epoch: 97, lr: 1.50e-04 - train si-snr: 1.89e-02 - valid si-snr: 1.19e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-37-27+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-37-05+00\nspeechbrain.utils.epoch_loop - Going into epoch 98\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.36s/it, train_loss=0.0187]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.67s/it]\nspeechbrain.utils.train_logger - epoch: 98, lr: 1.50e-04 - train si-snr: 1.87e-02 - valid si-snr: 1.18e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-37-50+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-37-27+00\nspeechbrain.utils.epoch_loop - Going into epoch 99\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.18s/it, train_loss=0.0186]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.32s/it]\nspeechbrain.utils.train_logger - epoch: 99, lr: 1.50e-04 - train si-snr: 1.86e-02 - valid si-snr: 1.17e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-38-12+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-37-50+00\nspeechbrain.utils.epoch_loop - Going into epoch 100\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.33s/it, train_loss=0.0185]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.33s/it]\nspeechbrain.utils.train_logger - epoch: 100, lr: 1.50e-04 - train si-snr: 1.85e-02 - valid si-snr: 1.16e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-38-35+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-38-12+00\nspeechbrain.utils.epoch_loop - Going into epoch 101\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.06s/it, train_loss=0.0184]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.42s/it]\nspeechbrain.utils.train_logger - epoch: 101, lr: 1.50e-04 - train si-snr: 1.84e-02 - valid si-snr: 1.15e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-38-57+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-38-35+00\nspeechbrain.utils.epoch_loop - Going into epoch 102\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.43s/it, train_loss=0.0183]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.30s/it]\nspeechbrain.utils.train_logger - epoch: 102, lr: 1.50e-04 - train si-snr: 1.83e-02 - valid si-snr: 1.13e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-39-20+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-38-57+00\nspeechbrain.utils.epoch_loop - Going into epoch 103\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.19s/it, train_loss=0.0182]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.44s/it]\nspeechbrain.utils.train_logger - epoch: 103, lr: 1.50e-04 - train si-snr: 1.82e-02 - valid si-snr: 1.12e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-39-42+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-39-20+00\nspeechbrain.utils.epoch_loop - Going into epoch 104\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.33s/it, train_loss=0.0181]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.39s/it]\nspeechbrain.utils.train_logger - epoch: 104, lr: 1.50e-04 - train si-snr: 1.81e-02 - valid si-snr: 1.11e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-40-05+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-39-42+00\nspeechbrain.utils.epoch_loop - Going into epoch 105\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.08s/it, train_loss=0.0179]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.25s/it]\nspeechbrain.utils.train_logger - epoch: 105, lr: 1.50e-04 - train si-snr: 1.79e-02 - valid si-snr: 1.10e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-40-27+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-40-05+00\nspeechbrain.utils.epoch_loop - Going into epoch 106\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.34s/it, train_loss=0.0179]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.44s/it]\nspeechbrain.utils.train_logger - epoch: 106, lr: 1.50e-04 - train si-snr: 1.79e-02 - valid si-snr: 1.09e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-40-49+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-40-27+00\nspeechbrain.utils.epoch_loop - Going into epoch 107\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.65s/it, train_loss=0.0177]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.27s/it]\nspeechbrain.utils.train_logger - epoch: 107, lr: 1.50e-04 - train si-snr: 1.77e-02 - valid si-snr: 1.08e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-41-12+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-40-49+00\nspeechbrain.utils.epoch_loop - Going into epoch 108\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.38s/it, train_loss=0.0176]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.37s/it]\nspeechbrain.utils.train_logger - epoch: 108, lr: 1.50e-04 - train si-snr: 1.76e-02 - valid si-snr: 1.08e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-41-34+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-41-12+00\nspeechbrain.utils.epoch_loop - Going into epoch 109\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.06s/it, train_loss=0.0176]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.18s/it]\nspeechbrain.utils.train_logger - epoch: 109, lr: 1.50e-04 - train si-snr: 1.76e-02 - valid si-snr: 1.07e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-41-56+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-41-34+00\nspeechbrain.utils.epoch_loop - Going into epoch 110\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.33s/it, train_loss=0.0175]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.15s/it]\nspeechbrain.utils.train_logger - epoch: 110, lr: 1.50e-04 - train si-snr: 1.75e-02 - valid si-snr: 1.06e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-42-19+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-41-56+00\nspeechbrain.utils.epoch_loop - Going into epoch 111\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.36s/it, train_loss=0.0174]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.44s/it]\nspeechbrain.utils.train_logger - epoch: 111, lr: 1.50e-04 - train si-snr: 1.74e-02 - valid si-snr: 1.05e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-42-41+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-42-19+00\nspeechbrain.utils.epoch_loop - Going into epoch 112\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.24s/it, train_loss=0.0173]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.35s/it]\nspeechbrain.utils.train_logger - epoch: 112, lr: 1.50e-04 - train si-snr: 1.73e-02 - valid si-snr: 1.04e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-43-04+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-42-41+00\nspeechbrain.utils.epoch_loop - Going into epoch 113\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.27s/it, train_loss=0.0172]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.31s/it]\nspeechbrain.utils.train_logger - epoch: 113, lr: 1.50e-04 - train si-snr: 1.72e-02 - valid si-snr: 1.03e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-43-26+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-43-04+00\nspeechbrain.utils.epoch_loop - Going into epoch 114\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.73s/it, train_loss=0.0172]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.54s/it]\nspeechbrain.utils.train_logger - epoch: 114, lr: 1.50e-04 - train si-snr: 1.72e-02 - valid si-snr: 1.03e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-43-49+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-43-26+00\nspeechbrain.utils.epoch_loop - Going into epoch 115\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.29s/it, train_loss=0.0171]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.53s/it]\nspeechbrain.utils.train_logger - epoch: 115, lr: 1.50e-04 - train si-snr: 1.71e-02 - valid si-snr: 1.02e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-44-12+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-43-49+00\nspeechbrain.utils.epoch_loop - Going into epoch 116\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|███████████████████████████| 1/1 [00:08<00:00,  8.20s/it, train_loss=0.017]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.22s/it]\nspeechbrain.utils.train_logger - epoch: 116, lr: 1.50e-04 - train si-snr: 1.70e-02 - valid si-snr: 1.01e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-44-34+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-44-12+00\nspeechbrain.utils.epoch_loop - Going into epoch 117\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|███████████████████████████| 1/1 [00:08<00:00,  8.24s/it, train_loss=0.017]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.22s/it]\nspeechbrain.utils.train_logger - epoch: 117, lr: 1.50e-04 - train si-snr: 1.70e-02 - valid si-snr: 1.01e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-44-57+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-44-34+00\nspeechbrain.utils.epoch_loop - Going into epoch 118\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.33s/it, train_loss=0.0169]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.31s/it]\nspeechbrain.utils.train_logger - epoch: 118, lr: 1.50e-04 - train si-snr: 1.69e-02 - valid si-snr: 1.00e-02\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-45-19+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-44-57+00\nspeechbrain.utils.epoch_loop - Going into epoch 119\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.06s/it, train_loss=0.0168]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.25s/it]\nspeechbrain.utils.train_logger - epoch: 119, lr: 1.50e-04 - train si-snr: 1.68e-02 - valid si-snr: 9.99e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-45-41+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-45-19+00\nspeechbrain.utils.epoch_loop - Going into epoch 120\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.18s/it, train_loss=0.0168]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.10s/it]\nspeechbrain.utils.train_logger - epoch: 120, lr: 1.50e-04 - train si-snr: 1.68e-02 - valid si-snr: 9.95e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-46-03+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-45-41+00\nspeechbrain.utils.epoch_loop - Going into epoch 121\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.45s/it, train_loss=0.0168]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.26s/it]\nspeechbrain.utils.train_logger - epoch: 121, lr: 1.50e-04 - train si-snr: 1.68e-02 - valid si-snr: 9.92e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-46-26+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-46-03+00\nspeechbrain.utils.epoch_loop - Going into epoch 122\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.36s/it, train_loss=0.0167]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.51s/it]\nspeechbrain.utils.train_logger - epoch: 122, lr: 1.50e-04 - train si-snr: 1.67e-02 - valid si-snr: 9.89e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-46-48+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-46-26+00\nspeechbrain.utils.epoch_loop - Going into epoch 123\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.24s/it, train_loss=0.0167]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.17s/it]\nspeechbrain.utils.train_logger - epoch: 123, lr: 1.50e-04 - train si-snr: 1.67e-02 - valid si-snr: 9.86e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-47-11+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-46-48+00\nspeechbrain.utils.epoch_loop - Going into epoch 124\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.34s/it, train_loss=0.0167]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.45s/it]\nspeechbrain.utils.train_logger - epoch: 124, lr: 1.50e-04 - train si-snr: 1.67e-02 - valid si-snr: 9.83e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-47-33+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-47-11+00\nspeechbrain.utils.epoch_loop - Going into epoch 125\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.49s/it, train_loss=0.0166]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.27s/it]\nspeechbrain.utils.train_logger - epoch: 125, lr: 1.50e-04 - train si-snr: 1.66e-02 - valid si-snr: 9.80e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-47-56+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-47-33+00\nspeechbrain.utils.epoch_loop - Going into epoch 126\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.02s/it, train_loss=0.0166]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.32s/it]\nspeechbrain.utils.train_logger - epoch: 126, lr: 1.50e-04 - train si-snr: 1.66e-02 - valid si-snr: 9.78e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-48-18+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-47-56+00\nspeechbrain.utils.epoch_loop - Going into epoch 127\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.14s/it, train_loss=0.0166]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.23s/it]\nspeechbrain.utils.train_logger - epoch: 127, lr: 1.50e-04 - train si-snr: 1.66e-02 - valid si-snr: 9.75e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-48-40+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-48-18+00\nspeechbrain.utils.epoch_loop - Going into epoch 128\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.36s/it, train_loss=0.0165]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.43s/it]\nspeechbrain.utils.train_logger - epoch: 128, lr: 1.50e-04 - train si-snr: 1.65e-02 - valid si-snr: 9.72e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-49-05+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-48-40+00\nspeechbrain.utils.epoch_loop - Going into epoch 129\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.34s/it, train_loss=0.0165]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.38s/it]\nspeechbrain.utils.train_logger - epoch: 129, lr: 1.50e-04 - train si-snr: 1.65e-02 - valid si-snr: 9.70e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-49-27+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-49-05+00\nspeechbrain.utils.epoch_loop - Going into epoch 130\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.37s/it, train_loss=0.0165]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.37s/it]\nspeechbrain.utils.train_logger - epoch: 130, lr: 1.50e-04 - train si-snr: 1.65e-02 - valid si-snr: 9.67e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-49-50+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-49-27+00\nspeechbrain.utils.epoch_loop - Going into epoch 131\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.40s/it, train_loss=0.0165]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.36s/it]\nspeechbrain.utils.train_logger - epoch: 131, lr: 1.50e-04 - train si-snr: 1.65e-02 - valid si-snr: 9.64e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-50-12+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-49-50+00\nspeechbrain.utils.epoch_loop - Going into epoch 132\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.92s/it, train_loss=0.0164]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.97s/it]\nspeechbrain.utils.train_logger - epoch: 132, lr: 1.50e-04 - train si-snr: 1.64e-02 - valid si-snr: 9.62e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-50-34+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-50-12+00\nspeechbrain.utils.epoch_loop - Going into epoch 133\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.77s/it, train_loss=0.0164]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.87s/it]\nspeechbrain.utils.train_logger - epoch: 133, lr: 1.50e-04 - train si-snr: 1.64e-02 - valid si-snr: 9.59e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-50-57+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-50-34+00\nspeechbrain.utils.epoch_loop - Going into epoch 134\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.71s/it, train_loss=0.0164]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.94s/it]\nspeechbrain.utils.train_logger - epoch: 134, lr: 1.50e-04 - train si-snr: 1.64e-02 - valid si-snr: 9.57e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-51-19+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-50-57+00\nspeechbrain.utils.epoch_loop - Going into epoch 135\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.66s/it, train_loss=0.0164]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.89s/it]\nspeechbrain.utils.train_logger - epoch: 135, lr: 1.50e-04 - train si-snr: 1.64e-02 - valid si-snr: 9.54e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-51-40+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-51-19+00\nspeechbrain.utils.epoch_loop - Going into epoch 136\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.59s/it, train_loss=0.0163]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.84s/it]\nspeechbrain.utils.train_logger - epoch: 136, lr: 1.50e-04 - train si-snr: 1.63e-02 - valid si-snr: 9.52e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-52-01+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-51-40+00\nspeechbrain.utils.epoch_loop - Going into epoch 137\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.61s/it, train_loss=0.0163]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.64s/it]\nspeechbrain.utils.train_logger - epoch: 137, lr: 1.50e-04 - train si-snr: 1.63e-02 - valid si-snr: 9.49e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-52-22+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-52-01+00\nspeechbrain.utils.epoch_loop - Going into epoch 138\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.80s/it, train_loss=0.0163]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.81s/it]\nspeechbrain.utils.train_logger - epoch: 138, lr: 1.50e-04 - train si-snr: 1.63e-02 - valid si-snr: 9.47e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-52-44+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-52-22+00\nspeechbrain.utils.epoch_loop - Going into epoch 139\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.72s/it, train_loss=0.0163]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.69s/it]\nspeechbrain.utils.train_logger - epoch: 139, lr: 1.50e-04 - train si-snr: 1.63e-02 - valid si-snr: 9.44e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-53-05+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-52-44+00\nspeechbrain.utils.epoch_loop - Going into epoch 140\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.54s/it, train_loss=0.0162]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.87s/it]\nspeechbrain.utils.train_logger - epoch: 140, lr: 1.50e-04 - train si-snr: 1.62e-02 - valid si-snr: 9.42e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-53-27+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-53-05+00\nspeechbrain.utils.epoch_loop - Going into epoch 141\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.91s/it, train_loss=0.0162]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.81s/it]\nspeechbrain.utils.train_logger - epoch: 141, lr: 1.50e-04 - train si-snr: 1.62e-02 - valid si-snr: 9.40e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-53-48+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-53-27+00\nspeechbrain.utils.epoch_loop - Going into epoch 142\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.55s/it, train_loss=0.0162]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.83s/it]\nspeechbrain.utils.train_logger - epoch: 142, lr: 1.50e-04 - train si-snr: 1.62e-02 - valid si-snr: 9.37e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-54-10+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-53-48+00\nspeechbrain.utils.epoch_loop - Going into epoch 143\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.40s/it, train_loss=0.0162]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.72s/it]\nspeechbrain.utils.train_logger - epoch: 143, lr: 1.50e-04 - train si-snr: 1.62e-02 - valid si-snr: 9.35e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-54-31+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-54-10+00\nspeechbrain.utils.epoch_loop - Going into epoch 144\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.58s/it, train_loss=0.0162]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.70s/it]\nspeechbrain.utils.train_logger - epoch: 144, lr: 1.50e-04 - train si-snr: 1.62e-02 - valid si-snr: 9.32e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-54-52+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-54-31+00\nspeechbrain.utils.epoch_loop - Going into epoch 145\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.48s/it, train_loss=0.0161]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.88s/it]\nspeechbrain.utils.train_logger - epoch: 145, lr: 1.50e-04 - train si-snr: 1.61e-02 - valid si-snr: 9.30e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-55-14+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-54-52+00\nspeechbrain.utils.epoch_loop - Going into epoch 146\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:08<00:00,  8.60s/it, train_loss=0.0161]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.65s/it]\nspeechbrain.utils.train_logger - epoch: 146, lr: 1.50e-04 - train si-snr: 1.61e-02 - valid si-snr: 9.28e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-55-36+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-55-14+00\nspeechbrain.utils.epoch_loop - Going into epoch 147\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.75s/it, train_loss=0.0161]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.64s/it]\nspeechbrain.utils.train_logger - epoch: 147, lr: 1.50e-04 - train si-snr: 1.61e-02 - valid si-snr: 9.25e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-55-58+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-55-36+00\nspeechbrain.utils.epoch_loop - Going into epoch 148\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|██████████████████████████| 1/1 [00:07<00:00,  7.28s/it, train_loss=0.0161]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.99s/it]\nspeechbrain.utils.train_logger - epoch: 148, lr: 1.50e-04 - train si-snr: 1.61e-02 - valid si-snr: 9.23e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-56-19+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-55-58+00\nspeechbrain.utils.epoch_loop - Going into epoch 149\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|███████████████████████████| 1/1 [00:07<00:00,  7.62s/it, train_loss=0.016]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.86s/it]\nspeechbrain.utils.train_logger - epoch: 149, lr: 1.50e-04 - train si-snr: 1.60e-02 - valid si-snr: 9.21e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-56-40+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-56-19+00\nspeechbrain.utils.epoch_loop - Going into epoch 150\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2739955\n2749780\ntorch.Size([1, 2, 2739955])\n------Compute forward---------\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\nin compute objective rn\ntorch.Size([1, 2, 2739955, 2])\ntorch.Size([1, 2, 2739955, 2])\n100%|███████████████████████████| 1/1 [00:07<00:00,  7.60s/it, train_loss=0.016]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n2648190\n2655572\ntorch.Size([1, 2, 2648190])\n------Compute forward---------\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\nin compute objective rn\ntorch.Size([1, 2, 2648190, 2])\ntorch.Size([1, 2, 2648190, 2])\n100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.66s/it]\nspeechbrain.utils.train_logger - epoch: 150, lr: 1.50e-04 - train si-snr: 1.60e-02 - valid si-snr: 9.19e-03\nspeechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-57-02+00\nspeechbrain.utils.checkpoints - Deleted checkpoint in /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-56-40+00\nspeechbrain.utils.checkpoints - Loading a checkpoint from /kaggle/working/results/demucs/1234/save/CKPT+2025-04-05+21-57-02+00\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n3358535\n3368276\ntorch.Size([1, 2, 3358535])\n------Compute forward---------\ntorch.Size([1, 2, 3358535, 2])\ntorch.Size([1, 2, 3358535, 2])\nin compute objective rn\ntorch.Size([1, 2, 3358535, 2])\ntorch.Size([1, 2, 3358535, 2])\ntorch.Size([2, 3358535])\ntorch.Size([2, 3358535])\ntorch.Size([2, 3358535])\n100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.99s/it]\nspeechbrain.utils.train_logger - Epoch loaded: 150 - test si-snr: 1.00e-02\n  0%|                                                     | 0/1 [00:00<?, ?it/s]\n3358535\n3368276\ntorch.Size([1, 2, 3358535])\n------Compute forward---------\ntorch.Size([1, 2, 3358535, 2])\ntorch.Size([1, 2, 3358535, 2])\ntorch.Size([1, 3358535, 2, 2])\ntorch.Size([1, 3358535, 2, 2])\n---------------------\ntorch.Size([1, 2, 3358535])\ntorch.Size([1, 3358535, 2, 2])\n/kaggle/working/train.py:380: FutureWarning: mir_eval.separation.bss_eval_sources\n\tDeprecated as of mir_eval version 0.8.\n\tIt will be removed in mir_eval version 0.9.\n  sdr, _, _, _ = bss_eval_sources(\n/kaggle/working/train.py:385: FutureWarning: mir_eval.separation.bss_eval_sources\n\tDeprecated as of mir_eval version 0.8.\n\tIt will be removed in mir_eval version 0.9.\n  sdr_baseline, _, _, _ = bss_eval_sources(\n100%|█████████████████████████████████████████████| 1/1 [00:46<00:00, 46.17s/it]\n__main__ - Mean SISNR is -75.69183349609375\n__main__ - Mean SISNRi is -75.67325592041016\n__main__ - Mean SDR is -26.343272083433163\n__main__ - Mean SDRi is -26.33461187842952\n","output_type":"stream"}],"execution_count":255},{"cell_type":"code","source":"import musdb\nimport torchaudio\nimport numpy as np\nfrom torch.utils.data import Dataset\nimport speechbrain as sb\nimport psutil\n\nclass LazyMusDBDataset(Dataset):\n    def __init__(self, root, subset=\"train\", split=None, target_sr=8000, chunk_size=15):\n        \"\"\"\n        True lazy-loading for MUSDB\n        :param chunk_size: in seconds\n        \"\"\"\n        self.db = musdb.DB(root=root, subsets=subset, split=split, is_wav=False)\n        self.target_sr = target_sr\n        self.chunk_size = chunk_size\n        self.tracks = [{\n            \"path\": track.path,\n            \"duration\": track.duration,\n            \"rate\": track.rate,\n            \"stem_id\": track.stem_id  # Needed for STEM access\n        } for track in self.db.tracks]\n\n    def __len__(self):\n        return len(self.tracks)\n\n    def __getitem__(self, idx):\n        track_info = self.tracks[idx]\n        \n        # Load chunk directly from disk without full track loading\n        def load_stem_chunk(stem_name, random_chunk=True):\n            # MUSDB's internal lazy loading\n            track = self.db.tracks[idx]\n            if stem_name == \"mix\":\n                source = track\n            else:\n                source = track.targets[stem_name]\n            \n            # Calculate chunk bounds\n            if random_chunk:\n                max_start = int(track_info[\"duration\"] * track_info[\"rate\"]) - self.chunk_size * track_info[\"rate\"]\n                start = np.random.randint(0, max(max_start, 1))\n            else:\n                start = 0\n            stop = start + self.chunk_size * track_info[\"rate\"]\n            \n            # Load only the needed segment\n            audio = source.audio[start:stop]\n            \n            # Convert and resample\n            audio_tensor = torch.from_numpy(audio).float().permute(1, 0)\n            return torchaudio.functional.resample(\n                audio_tensor,\n                orig_freq=track_info[\"rate\"],\n                new_freq=self.target_sr\n            ).mean(dim=0, keepdim=False)\n\n        \n        # orig_sr = track.rate  # Original sample rate\n        \n        # chunk_size = orig_sr * chunk_size_seconds  # Convert chunk size to samples\n    \n        # resampled_chunks = []\n    \n        # for i in range(0, audio_tensor.shape[1], chunk_size):\n        #     chunk = audio_tensor[:, i:i + chunk_size]  # Extract chunk\n        #     resampled_chunk = torchaudio.functional.resample(chunk, orig_freq=orig_sr, new_freq=target_sr)\n        #     resampled_chunks.append(resampled_chunk)\n    \n        # # Concatenate back the processed chunks\n        # # print(\"PROCESSING CHUNKS\")\n        # resampled_audio = torch.cat(resampled_chunks, dim=1)\n        # # print(resampled_audio.shape)\n        # resampled_audio = resampled_audio.mean(dim=0, keepdim=False)\n        # # print(resampled_audio.shape)\n        # # print(resampled_audio.shape)\n        # return resampled_audio\n\n        return {\n            \"mix_sig\": load_stem_chunk(\"mix\"),\n            \"voc_sig\": load_stem_chunk(\"vocals\"),\n            \"inst_sig\": load_stem_chunk(\"accompaniment\"),\n            \"track_id\": track_info[\"stem_id\"]\n        }\n\n# Usage with SpeechBrain\ntrain_data = LazyMusDBDataset(db_path, subset=\"train\", split=\"train\")\nvalid_data = LazyMusDBDataset(db_path, subset=\"train\", split=\"valid\")\ntest_data = LazyMusDBDataset(db_path, subset=\"test\")\n\n# Create DataLoader\ntrain_loader = sb.dataio.dataloader.make_dataloader(\n    train_data,\n    batch_size=1,\n    collate_fn=sb.dataio.batch.PaddedBatch  # Handles variable lengths\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T21:58:07.525125Z","iopub.execute_input":"2025-04-05T21:58:07.525383Z","iopub.status.idle":"2025-04-05T21:58:25.402283Z","shell.execute_reply.started":"2025-04-05T21:58:07.525356Z","shell.execute_reply":"2025-04-05T21:58:25.401409Z"}},"outputs":[],"execution_count":256},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def convert_musdb_to_torch(track, target_sr=8000, chunk_size_seconds=1):\n#     \"\"\"\n#     Converts a musdb track to a PyTorch tensor with efficient resampling.\n\n#     Args:\n#         track: A musdb track object (e.g., `mus_train[0]`).\n#         target_sr (int): The target sampling rate for resampling.\n#         chunk_size_seconds (int): Number of seconds per processing chunk.\n\n#     Returns:\n#         torch.Tensor: The resampled waveform tensor of shape (num_channels, num_samples).\n#     \"\"\"\n#     # Convert to tensor and move channels first (PyTorch format)\n#     audio_tensor = torch.from_numpy(track.audio).float().permute(1, 0)  # Shape: (num_channels, num_samples)\n    \n#     orig_sr = track.rate  # Original sample rate\n    \n#     chunk_size = orig_sr * chunk_size_seconds  # Convert chunk size to samples\n\n#     resampled_chunks = []\n\n#     for i in range(0, audio_tensor.shape[1], chunk_size):\n#         chunk = audio_tensor[:, i:i + chunk_size]  # Extract chunk\n#         resampled_chunk = torchaudio.functional.resample(chunk, orig_freq=orig_sr, new_freq=target_sr)\n#         resampled_chunks.append(resampled_chunk)\n\n#     # Concatenate back the processed chunks\n#     resampled_audio = torch.cat(resampled_chunks, dim=1)\n\n#     return resampled_audio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T21:58:25.403922Z","iopub.execute_input":"2025-04-05T21:58:25.404298Z","iopub.status.idle":"2025-04-05T21:58:25.408062Z","shell.execute_reply.started":"2025-04-05T21:58:25.404258Z","shell.execute_reply":"2025-04-05T21:58:25.407364Z"}},"outputs":[],"execution_count":257},{"cell_type":"code","source":"# import soundfile as sf\n\n# def process_and_save_tracks(db, subset_name, output_dir):\n#     \"\"\"\n#     Process tracks from a musdb subset and save vocals, instrumentals, and mix as WAV files\n    \n#     Args:\n#         db: musdb DB object (train, valid, or test)\n#         subset_name: name of the subset ('train', 'valid', or 'test')\n#         output_dir: root directory where files should be saved\n#     \"\"\"\n#     # Create output directory if it doesn't exist\n#     subset_dir = os.path.join(output_dir, subset_name)\n#     os.makedirs(subset_dir, exist_ok=True)\n    \n#     for idx, track in enumerate(db):\n#         print(f\"Processing {subset_name} track {idx+1}/{len(db)}: {track.name}\")\n        \n#         # Get the audio data\n#         vocals = track.targets['vocals'].audio\n#         mix = track.audio\n#         instrumentals = track.targets['accompaniment'].audio\n        \n#         # # Create track-specific directory\n#         # track_dir = os.path.join(subset_dir, track.name)\n#         # os.makedirs(track_dir, exist_ok=True)\n        \n#         # Save files with appropriate names\n#         sf.write(os.path.join(subset_dir, f\"{track.name}_vocals.wav\"), vocals, track.rate)\n#         sf.write(os.path.join(subset_dir, f\"{track.name}_instrumentals.wav\"), instrumentals, track.rate)\n#         sf.write(os.path.join(subset_dir, f\"{track.name}_mix.wav\"), mix, track.rate)\n\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T21:58:25.409231Z","iopub.execute_input":"2025-04-05T21:58:25.409439Z","iopub.status.idle":"2025-04-05T21:58:25.429003Z","shell.execute_reply.started":"2025-04-05T21:58:25.409420Z","shell.execute_reply":"2025-04-05T21:58:25.428278Z"}},"outputs":[],"execution_count":258},{"cell_type":"code","source":"# output_dir = '/kaggle/working/musdb'\n# process_and_save_tracks(mus_train, \"train\", output_dir + '/train')\n# process_and_save_tracks(mus_valid, \"valid\", output_dir + '/valid')\n# process_and_save_tracks(mus_test, \"test\", output_dir + '/test')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T21:58:25.430040Z","iopub.execute_input":"2025-04-05T21:58:25.430331Z","iopub.status.idle":"2025-04-05T21:58:25.442218Z","shell.execute_reply.started":"2025-04-05T21:58:25.430299Z","shell.execute_reply":"2025-04-05T21:58:25.441535Z"}},"outputs":[],"execution_count":259},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# track = mus_train[0]\n# print(track)\n# print(track.audio.shape)\n# import torchaudio\n# import torch\n# import IPython.display as ipd\n# np.float_ = np.float64\n\n# audio_tensor = torch.from_numpy(track.audio).float()\n\n# # audio_tensor = audio_tensor.permute(1, 0)\n# # audio_tensor = audio_tensor.mean(dim=0, keepdim=True)\n# # print(audio_tensor.shape)\n# # mix_sig = torchaudio.functional.resample(torch.from_numpy(track.audio), track.rate, 8000)\n# mix_sig = convert_musdb_to_torch(track, 16000, chunk_size_seconds=1)\n# voc_sig = convert_musdb_to_torch(track.targets['vocals'], 16000, chunk_size_seconds=1)\n# inst_sig = convert_musdb_to_torch(track.targets['accompaniment'], 16000, chunk_size_seconds=1)\n# print(mix_sig)\n# print(mix_sig.shape)\n# # print(torch.Size(mix_sig))\n# ipd.Audio(mix_sig.numpy(), rate=16000)\n# ipd.Audio(voc_sig.numpy(), rate=16000)\n# ipd.Audio(inst_sig.numpy(), rate=16000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T21:58:25.443000Z","iopub.execute_input":"2025-04-05T21:58:25.443234Z","iopub.status.idle":"2025-04-05T21:58:25.455070Z","shell.execute_reply.started":"2025-04-05T21:58:25.443213Z","shell.execute_reply":"2025-04-05T21:58:25.454249Z"}},"outputs":[],"execution_count":260},{"cell_type":"code","source":"# import json\n# import torchaudio\n# from speechbrain.utils.data_utils import get_all_files\n\n# train_files = []\n# valid_files = []\n# test_files = []\n\n# def create_json(json_file, mus_obj):\n\n#   json_dict = {}\n#   for i, track in enumerate(mus_obj):\n#     if i % 10 == 0:\n#       print(i)\n\n#     file_name = track.name\n#     file_path = track.path\n#     file_rate = track.rate\n#     # file_audio = track.audio\n#     # file_vocal = track.targets['vocals'].audio\n#     # print(file_name)\n#     json_dict[file_name] = {\n#               \"file_path\": file_path,\n#               \"rate\": file_rate\n#       }\n#     # print(json_dict[file_name])\n\n#     with open(json_file, mode=\"w\") as json_f:\n#         json.dump(json_dict, json_f, indent=2)\n\n# # 80% for training\n# create_json(os.path.join(output_path, \"train.json\"), mus_train)\n# create_json(os.path.join(output_path, \"valid.json\"), mus_valid)\n# create_json(os.path.join(output_path, \"test.json\"), mus_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T21:58:25.455933Z","iopub.execute_input":"2025-04-05T21:58:25.456525Z","iopub.status.idle":"2025-04-05T21:58:25.470849Z","shell.execute_reply.started":"2025-04-05T21:58:25.456500Z","shell.execute_reply":"2025-04-05T21:58:25.470014Z"}},"outputs":[],"execution_count":261},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r file.zip /kaggle/working/results/convtasnet/1234/save","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T21:58:25.473068Z","iopub.execute_input":"2025-04-05T21:58:25.473316Z","iopub.status.idle":"2025-04-05T21:58:25.644551Z","shell.execute_reply.started":"2025-04-05T21:58:25.473296Z","shell.execute_reply":"2025-04-05T21:58:25.643360Z"}},"outputs":[{"name":"stdout","text":"\tzip warning: name not matched: /kaggle/working/results/convtasnet/1234/save\n\nzip error: Nothing to do! (try: zip -r file.zip . -i /kaggle/working/results/convtasnet/1234/save)\n","output_type":"stream"}],"execution_count":262}]}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9HeMa6CRWlY7lPJOdEOuM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mirchandani-mohnish/Musformer/blob/main/ConvAI_Musformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO List\n",
        "get the dataset\n",
        "1. ~~mount the drive~~\n",
        "2. ~~copy or use dataset directly from there ~~\n",
        "3. ~~make dataset usable ~~\n",
        "4. ~~make the dataset json file for speechbrain ~~\n",
        "5. make simple model run - one encoder transformer decoder architecture\n",
        "\n",
        "## March 21\n",
        "1. take one recipe from speechbrain recipes and reverse engineer it\n",
        "  - look at recipes once to do the same\n",
        "2. or take a small version of demucs\n",
        "  - research on demucs and see how you can build the same\n",
        "  - use the same to split against it"
      ],
      "metadata": {
        "id": "yM1w0AgFU9nn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from google.colab import drive\n",
        "# from pydrive.auth import GoogleAuth\n",
        "# from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "\n",
        "# Authenticate with Google Drive\n",
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleAuth().credentials\n",
        "# drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF7TarWEU9UI",
        "outputId": "4a8b99fb-15d6-4f3f-dd96-4dba1c49494b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/MyDrive/musdb18/musdb18 (2)/musdb18'\n",
        "reduced_dataset_path = '/content/drive/MyDrive/musdb18/musdb18'\n"
      ],
      "metadata": {
        "id": "Py6oc6loVqum"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install musdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsYpiXgyV7yC",
        "outputId": "d9b45e4b-35d1-4db7-e8b3-c1804ed6baeb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting musdb\n",
            "  Downloading musdb-0.4.2-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.11/dist-packages (from musdb) (2.0.2)\n",
            "Collecting stempeg>=0.2.3 (from musdb)\n",
            "  Downloading stempeg-0.2.3-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting pyaml (from musdb)\n",
            "  Downloading pyaml-25.1.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from musdb) (4.67.1)\n",
            "Collecting ffmpeg-python>=0.2.0 (from stempeg>=0.2.3->musdb)\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml->musdb) (6.0.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python>=0.2.0->stempeg>=0.2.3->musdb) (1.0.0)\n",
            "Downloading musdb-0.4.2-py2.py3-none-any.whl (13 kB)\n",
            "Downloading stempeg-0.2.3-py3-none-any.whl (963 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-25.1.0-py3-none-any.whl (26 kB)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyaml, ffmpeg-python, stempeg, musdb\n",
            "Successfully installed ffmpeg-python-0.2.0 musdb-0.4.2 pyaml-25.1.0 stempeg-0.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "np.float_ = np.float64\n",
        "import musdb\n",
        "\n",
        "MUS_DB_PATH = reduced_dataset_path\n",
        "\n",
        "mus = musdb.DB(root=MUS_DB_PATH)\n",
        "mus_train = musdb.DB(root=MUS_DB_PATH,subsets=\"train\", split=\"train\")\n",
        "mus_valid = musdb.DB(root=MUS_DB_PATH,subsets=\"train\", split=\"valid\")\n",
        "mus_test = musdb.DB(root=MUS_DB_PATH,subsets=\"test\")\n",
        "print(mus_train[0])\n",
        "print(mus_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoXdLPlPWH8Q",
        "outputId": "81b5762b-2d8b-4689-b8b1-0ed7b479e412"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANiMAL - Easy Tiger\n",
            "Arise - Run Run Run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Installing SpeechBrain via pip\n",
        "BRANCH = 'develop'\n",
        "!python -m pip install git+https://github.com/speechbrain/speechbrain.git@$BRANCH\n",
        "\n",
        "# Clone SpeechBrain repository\n",
        "!git clone https://github.com/speechbrain/speechbrain/"
      ],
      "metadata": {
        "id": "5ViJidLvXVi4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n"
      ],
      "metadata": {
        "id": "jUZxwtEIdxXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torchaudio\n",
        "from speechbrain.utils.data_utils import get_all_files\n",
        "\n",
        "train_files = []\n",
        "valid_files = []\n",
        "test_files = []\n",
        "\n",
        "def create_json(json_file, mus_obj):\n",
        "\n",
        "  json_dict = {}\n",
        "  for i, track in enumerate(mus_obj):\n",
        "    if i % 10 == 0:\n",
        "      print(i)\n",
        "\n",
        "    file_name = track.name\n",
        "    file_path = track.path\n",
        "    file_rate = track.rate\n",
        "    # file_audio = track.audio\n",
        "    # file_vocal = track.targets['vocals'].audio\n",
        "    # print(file_name)\n",
        "    json_dict[file_name] = {\n",
        "              \"file_path\": file_path,\n",
        "              \"rate\": file_rate\n",
        "      }\n",
        "    # print(json_dict[file_name])\n",
        "\n",
        "    with open(json_file, mode=\"w\") as json_f:\n",
        "        json.dump(json_dict, json_f, indent=2)\n",
        "\n",
        "# 80% for training\n",
        "create_json(\"train.json\", mus_train)\n",
        "create_json(\"valid.json\", mus_valid)\n",
        "create_json(\"test.json\", mus_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpCJqshDXWVw",
        "outputId": "203e93d6-8b7f-4ae9-e54b-1a5c2f7f123e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _speechbrain_save\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _speechbrain_load\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for save\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for load\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _save\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _recover\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DEMUCS V2 - https://github.com/facebookresearch/demucs/tree/v2?tab=readme-ov-file"
      ],
      "metadata": {
        "id": "lgeB83HMqous"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%file hparams_demucs.yaml\n",
        "\n",
        "# Seed for reproducibility\n",
        "seed: 1986\n",
        "__set_seed: !apply:torch.manual_seed [!ref <seed>]\n",
        "\n",
        "# Folder setup\n",
        "output_folder: !ref results/VocalSeparation/<seed>\n",
        "save_folder: !ref <output_folder>/save\n",
        "train_log: !ref <output_folder>/train_log.txt\n",
        "data_folder: !ref /content/drive/MyDrive/musdb18/musdb18/\n",
        "\n",
        "# Dataset paths\n",
        "train_annotation: train.json\n",
        "valid_annotation: valid.json\n",
        "test_annotation: test.json\n",
        "\n",
        "# Training parameters\n",
        "number_of_epochs: 100\n",
        "batch_size: 16\n",
        "lr: 0.0001\n",
        "lr_final: 0.00001\n",
        "\n",
        "# Dataloader options\n",
        "train_dataloader_opts:\n",
        "    batch_size: !ref <batch_size>\n",
        "    shuffle: True\n",
        "\n",
        "valid_dataloader_opts:\n",
        "    batch_size: !ref <batch_size>\n",
        "\n",
        "test_dataloader_opts:\n",
        "    batch_size: !ref <batch_size>\n",
        "\n",
        "# Model parameters\n",
        "input_size: 2  # Input channels (e.g., stereo audio)\n",
        "hidden_size: 3200  # Hidden size for LSTM/Linear layers\n",
        "num_layers: 2  # Number of bidirectional LSTM layers\n",
        "nhead: 8  # Number of attention heads (if using transformers)\n",
        "dropout: 0.1  # Dropout rate\n",
        "\n",
        "# Encoder parameters\n",
        "encoder_layers:\n",
        "    Encoder1:\n",
        "        in_channels: 2\n",
        "        out_channels: 100\n",
        "    Encoder7:\n",
        "        in_channels: 100\n",
        "        out_channels: 200\n",
        "    Encoder6:\n",
        "        in_channels: 1600\n",
        "        out_channels: 3200\n",
        "\n",
        "# Decoder parameters\n",
        "decoder_layers:\n",
        "    Decoder1:\n",
        "        in_channels: 100\n",
        "        out_channels: 8  # 4 * 2\n",
        "    Decoder2:\n",
        "        in_channels: 200\n",
        "        out_channels: 100\n",
        "    Decoder6:\n",
        "        in_channels: 3200\n",
        "        out_channels: 1600\n",
        "\n",
        "# Linear layer\n",
        "linear_layer:\n",
        "    in_features: 6400\n",
        "    out_features: 3200\n",
        "\n",
        "# Loss function\n",
        "loss: !new:speechbrain.nnet.loss.si_snr_loss\n",
        "\n",
        "# Optimizer\n",
        "opt_class: !name:torch.optim.Adam\n",
        "    lr: !ref <lr>\n",
        "\n",
        "# Learning rate scheduler\n",
        "lr_annealing: !new:speechbrain.nnet.schedulers.LinearScheduler\n",
        "    initial_value: !ref <lr>\n",
        "    final_value: !ref <lr_final>\n",
        "    epoch_count: !ref <number_of_epochs>\n",
        "\n",
        "# Checkpointer\n",
        "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
        "    checkpoints_dir: !ref <save_folder>\n",
        "    recoverables:\n",
        "        model: !ref <model>\n",
        "        counter: !ref <epoch_counter>\n",
        "\n",
        "# Epoch counter\n",
        "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
        "    limit: !ref <number_of_epochs>\n",
        "\n",
        "# Modules\n",
        "modules:\n",
        "    encoder: !new:torch.nn.ModuleDict\n",
        "        Encoder1: !new:speechbrain.nnet.CNN.Conv1d\n",
        "            out_channels: 100\n",
        "            kernel_size: 8\n",
        "            stride: 4\n",
        "            padding: \"same\"\n",
        "        Encoder7: !new:speechbrain.nnet.CNN.Conv1d\n",
        "            out_channels: 200\n",
        "            kernel_size: 3\n",
        "            stride: 1\n",
        "            padding: \"same\"\n",
        "        Encoder6: !new:speechbrain.nnet.CNN.Conv1d\n",
        "            out_channels: 3200\n",
        "            kernel_size: 8\n",
        "            stride: 4\n",
        "            padding: \"same\"\n",
        "\n",
        "    decoder: !new:torch.nn.ModuleDict\n",
        "        Decoder1: !new:speechbrain.nnet.CNN.ConvTranspose1d\n",
        "            in_channels: 100\n",
        "            out_channels: 8\n",
        "            kernel_size: 8\n",
        "            stride: 4\n",
        "            padding: \"same\"\n",
        "        Decoder2: !new:speechbrain.nnet.CNN.ConvTranspose1d\n",
        "            in_channels: 200\n",
        "            out_channels: 100\n",
        "            kernel_size: 3\n",
        "            stride: 1\n",
        "            padding: \"same\"\n",
        "        Decoder6: !new:speechbrain.nnet.CNN.ConvTranspose1d\n",
        "            in_channels: 3200\n",
        "            out_channels: 1600\n",
        "            kernel_size: 8\n",
        "            stride: 4\n",
        "            padding: \"same\"\n",
        "\n",
        "    linear: !new:speechbrain.nnet.linear.Linear\n",
        "        input_size: 6400\n",
        "        n_neurons: 3200\n",
        "\n",
        "    lstm: !new:torch.nn.LSTM\n",
        "        input_size: 3200\n",
        "        hidden_size: 3200\n",
        "        num_layers: 2\n",
        "        bidirectional: True\n",
        "        dropout: 0.1\n",
        "\n",
        "# Model\n",
        "model: !new:torch.nn.ModuleList\n",
        "    - - !ref <encoder>\n",
        "      - !ref <decoder>\n",
        "      - !ref <linear>\n",
        "      - !ref <lstm>"
      ],
      "metadata": {
        "id": "WVJyRJmHqrqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%file train_demucs.py\n",
        "\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"Recipe for training a sequence-to-sequence vocal separation system.\n",
        "The system employs a Transformer encoder, a decoder, and an attention mechanism\n",
        "between them.\n",
        "\n",
        "To run this recipe, do the following:\n",
        "> python train.py hparams/vocal_separation.yaml\n",
        "\n",
        "With the default hyperparameters, the system employs a Transformer encoder and decoder.\n",
        "The neural network is trained with the SI-SDR loss objective.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import logging\n",
        "import json\n",
        "import speechbrain as sb\n",
        "from hyperpyyaml import load_hyperpyyaml\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "# Brain class for vocal separation training\n",
        "class VocalSeparation(sb.Brain):\n",
        "    \"\"\"Class that manages the training loop. See speechbrain.core.Brain.\"\"\"\n",
        "\n",
        "    def compute_forward(self, batch, stage):\n",
        "        \"\"\"Runs all the computation of the vocal separation model. It returns the\n",
        "        separated vocals and music signals.\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        batch : PaddedBatch\n",
        "            This batch object contains all the relevant tensors for computation.\n",
        "        stage : sb.Stage\n",
        "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        vocals : torch.tensor\n",
        "            Separated vocals signal.\n",
        "        music : torch.tensor\n",
        "            Separated music signal.\n",
        "        \"\"\"\n",
        "        # Move the batch to the appropriate device\n",
        "        batch = batch.to(self.device)\n",
        "\n",
        "        # Unpack the batch\n",
        "        mixed_signal, _ = batch.mixed_signal\n",
        "\n",
        "        # Encoder: Convert waveform to latent representation\n",
        "        enc_output = self.modules.encoder(mixed_signal)\n",
        "\n",
        "        # Transformer: Process latent representation\n",
        "        transformer_output = self.modules.transformer(enc_output)\n",
        "\n",
        "        # Mask Estimation: Estimate masks for vocals and music\n",
        "        vocal_mask = torch.sigmoid(self.modules.vocal_mask(transformer_output))\n",
        "        music_mask = torch.sigmoid(self.modules.music_mask(transformer_output))\n",
        "\n",
        "        # Apply masks\n",
        "        vocals = transformer_output * vocal_mask\n",
        "        music = transformer_output * music_mask\n",
        "\n",
        "        # Decoder: Convert masked representation back to waveform\n",
        "        vocals = self.modules.decoder(vocals)\n",
        "        music = self.modules.decoder(music)\n",
        "\n",
        "        return vocals, music\n",
        "\n",
        "    def compute_objectives(self, predictions, batch, stage):\n",
        "        \"\"\"Computes the loss given the predicted and targeted outputs.\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        predictions : tuple\n",
        "            The output tensor from `compute_forward` (vocals, music).\n",
        "        batch : PaddedBatch\n",
        "            This batch object contains all the relevant tensors for computation.\n",
        "        stage : sb.Stage\n",
        "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        loss : torch.Tensor\n",
        "            A one-element tensor used for backpropagating the gradient.\n",
        "        \"\"\"\n",
        "        # Unpack predictions\n",
        "        vocals_pred, music_pred = predictions\n",
        "\n",
        "        # Unpack targets\n",
        "        vocals_target, _ = batch.vocals\n",
        "        music_target, _ = batch.music\n",
        "\n",
        "        # Compute SI-SDR loss for vocals and music\n",
        "        loss_vocals = self.hparams.loss(vocals_pred, vocals_target)\n",
        "        loss_music = self.hparams.loss(music_pred, music_target)\n",
        "\n",
        "        # Combine losses\n",
        "        loss = loss_vocals + loss_music\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def on_stage_end(self, stage, stage_loss, epoch):\n",
        "        \"\"\"Gets called at the end of an epoch.\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        stage : sb.Stage\n",
        "            One of sb.Stage.TRAIN, sb.Stage.VALID, sb.Stage.TEST\n",
        "        stage_loss : float\n",
        "            The average loss for all of the data processed in this stage.\n",
        "        epoch : int\n",
        "            The currently-starting epoch. This is passed\n",
        "            `None` during the test stage.\n",
        "        \"\"\"\n",
        "        # Store the train loss until the validation stage.\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            self.train_stats = {\"loss\": stage_loss}\n",
        "\n",
        "        # Perform end-of-iteration things, like annealing, logging, etc.\n",
        "        elif stage == sb.Stage.VALID:\n",
        "            # Update learning rate\n",
        "            old_lr, new_lr = self.hparams.lr_annealing(epoch)\n",
        "            sb.nnet.schedulers.update_learning_rate(self.optimizer, new_lr)\n",
        "\n",
        "            # The train_logger writes a summary to stdout and to the logfile.\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                stats_meta={\"epoch\": epoch, \"lr\": old_lr},\n",
        "                train_stats=self.train_stats,\n",
        "                valid_stats={\"loss\": stage_loss},\n",
        "            )\n",
        "\n",
        "            # Save the current checkpoint and delete previous checkpoints.\n",
        "            self.checkpointer.save_and_keep_only(\n",
        "                meta={\"loss\": stage_loss}, min_keys=[\"loss\"]\n",
        "            )\n",
        "\n",
        "        # We also write statistics about test data to stdout and to the logfile.\n",
        "        elif stage == sb.Stage.TEST:\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                stats_meta={\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
        "                test_stats={\"loss\": stage_loss},\n",
        "            )\n",
        "\n",
        "\n",
        "def dataio_prepare(hparams):\n",
        "    \"\"\"This function prepares the datasets to be used in the brain class.\n",
        "    It also defines the data processing pipeline through user-defined functions.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    hparams : dict\n",
        "        This dictionary is loaded from the `train.yaml` file, and it includes\n",
        "        all the hyperparameters needed for dataset construction and loading.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    datasets : dict\n",
        "        Dictionary containing \"train\", \"valid\", and \"test\" keys that correspond\n",
        "        to the DynamicItemDataset objects.\n",
        "    \"\"\"\n",
        "    # Define audio processing pipeline\n",
        "    @sb.utils.data_pipeline.takes(\"file_path\")\n",
        "    @sb.utils.data_pipeline.provides(\"mixed_signal\")\n",
        "    def audio_pipeline(file_path):\n",
        "        \"\"\"Processes the mixed audio signal.\"\"\"\n",
        "        mixed_signal = sb.dataio.dataio.read_audio(file_path)\n",
        "        yield mixed_signal\n",
        "\n",
        "    # Load JSON manifest files\n",
        "    datasets = {}\n",
        "    for dataset in [\"train\", \"valid\", \"test\"]:\n",
        "        with open(hparams[f\"{dataset}_annotation\"]) as f:\n",
        "            data = json.load(f)\n",
        "        datasets[dataset] = sb.dataio.dataset.DynamicItemDataset.from_dict(\n",
        "            data, dynamic_items=[audio_pipeline], output_keys=[\"id\", \"mixed_signal\"]\n",
        "        )\n",
        "\n",
        "    return datasets\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Reading command line arguments\n",
        "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
        "\n",
        "    # Load hyperparameters file with command-line overrides\n",
        "    with open(hparams_file) as fin:\n",
        "        hparams = load_hyperpyyaml(fin, overrides)\n",
        "\n",
        "    # Create experiment directory\n",
        "    sb.create_experiment_directory(\n",
        "        experiment_directory=hparams[\"output_folder\"],\n",
        "        hyperparams_to_save=hparams_file,\n",
        "        overrides=overrides,\n",
        "    )\n",
        "\n",
        "    # We can now directly create the datasets for training, valid, and test\n",
        "    datasets = dataio_prepare(hparams)\n",
        "\n",
        "    # Trainer initialization\n",
        "    vocal_separation_brain = VocalSeparation(\n",
        "        modules=hparams[\"modules\"],\n",
        "        opt_class=hparams[\"opt_class\"],\n",
        "        hparams=hparams,\n",
        "        run_opts=run_opts,\n",
        "        checkpointer=hparams[\"checkpointer\"],\n",
        "    )\n",
        "\n",
        "    # The `fit()` method iterates the training loop, calling the methods\n",
        "    # necessary to update the parameters of the model. Since all objects\n",
        "    # with changing state are managed by the Checkpointer, training can be\n",
        "    # stopped at any point, and will be resumed on next call.\n",
        "    vocal_separation_brain.fit(\n",
        "        vocal_separation_brain.hparams.epoch_counter,\n",
        "        datasets[\"train\"],\n",
        "        datasets[\"valid\"],\n",
        "        train_loader_kwargs=hparams[\"train_dataloader_opts\"],\n",
        "        valid_loader_kwargs=hparams[\"valid_dataloader_opts\"],\n",
        "    )\n",
        "\n",
        "    # Load best checkpoint for evaluation\n",
        "    test_stats = vocal_separation_brain.evaluate(\n",
        "        test_set=datasets[\"test\"],\n",
        "        min_key=\"loss\",\n",
        "        test_loader_kwargs=hparams[\"test_dataloader_opts\"],\n",
        "    )"
      ],
      "metadata": {
        "id": "kVFhXojFq0Gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete the output folder to start training from scratch\n",
        "# (and not from a previous checkpoint).\n",
        "!rm -rf ./results/DEMUCS/1986\n",
        "gg\n",
        "# Run Training\n",
        "!python train_demucs.py hparams_demucs.yaml --data_folder='/content/drive/MyDrive/musdb18/musdb18/' --device='cuda:0' --number_of_epochs=25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkzIxACzu92D",
        "outputId": "d3f22cd0-bed9-4024-f5c1-da5d505f73f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/train_demucs.py\", line 191, in <module>\n",
            "    hparams = load_hyperpyyaml(fin, overrides)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/hyperpyyaml/core.py\", line 157, in load_hyperpyyaml\n",
            "    yaml_stream = resolve_references(yaml_stream, overrides, overrides_must_match)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/hyperpyyaml/core.py\", line 325, in resolve_references\n",
            "    _walk_tree_and_resolve(\"root\", preview, preview, file_path)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/hyperpyyaml/core.py\", line 372, in _walk_tree_and_resolve\n",
            "    current_node[k] = _walk_tree_and_resolve(sub_key, sub_node, tree, file_path)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/hyperpyyaml/core.py\", line 366, in _walk_tree_and_resolve\n",
            "    current_node[i] = _walk_tree_and_resolve(sub_key, sub_node, tree, file_path)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/hyperpyyaml/core.py\", line 366, in _walk_tree_and_resolve\n",
            "    current_node[i] = _walk_tree_and_resolve(sub_key, sub_node, tree, file_path)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/hyperpyyaml/core.py\", line 385, in _walk_tree_and_resolve\n",
            "    current_node = recursive_resolve(\n",
            "                   ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/hyperpyyaml/core.py\", line 663, in recursive_resolve\n",
            "    value = deref(reference.strip(\"<>\"), full_tree, copy_mode)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/hyperpyyaml/core.py\", line 600, in deref\n",
            "    raise ValueError('The reference \"%s\" is not valid' % ref)\n",
            "ValueError: The reference \"encoder\" is not valid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Transformer Model"
      ],
      "metadata": {
        "id": "oCDLptgUYjnL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqoZojtOYixb",
        "outputId": "87dc2e57-f443-4af3-a746-8e43289a2754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hparams_transformer.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoC0bVvRYvr5",
        "outputId": "f56a58d9-4a7d-4b49-a3a4-806375fd8a56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train_transformer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pBx1VD9kuxPO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WSJmix\n"
      ],
      "metadata": {
        "id": "QF8JV99suyPW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vtwfEaWhw8Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/speechbrain/recipes/WSJ0Mix/ /content/wsjmix"
      ],
      "metadata": {
        "id": "KqyleqjKu1qp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3iNfcBxRw88n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%file hparams.yaml\n",
        "\n",
        "# ################################\n",
        "# Model: SepFormer for source separation\n",
        "# https://arxiv.org/abs/2010.13154\n",
        "# Dataset : Custom dataset\n",
        "# ################################\n",
        "#\n",
        "# Basic parameters\n",
        "# Seed needs to be set at top of yaml, before objects with parameters are made\n",
        "#\n",
        "seed: 1234\n",
        "__set_seed: !apply:speechbrain.utils.seed_everything [!ref <seed>]\n",
        "\n",
        "# Data params\n",
        "\n",
        "# e.g. '/yourpath/wsj0-mix/2speakers'\n",
        "# end with 2speakers for wsj0-2mix or 3speakers for wsj0-3mix\n",
        "data_folder: dataset_path\n",
        "\n",
        "# the path for wsj0/si_tr_s/ folder -- only needed if dynamic mixing is used\n",
        "# e.g. /yourpath/wsj0-processed/si_tr_s/\n",
        "# you need to convert the original wsj0 to 8k\n",
        "# you can do this conversion with the script ../meta/preprocess_dynamic_mixing.py\n",
        "base_folder_dm: /content/wsjmix/\n",
        "\n",
        "experiment_name: sepformer-custom\n",
        "output_folder: /content/results/<experiment_name>/<seed>\n",
        "train_log: !ref <output_folder>/train_log.txt\n",
        "save_folder: !ref <output_folder>/save\n",
        "train_data: train.json\n",
        "valid_data: valid.json\n",
        "test_data: test.json\n",
        "skip_prep: False\n",
        "\n",
        "\n",
        "# Experiment params\n",
        "precision: fp32 # bf16, fp16 or fp32\n",
        "num_spks: 2 # set to 3 for wsj0-3mix\n",
        "noprogressbar: False\n",
        "save_audio: True # Save estimated sources on disk\n",
        "sample_rate: 16000\n",
        "\n",
        "####################### Training Parameters ####################################\n",
        "N_epochs: 200\n",
        "batch_size: 1\n",
        "lr: 0.00015\n",
        "clip_grad_norm: 5\n",
        "loss_upper_lim: 999999  # this is the upper limit for an acceptable loss\n",
        "# if True, the training sequences are cut to a specified length\n",
        "limit_training_signal_len: False\n",
        "# this is the length of sequences if we choose to limit\n",
        "# the signal length of training sequences\n",
        "training_signal_len: 32000\n",
        "\n",
        "# Set it to True to dynamically create mixtures at training time\n",
        "dynamic_mixing: False\n",
        "\n",
        "# Parameters for data augmentation\n",
        "use_wavedrop: False\n",
        "use_speedperturb: False\n",
        "use_rand_shift: False\n",
        "min_shift: -8000\n",
        "max_shift: 8000\n",
        "\n",
        "# Speed perturbation\n",
        "speed_changes: [95, 100, 105]  # List of speed changes for time-stretching\n",
        "\n",
        "speed_perturb: !new:speechbrain.augment.time_domain.SpeedPerturb\n",
        "    orig_freq: !ref <sample_rate>\n",
        "    speeds: !ref <speed_changes>\n",
        "\n",
        "# Frequency drop: randomly drops a number of frequency bands to zero.\n",
        "drop_freq_low: 0  # Min frequency band dropout probability\n",
        "drop_freq_high: 1  # Max frequency band dropout probability\n",
        "drop_freq_count_low: 1  # Min number of frequency bands to drop\n",
        "drop_freq_count_high: 3  # Max number of frequency bands to drop\n",
        "drop_freq_width: 0.05  # Width of frequency bands to drop\n",
        "\n",
        "drop_freq: !new:speechbrain.augment.time_domain.DropFreq\n",
        "    drop_freq_low: !ref <drop_freq_low>\n",
        "    drop_freq_high: !ref <drop_freq_high>\n",
        "    drop_freq_count_low: !ref <drop_freq_count_low>\n",
        "    drop_freq_count_high: !ref <drop_freq_count_high>\n",
        "    drop_freq_width: !ref <drop_freq_width>\n",
        "\n",
        "# Time drop: randomly drops a number of temporal chunks.\n",
        "drop_chunk_count_low: 1  # Min number of audio chunks to drop\n",
        "drop_chunk_count_high: 5  # Max number of audio chunks to drop\n",
        "drop_chunk_length_low: 1000  # Min length of audio chunks to drop\n",
        "drop_chunk_length_high: 2000  # Max length of audio chunks to drop\n",
        "\n",
        "drop_chunk: !new:speechbrain.augment.time_domain.DropChunk\n",
        "    drop_length_low: !ref <drop_chunk_length_low>\n",
        "    drop_length_high: !ref <drop_chunk_length_high>\n",
        "    drop_count_low: !ref <drop_chunk_count_low>\n",
        "    drop_count_high: !ref <drop_chunk_count_high>\n",
        "\n",
        "# loss thresholding -- this thresholds the training loss\n",
        "threshold_byloss: True\n",
        "threshold: -30\n",
        "\n",
        "# Encoder parameters\n",
        "N_encoder_out: 256\n",
        "out_channels: 256\n",
        "kernel_size: 16\n",
        "kernel_stride: 8\n",
        "\n",
        "# Dataloader options\n",
        "# Set num_workers: 0 on MacOS due to behavior of the multiprocessing library\n",
        "dataloader_opts:\n",
        "    batch_size: !ref <batch_size>\n",
        "    num_workers: 3\n",
        "\n",
        "\n",
        "# Specifying the network\n",
        "Encoder: !new:speechbrain.lobes.models.dual_path.Encoder\n",
        "    kernel_size: !ref <kernel_size>\n",
        "    out_channels: !ref <N_encoder_out>\n",
        "\n",
        "\n",
        "SBtfintra: !new:speechbrain.lobes.models.dual_path.SBTransformerBlock\n",
        "    num_layers: 4\n",
        "    d_model: !ref <out_channels>\n",
        "    nhead: 8\n",
        "    d_ffn: 1024\n",
        "    dropout: 0\n",
        "    use_positional_encoding: True\n",
        "    norm_before: True\n",
        "\n",
        "SBtfinter: !new:speechbrain.lobes.models.dual_path.SBTransformerBlock\n",
        "    num_layers: 4\n",
        "    d_model: !ref <out_channels>\n",
        "    nhead: 8\n",
        "    d_ffn: 1024\n",
        "    dropout: 0\n",
        "    use_positional_encoding: True\n",
        "    norm_before: True\n",
        "\n",
        "MaskNet: !new:speechbrain.lobes.models.dual_path.Dual_Path_Model\n",
        "    num_spks: !ref <num_spks>\n",
        "    in_channels: !ref <N_encoder_out>\n",
        "    out_channels: !ref <out_channels>\n",
        "    num_layers: 1\n",
        "    K: 250\n",
        "    intra_model: !ref <SBtfintra>\n",
        "    inter_model: !ref <SBtfinter>\n",
        "    norm: ln\n",
        "    linear_layer_after_inter_intra: False\n",
        "    skip_around_intra: True\n",
        "\n",
        "Decoder: !new:speechbrain.lobes.models.dual_path.Decoder\n",
        "    in_channels: !ref <N_encoder_out>\n",
        "    out_channels: 1\n",
        "    kernel_size: !ref <kernel_size>\n",
        "    stride: !ref <kernel_stride>\n",
        "    bias: False\n",
        "\n",
        "optimizer: !name:torch.optim.Adam\n",
        "    lr: !ref <lr>\n",
        "    weight_decay: 0\n",
        "\n",
        "loss: !name:speechbrain.nnet.losses.get_si_snr_with_pitwrapper\n",
        "\n",
        "lr_scheduler: !new:speechbrain.nnet.schedulers.ReduceLROnPlateau\n",
        "    factor: 0.5\n",
        "    patience: 2\n",
        "    dont_halve_until_epoch: 85\n",
        "\n",
        "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
        "    limit: !ref <N_epochs>\n",
        "\n",
        "modules:\n",
        "    encoder: !ref <Encoder>\n",
        "    decoder: !ref <Decoder>\n",
        "    masknet: !ref <MaskNet>\n",
        "\n",
        "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
        "    checkpoints_dir: !ref <save_folder>\n",
        "    recoverables:\n",
        "        encoder: !ref <Encoder>\n",
        "        decoder: !ref <Decoder>\n",
        "        masknet: !ref <MaskNet>\n",
        "        counter: !ref <epoch_counter>\n",
        "        lr_scheduler: !ref <lr_scheduler>\n",
        "\n",
        "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
        "    save_file: !ref <train_log>\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEiXx1ZJvCc7",
        "outputId": "0028e9e6-5566-40ee-ec0c-db39733023bd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hparams.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file train.py\n",
        "#!/usr/bin/env/python3\n",
        "\"\"\"Recipe for training a neural speech separation system on the wsjmix\n",
        "dataset. The system employs an encoder, a decoder, and a masking network.\n",
        "\n",
        "To run this recipe, do the following:\n",
        "> python train.py hparams/sepformer.yaml\n",
        "> python train.py hparams/dualpath_rnn.yaml\n",
        "> python train.py hparams/convtasnet.yaml\n",
        "\n",
        "The experiment file is flexible enough to support different neural\n",
        "networks. By properly changing the parameter files, you can try\n",
        "different architectures. The script supports both wsj2mix and\n",
        "wsj3mix.\n",
        "\n",
        "\n",
        "Authors\n",
        " * Cem Subakan 2020\n",
        " * Mirco Ravanelli 2020\n",
        " * Samuele Cornell 2020\n",
        " * Mirko Bronzi 2020\n",
        " * Jianyuan Zhong 2020\n",
        "\"\"\"\n",
        "\n",
        "import csv\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "from hyperpyyaml import load_hyperpyyaml\n",
        "from tqdm import tqdm\n",
        "\n",
        "import speechbrain as sb\n",
        "import speechbrain.nnet.schedulers as schedulers\n",
        "from speechbrain.core import AMPConfig\n",
        "from speechbrain.utils.distributed import run_on_main\n",
        "from speechbrain.utils.logger import get_logger\n",
        "\n",
        "\n",
        "# Define training procedure\n",
        "class Separation(sb.Brain):\n",
        "    def compute_forward(self, mix, targets, stage, noise=None):\n",
        "        \"\"\"Forward computations from the mixture to the separated signals.\"\"\"\n",
        "\n",
        "        # Unpack lists and put tensors in the right device\n",
        "        mix, mix_lens = mix\n",
        "        mix, mix_lens = mix.to(self.device), mix_lens.to(self.device)\n",
        "\n",
        "        # Convert targets to tensor\n",
        "        targets = torch.cat(\n",
        "            [targets[i][0].unsqueeze(-1) for i in range(self.hparams.num_spks)],\n",
        "            dim=-1,\n",
        "        ).to(self.device)\n",
        "\n",
        "        # Add speech distortions\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            with torch.no_grad():\n",
        "                if self.hparams.use_speedperturb:\n",
        "                    mix, targets = self.add_speed_perturb(targets, mix_lens)\n",
        "\n",
        "                    mix = targets.sum(-1)\n",
        "\n",
        "                if self.hparams.use_wavedrop:\n",
        "                    mix = self.hparams.drop_chunk(mix, mix_lens)\n",
        "                    mix = self.hparams.drop_freq(mix)\n",
        "\n",
        "                if self.hparams.limit_training_signal_len:\n",
        "                    mix, targets = self.cut_signals(mix, targets)\n",
        "\n",
        "        # Separation\n",
        "        mix_w = self.hparams.Encoder(mix)\n",
        "        est_mask = self.hparams.MaskNet(mix_w)\n",
        "        mix_w = torch.stack([mix_w] * self.hparams.num_spks)\n",
        "        sep_h = mix_w * est_mask\n",
        "\n",
        "        # Decoding\n",
        "        est_source = torch.cat(\n",
        "            [\n",
        "                self.hparams.Decoder(sep_h[i]).unsqueeze(-1)\n",
        "                for i in range(self.hparams.num_spks)\n",
        "            ],\n",
        "            dim=-1,\n",
        "        )\n",
        "\n",
        "        # T changed after conv1d in encoder, fix it here\n",
        "        T_origin = mix.size(1)\n",
        "        T_est = est_source.size(1)\n",
        "        if T_origin > T_est:\n",
        "            est_source = F.pad(est_source, (0, 0, 0, T_origin - T_est))\n",
        "        else:\n",
        "            est_source = est_source[:, :T_origin, :]\n",
        "\n",
        "        return est_source, targets\n",
        "\n",
        "    def compute_objectives(self, predictions, targets):\n",
        "        \"\"\"Computes the sinr loss\"\"\"\n",
        "        return self.hparams.loss(targets, predictions)\n",
        "\n",
        "    def fit_batch(self, batch):\n",
        "        \"\"\"Trains one batch\"\"\"\n",
        "        amp = AMPConfig.from_name(self.precision)\n",
        "        should_step = (self.step % self.grad_accumulation_factor) == 0\n",
        "\n",
        "        # Unpacking batch list\n",
        "        mixture = batch.mix_sig\n",
        "        targets = [batch.s1_sig, batch.s2_sig]\n",
        "\n",
        "        if self.hparams.num_spks == 3:\n",
        "            targets.append(batch.s3_sig)\n",
        "\n",
        "        with self.no_sync(not should_step):\n",
        "            if self.use_amp:\n",
        "                with torch.autocast(\n",
        "                    dtype=amp.dtype, device_type=torch.device(self.device).type\n",
        "                ):\n",
        "                    predictions, targets = self.compute_forward(\n",
        "                        mixture, targets, sb.Stage.TRAIN\n",
        "                    )\n",
        "                    loss = self.compute_objectives(predictions, targets)\n",
        "\n",
        "                    # hard threshold the easy dataitems\n",
        "                    if self.hparams.threshold_byloss:\n",
        "                        th = self.hparams.threshold\n",
        "                        loss = loss[loss > th]\n",
        "                        if loss.nelement() > 0:\n",
        "                            loss = loss.mean()\n",
        "                    else:\n",
        "                        loss = loss.mean()\n",
        "\n",
        "                if (\n",
        "                    loss.nelement() > 0 and loss < self.hparams.loss_upper_lim\n",
        "                ):  # the fix for computational problems\n",
        "                    self.scaler.scale(loss).backward()\n",
        "                    if self.hparams.clip_grad_norm >= 0:\n",
        "                        self.scaler.unscale_(self.optimizer)\n",
        "                        torch.nn.utils.clip_grad_norm_(\n",
        "                            self.modules.parameters(),\n",
        "                            self.hparams.clip_grad_norm,\n",
        "                        )\n",
        "                    self.scaler.step(self.optimizer)\n",
        "                    self.scaler.update()\n",
        "                else:\n",
        "                    self.nonfinite_count += 1\n",
        "                    logger.info(\n",
        "                        \"infinite loss or empty loss! it happened {} times so far - skipping this batch\".format(\n",
        "                            self.nonfinite_count\n",
        "                        )\n",
        "                    )\n",
        "                    loss.data = torch.tensor(0.0).to(self.device)\n",
        "            else:\n",
        "                predictions, targets = self.compute_forward(\n",
        "                    mixture, targets, sb.Stage.TRAIN\n",
        "                )\n",
        "                loss = self.compute_objectives(predictions, targets)\n",
        "\n",
        "                if self.hparams.threshold_byloss:\n",
        "                    th = self.hparams.threshold\n",
        "                    loss = loss[loss > th]\n",
        "                    if loss.nelement() > 0:\n",
        "                        loss = loss.mean()\n",
        "                else:\n",
        "                    loss = loss.mean()\n",
        "\n",
        "                if (\n",
        "                    loss.nelement() > 0 and loss < self.hparams.loss_upper_lim\n",
        "                ):  # the fix for computational problems\n",
        "                    loss.backward()\n",
        "                    if self.hparams.clip_grad_norm >= 0:\n",
        "                        torch.nn.utils.clip_grad_norm_(\n",
        "                            self.modules.parameters(),\n",
        "                            self.hparams.clip_grad_norm,\n",
        "                        )\n",
        "                    self.optimizer.step()\n",
        "                else:\n",
        "                    self.nonfinite_count += 1\n",
        "                    logger.info(\n",
        "                        \"infinite loss or empty loss! it happened {} times so far - skipping this batch\".format(\n",
        "                            self.nonfinite_count\n",
        "                        )\n",
        "                    )\n",
        "                    loss.data = torch.tensor(0.0).to(self.device)\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        return loss.detach().cpu()\n",
        "\n",
        "    def evaluate_batch(self, batch, stage):\n",
        "        \"\"\"Computations needed for validation/test batches\"\"\"\n",
        "        snt_id = batch.id\n",
        "        mixture = batch.mix_sig\n",
        "        targets = [batch.s1_sig, batch.s2_sig]\n",
        "        if self.hparams.num_spks == 3:\n",
        "            targets.append(batch.s3_sig)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            predictions, targets = self.compute_forward(mixture, targets, stage)\n",
        "            loss = self.compute_objectives(predictions, targets)\n",
        "\n",
        "        # Manage audio file saving\n",
        "        if stage == sb.Stage.TEST and self.hparams.save_audio:\n",
        "            if hasattr(self.hparams, \"n_audio_to_save\"):\n",
        "                if self.hparams.n_audio_to_save > 0:\n",
        "                    self.save_audio(snt_id[0], mixture, targets, predictions)\n",
        "                    self.hparams.n_audio_to_save += -1\n",
        "            else:\n",
        "                self.save_audio(snt_id[0], mixture, targets, predictions)\n",
        "\n",
        "        return loss.mean().detach()\n",
        "\n",
        "    def on_stage_end(self, stage, stage_loss, epoch):\n",
        "        \"\"\"Gets called at the end of a epoch.\"\"\"\n",
        "        # Compute/store important stats\n",
        "        stage_stats = {\"si-snr\": stage_loss}\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            self.train_stats = stage_stats\n",
        "\n",
        "        # Perform end-of-iteration things, like annealing, logging, etc.\n",
        "        if stage == sb.Stage.VALID:\n",
        "            # Learning rate annealing\n",
        "            if isinstance(\n",
        "                self.hparams.lr_scheduler, schedulers.ReduceLROnPlateau\n",
        "            ):\n",
        "                current_lr, next_lr = self.hparams.lr_scheduler(\n",
        "                    [self.optimizer], epoch, stage_loss\n",
        "                )\n",
        "                schedulers.update_learning_rate(self.optimizer, next_lr)\n",
        "            else:\n",
        "                # if we do not use the reducelronplateau, we do not change the lr\n",
        "                current_lr = self.hparams.optimizer.optim.param_groups[0][\"lr\"]\n",
        "\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                stats_meta={\"epoch\": epoch, \"lr\": current_lr},\n",
        "                train_stats=self.train_stats,\n",
        "                valid_stats=stage_stats,\n",
        "            )\n",
        "            self.checkpointer.save_and_keep_only(\n",
        "                meta={\"si-snr\": stage_stats[\"si-snr\"]}, min_keys=[\"si-snr\"]\n",
        "            )\n",
        "        elif stage == sb.Stage.TEST:\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                stats_meta={\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
        "                test_stats=stage_stats,\n",
        "            )\n",
        "\n",
        "    def add_speed_perturb(self, targets, targ_lens):\n",
        "        \"\"\"Adds speed perturbation and random_shift to the input signals\"\"\"\n",
        "\n",
        "        min_len = -1\n",
        "        recombine = False\n",
        "\n",
        "        if self.hparams.use_speedperturb or self.hparams.use_rand_shift:\n",
        "            # Performing speed change (independently on each source)\n",
        "            new_targets = []\n",
        "            recombine = True\n",
        "\n",
        "            for i in range(targets.shape[-1]):\n",
        "                new_target = self.hparams.speed_perturb(targets[:, :, i])\n",
        "                new_targets.append(new_target)\n",
        "                if i == 0:\n",
        "                    min_len = new_target.shape[-1]\n",
        "                else:\n",
        "                    if new_target.shape[-1] < min_len:\n",
        "                        min_len = new_target.shape[-1]\n",
        "\n",
        "            if self.hparams.use_rand_shift:\n",
        "                # Performing random_shift (independently on each source)\n",
        "                recombine = True\n",
        "                for i in range(targets.shape[-1]):\n",
        "                    rand_shift = torch.randint(\n",
        "                        self.hparams.min_shift, self.hparams.max_shift, (1,)\n",
        "                    )\n",
        "                    new_targets[i] = new_targets[i].to(self.device)\n",
        "                    new_targets[i] = torch.roll(\n",
        "                        new_targets[i], shifts=(rand_shift[0],), dims=1\n",
        "                    )\n",
        "\n",
        "            # Re-combination\n",
        "            if recombine:\n",
        "                if self.hparams.use_speedperturb:\n",
        "                    targets = torch.zeros(\n",
        "                        targets.shape[0],\n",
        "                        min_len,\n",
        "                        targets.shape[-1],\n",
        "                        device=targets.device,\n",
        "                        dtype=torch.float,\n",
        "                    )\n",
        "                for i, new_target in enumerate(new_targets):\n",
        "                    targets[:, :, i] = new_targets[i][:, 0:min_len]\n",
        "\n",
        "        mix = targets.sum(-1)\n",
        "        return mix, targets\n",
        "\n",
        "    def cut_signals(self, mixture, targets):\n",
        "        \"\"\"This function selects a random segment of a given length within the mixture.\n",
        "        The corresponding targets are selected accordingly\"\"\"\n",
        "        randstart = torch.randint(\n",
        "            0,\n",
        "            1 + max(0, mixture.shape[1] - self.hparams.training_signal_len),\n",
        "            (1,),\n",
        "        ).item()\n",
        "        targets = targets[\n",
        "            :, randstart : randstart + self.hparams.training_signal_len, :\n",
        "        ]\n",
        "        mixture = mixture[\n",
        "            :, randstart : randstart + self.hparams.training_signal_len\n",
        "        ]\n",
        "        return mixture, targets\n",
        "\n",
        "    def reset_layer_recursively(self, layer):\n",
        "        \"\"\"Reinitializes the parameters of the neural networks\"\"\"\n",
        "        if hasattr(layer, \"reset_parameters\"):\n",
        "            layer.reset_parameters()\n",
        "        for child_layer in layer.modules():\n",
        "            if layer != child_layer:\n",
        "                self.reset_layer_recursively(child_layer)\n",
        "\n",
        "    def save_results(self, test_data):\n",
        "        \"\"\"This script computes the SDR and SI-SNR metrics and saves\n",
        "        them into a csv file\"\"\"\n",
        "\n",
        "        # This package is required for SDR computation\n",
        "        from mir_eval.separation import bss_eval_sources\n",
        "\n",
        "        # Create folders where to store audio\n",
        "        save_file = os.path.join(self.hparams.output_folder, \"test_results.csv\")\n",
        "\n",
        "        # Variable init\n",
        "        all_sdrs = []\n",
        "        all_sdrs_i = []\n",
        "        all_sisnrs = []\n",
        "        all_sisnrs_i = []\n",
        "        csv_columns = [\"snt_id\", \"sdr\", \"sdr_i\", \"si-snr\", \"si-snr_i\"]\n",
        "\n",
        "        test_loader = sb.dataio.dataloader.make_dataloader(\n",
        "            test_data, **self.hparams.dataloader_opts\n",
        "        )\n",
        "\n",
        "        with open(save_file, \"w\", newline=\"\", encoding=\"utf-8\") as results_csv:\n",
        "            writer = csv.DictWriter(results_csv, fieldnames=csv_columns)\n",
        "            writer.writeheader()\n",
        "\n",
        "            # Loop over all test sentence\n",
        "            with tqdm(test_loader, dynamic_ncols=True) as t:\n",
        "                for i, batch in enumerate(t):\n",
        "                    # Apply Separation\n",
        "                    mixture, mix_len = batch.mix_sig\n",
        "                    snt_id = batch.id\n",
        "                    targets = [batch.s1_sig, batch.s2_sig]\n",
        "                    if self.hparams.num_spks == 3:\n",
        "                        targets.append(batch.s3_sig)\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        predictions, targets = self.compute_forward(\n",
        "                            batch.mix_sig, targets, sb.Stage.TEST\n",
        "                        )\n",
        "\n",
        "                    # Compute SI-SNR\n",
        "                    sisnr = self.compute_objectives(predictions, targets)\n",
        "\n",
        "                    # Compute SI-SNR improvement\n",
        "                    mixture_signal = torch.stack(\n",
        "                        [mixture] * self.hparams.num_spks, dim=-1\n",
        "                    )\n",
        "                    mixture_signal = mixture_signal.to(targets.device)\n",
        "                    sisnr_baseline = self.compute_objectives(\n",
        "                        mixture_signal, targets\n",
        "                    )\n",
        "                    sisnr_i = sisnr - sisnr_baseline\n",
        "\n",
        "                    # Compute SDR\n",
        "                    sdr, _, _, _ = bss_eval_sources(\n",
        "                        targets[0].t().cpu().numpy(),\n",
        "                        predictions[0].t().detach().cpu().numpy(),\n",
        "                    )\n",
        "\n",
        "                    sdr_baseline, _, _, _ = bss_eval_sources(\n",
        "                        targets[0].t().cpu().numpy(),\n",
        "                        mixture_signal[0].t().detach().cpu().numpy(),\n",
        "                    )\n",
        "\n",
        "                    sdr_i = sdr.mean() - sdr_baseline.mean()\n",
        "\n",
        "                    # Saving on a csv file\n",
        "                    row = {\n",
        "                        \"snt_id\": snt_id[0],\n",
        "                        \"sdr\": sdr.mean(),\n",
        "                        \"sdr_i\": sdr_i,\n",
        "                        \"si-snr\": -sisnr.item(),\n",
        "                        \"si-snr_i\": -sisnr_i.item(),\n",
        "                    }\n",
        "                    writer.writerow(row)\n",
        "\n",
        "                    # Metric Accumulation\n",
        "                    all_sdrs.append(sdr.mean())\n",
        "                    all_sdrs_i.append(sdr_i.mean())\n",
        "                    all_sisnrs.append(-sisnr.item())\n",
        "                    all_sisnrs_i.append(-sisnr_i.item())\n",
        "\n",
        "                row = {\n",
        "                    \"snt_id\": \"avg\",\n",
        "                    \"sdr\": np.array(all_sdrs).mean(),\n",
        "                    \"sdr_i\": np.array(all_sdrs_i).mean(),\n",
        "                    \"si-snr\": np.array(all_sisnrs).mean(),\n",
        "                    \"si-snr_i\": np.array(all_sisnrs_i).mean(),\n",
        "                }\n",
        "                writer.writerow(row)\n",
        "\n",
        "        logger.info(\"Mean SISNR is {}\".format(np.array(all_sisnrs).mean()))\n",
        "        logger.info(\"Mean SISNRi is {}\".format(np.array(all_sisnrs_i).mean()))\n",
        "        logger.info(\"Mean SDR is {}\".format(np.array(all_sdrs).mean()))\n",
        "        logger.info(\"Mean SDRi is {}\".format(np.array(all_sdrs_i).mean()))\n",
        "\n",
        "    def save_audio(self, snt_id, mixture, targets, predictions):\n",
        "        \"saves the test audio (mixture, targets, and estimated sources) on disk\"\n",
        "\n",
        "        # Create output folder\n",
        "        save_path = os.path.join(self.hparams.save_folder, \"audio_results\")\n",
        "        if not os.path.exists(save_path):\n",
        "            os.mkdir(save_path)\n",
        "\n",
        "        for ns in range(self.hparams.num_spks):\n",
        "            # Estimated source\n",
        "            signal = predictions[0, :, ns]\n",
        "            signal = signal / signal.abs().max()\n",
        "            save_file = os.path.join(\n",
        "                save_path, \"item{}_source{}hat.wav\".format(snt_id, ns + 1)\n",
        "            )\n",
        "            torchaudio.save(\n",
        "                save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n",
        "            )\n",
        "\n",
        "            # Original source\n",
        "            signal = targets[0, :, ns]\n",
        "            signal = signal / signal.abs().max()\n",
        "            save_file = os.path.join(\n",
        "                save_path, \"item{}_source{}.wav\".format(snt_id, ns + 1)\n",
        "            )\n",
        "            torchaudio.save(\n",
        "                save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n",
        "            )\n",
        "\n",
        "        # Mixture\n",
        "        signal = mixture[0][0, :]\n",
        "        signal = signal / signal.abs().max()\n",
        "        save_file = os.path.join(save_path, \"item{}_mix.wav\".format(snt_id))\n",
        "        torchaudio.save(\n",
        "            save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n",
        "        )\n",
        "\n",
        "\n",
        "def dataio_prep(hparams):\n",
        "    \"\"\"Creates data processing pipeline\"\"\"\n",
        "\n",
        "    # 1. Define datasets\n",
        "    train_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n",
        "        csv_path=hparams[\"train_data\"],\n",
        "        replacements={\"data_root\": hparams[\"data_folder\"]},\n",
        "    )\n",
        "\n",
        "    valid_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n",
        "        csv_path=hparams[\"valid_data\"],\n",
        "        replacements={\"data_root\": hparams[\"data_folder\"]},\n",
        "    )\n",
        "\n",
        "    test_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n",
        "        csv_path=hparams[\"test_data\"],\n",
        "        replacements={\"data_root\": hparams[\"data_folder\"]},\n",
        "    )\n",
        "\n",
        "    datasets = [train_data, valid_data, test_data]\n",
        "\n",
        "    # 2. Provide audio pipelines\n",
        "\n",
        "    @sb.utils.data_pipeline.takes(\"mix_wav\")\n",
        "    @sb.utils.data_pipeline.provides(\"mix_sig\")\n",
        "    def audio_pipeline_mix(mix_wav):\n",
        "        mix_sig = sb.dataio.dataio.read_audio(mix_wav)\n",
        "        return mix_sig\n",
        "\n",
        "    @sb.utils.data_pipeline.takes(\"s1_wav\")\n",
        "    @sb.utils.data_pipeline.provides(\"s1_sig\")\n",
        "    def audio_pipeline_s1(s1_wav):\n",
        "        s1_sig = sb.dataio.dataio.read_audio(s1_wav)\n",
        "        return s1_sig\n",
        "\n",
        "    @sb.utils.data_pipeline.takes(\"s2_wav\")\n",
        "    @sb.utils.data_pipeline.provides(\"s2_sig\")\n",
        "    def audio_pipeline_s2(s2_wav):\n",
        "        s2_sig = sb.dataio.dataio.read_audio(s2_wav)\n",
        "        return s2_sig\n",
        "\n",
        "    if hparams[\"num_spks\"] == 3:\n",
        "\n",
        "        @sb.utils.data_pipeline.takes(\"s3_wav\")\n",
        "        @sb.utils.data_pipeline.provides(\"s3_sig\")\n",
        "        def audio_pipeline_s3(s3_wav):\n",
        "            s3_sig = sb.dataio.dataio.read_audio(s3_wav)\n",
        "            return s3_sig\n",
        "\n",
        "    sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_mix)\n",
        "    sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_s1)\n",
        "    sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_s2)\n",
        "    if hparams[\"num_spks\"] == 3:\n",
        "        sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_s3)\n",
        "        sb.dataio.dataset.set_output_keys(\n",
        "            datasets, [\"id\", \"mix_sig\", \"s1_sig\", \"s2_sig\", \"s3_sig\"]\n",
        "        )\n",
        "    else:\n",
        "        sb.dataio.dataset.set_output_keys(\n",
        "            datasets, [\"id\", \"mix_sig\", \"s1_sig\", \"s2_sig\"]\n",
        "        )\n",
        "\n",
        "    return train_data, valid_data, test_data\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load hyperparameters file with command-line overrides\n",
        "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
        "    with open(hparams_file, encoding=\"utf-8\") as fin:\n",
        "        hparams = load_hyperpyyaml(fin, overrides)\n",
        "\n",
        "    # Initialize ddp (useful only for multi-GPU DDP training)\n",
        "    sb.utils.distributed.ddp_init_group(run_opts)\n",
        "\n",
        "    # Logger info\n",
        "    logger = get_logger(__name__)\n",
        "\n",
        "    # Create experiment directory\n",
        "    sb.create_experiment_directory(\n",
        "        experiment_directory=hparams[\"output_folder\"],\n",
        "        hyperparams_to_save=hparams_file,\n",
        "        overrides=overrides,\n",
        "    )\n",
        "\n",
        "    # Update precision to bf16 if the device is CPU and precision is fp16\n",
        "    if run_opts.get(\"device\") == \"cpu\" and hparams.get(\"precision\") == \"fp16\":\n",
        "        hparams[\"precision\"] = \"bf16\"\n",
        "\n",
        "    # Check if wsj0_tr is set with dynamic mixing\n",
        "    if hparams[\"dynamic_mixing\"] and not os.path.exists(\n",
        "        hparams[\"base_folder_dm\"]\n",
        "    ):\n",
        "        raise ValueError(\n",
        "            \"Please, specify a valid base_folder_dm folder when using dynamic mixing\"\n",
        "        )\n",
        "\n",
        "    # Data preparation\n",
        "    # from prepare_data import prepare_wsjmix  # noqa\n",
        "\n",
        "    # run_on_main(\n",
        "    #     prepare_wsjmix,\n",
        "    #     kwargs={\n",
        "    #         \"datapath\": hparams[\"data_folder\"],\n",
        "    #         \"savepath\": hparams[\"save_folder\"],\n",
        "    #         \"n_spks\": hparams[\"num_spks\"],\n",
        "    #         \"skip_prep\": hparams[\"skip_prep\"],\n",
        "    #         \"fs\": hparams[\"sample_rate\"],\n",
        "    #     },\n",
        "    # )\n",
        "\n",
        "    # Create dataset objects\n",
        "    # if hparams[\"dynamic_mixing\"]:\n",
        "    #     from dynamic_mixing import dynamic_mix_data_prep\n",
        "\n",
        "    #     # if the base_folder for dm is not processed, preprocess them\n",
        "    #     if \"processed\" not in hparams[\"base_folder_dm\"]:\n",
        "    #         # if the processed folder already exists we just use it otherwise we do the preprocessing\n",
        "    #         if not os.path.exists(\n",
        "    #             os.path.normpath(hparams[\"base_folder_dm\"]) + \"_processed\"\n",
        "    #         ):\n",
        "    #             from preprocess_dynamic_mixing import resample_folder\n",
        "\n",
        "    #             print(\"Resampling the base folder\")\n",
        "    #             run_on_main(\n",
        "    #                 resample_folder,\n",
        "    #                 kwargs={\n",
        "    #                     \"input_folder\": hparams[\"base_folder_dm\"],\n",
        "    #                     \"output_folder\": os.path.normpath(\n",
        "    #                         hparams[\"base_folder_dm\"]\n",
        "    #                     )\n",
        "    #                     + \"_processed\",\n",
        "    #                     \"fs\": hparams[\"sample_rate\"],\n",
        "    #                     \"regex\": \"**/*.wav\",\n",
        "    #                 },\n",
        "    #             )\n",
        "    #             # adjust the base_folder_dm path\n",
        "    #             hparams[\"base_folder_dm\"] = (\n",
        "    #                 os.path.normpath(hparams[\"base_folder_dm\"]) + \"_processed\"\n",
        "    #             )\n",
        "    #         else:\n",
        "    #             print(\n",
        "    #                 \"Using the existing processed folder on the same directory as base_folder_dm\"\n",
        "    #             )\n",
        "    #             hparams[\"base_folder_dm\"] = (\n",
        "    #                 os.path.normpath(hparams[\"base_folder_dm\"]) + \"_processed\"\n",
        "    #             )\n",
        "\n",
        "    #     # Collecting the hparams for dynamic batching\n",
        "    #     dm_hparams = {\n",
        "    #         \"train_data\": hparams[\"train_data\"],\n",
        "    #         \"data_folder\": hparams[\"data_folder\"],\n",
        "    #         \"base_folder_dm\": hparams[\"base_folder_dm\"],\n",
        "    #         \"sample_rate\": hparams[\"sample_rate\"],\n",
        "    #         \"num_spks\": hparams[\"num_spks\"],\n",
        "    #         \"training_signal_len\": hparams[\"training_signal_len\"],\n",
        "    #         \"dataloader_opts\": hparams[\"dataloader_opts\"],\n",
        "    #     }\n",
        "    #     train_data = dynamic_mix_data_prep(dm_hparams)\n",
        "    #     _, valid_data, test_data = dataio_prep(hparams)\n",
        "    # else:\n",
        "    #     train_data, valid_data, test_data = dataio_prep(hparams)\n",
        "\n",
        "    # Load pretrained model if pretrained_separator is present in the yaml\n",
        "    if \"pretrained_separator\" in hparams:\n",
        "        run_on_main(hparams[\"pretrained_separator\"].collect_files)\n",
        "        hparams[\"pretrained_separator\"].load_collected()\n",
        "\n",
        "    # Brain class initialization\n",
        "    separator = Separation(\n",
        "        modules=hparams[\"modules\"],\n",
        "        opt_class=hparams[\"optimizer\"],\n",
        "        hparams=hparams,\n",
        "        run_opts=run_opts,\n",
        "        checkpointer=hparams[\"checkpointer\"],\n",
        "    )\n",
        "\n",
        "    # re-initialize the parameters if we don't use a pretrained model\n",
        "    if \"pretrained_separator\" not in hparams:\n",
        "        for module in separator.modules.values():\n",
        "            separator.reset_layer_recursively(module)\n",
        "\n",
        "    # Training\n",
        "    separator.fit(\n",
        "        separator.hparams.epoch_counter,\n",
        "        train_data,\n",
        "        valid_data,\n",
        "        train_loader_kwargs=hparams[\"dataloader_opts\"],\n",
        "        valid_loader_kwargs=hparams[\"dataloader_opts\"],\n",
        "    )\n",
        "\n",
        "    # Eval\n",
        "    separator.evaluate(test_data, min_key=\"si-snr\")\n",
        "    separator.save_results(test_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYyAACbjvcEG",
        "outputId": "63ccc432-09b6-4001-802b-21211071e474"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Archive\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "M_lDn36gXFNo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1V9z55d4Bxrz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "3ed772fe-cf36-4ae3-d757-1eca496d32ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/dakshsethi/musdb18?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 0.99G/4.37G [00:16<00:55, 65.3MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-367e099880a2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkagglehub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dakshsethi/musdb18\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Path: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/datasets.py\u001b[0m in \u001b[0;36mdataset_download\u001b[0;34m(handle, path, force_download)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_dataset_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloading Dataset: {h.to_url()} ...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mEXTRA_CONSOLE_BLOCK\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_resolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/registry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimpl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/resolver.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, handle, path, force_download)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mSome\u001b[0m \u001b[0mcases\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mmight\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCompetition\u001b[0m \u001b[0mdatasource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAPI\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbased\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \"\"\"\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Note handles are immutable, so _resolve() could not have altered our reference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/http_resolver.py\u001b[0m in \u001b[0;36m_resolve\u001b[0;34m(self, h, path, force_download)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;31m# First, we download the archive.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mapi_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marchive_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0m_extract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/clients.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(self, path, out_file, resource_handle, cached_path, extract_auto_compressed_file)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloading from {url}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0m_download_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhash_object\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/clients.py\u001b[0m in \u001b[0;36m_download_file\u001b[0;34m(response, out_file, size_read, total_size, hash_object)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit_divisor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhash_object\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    953\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0mflush_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_catcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;31m# StringIO doesn't like amt=None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m     def _raw_read(\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    471\u001b[0m                 \u001b[0;31m# clip the read to the \"end of response\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m                 \u001b[0mamt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1312\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#\n",
        "import kagglehub\n",
        "import shutil\n",
        "\n",
        "\n",
        "path = kagglehub.dataset_download(\"dakshsethi/musdb18\")\n",
        "\n",
        "print(\"Path: \", path)\n",
        "\n",
        "\n",
        "\n",
        "destination_path = \"/content/musdb\"\n",
        "db_path = \"/content/musdb\"\n",
        "# Move the dataset\n",
        "shutil.move(path, destination_path)\n",
        "shutil.move(destination_path + '/musdb18 (2)/musdb18', '/content/')\n",
        "db_path = '/content/musdb18'\n",
        "print(\"Dataset moved to:\", db_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "# Folder ID from the Google Drive link\n",
        "folder_id = \"1-9VnggJq4dTGzbWvLHZMWb5X1LYvofOi\"\n",
        "\n",
        "# Download the folder\n",
        "gdown.download_folder(f\"https://drive.google.com/drive/folders/19NaewsdYy8TgRn3AzbKLYiOeVh02GK9c\", quiet=False)\n",
        "\n",
        "print(\"Download complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eitPlsB6NWVj",
        "outputId": "17082daa-4294-4f40-afcc-f9f87657d2ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder 19agTXmjp5xB8MOJzxWOXCnVuKMSLhdhJ test\n",
            "Processing file 19fPvncz6GIowwfFiR8SUYPsZzYuXOl9- Arise - Run Run Run.stem.mp4\n",
            "Processing file 19gsWaBKuTdtKgXsISQxpnb1wv4iRX_a_ Ben Carrigan - We will Talk About It All Tonight.stem.mp4\n",
            "Processing file 19gIET2rx8fUBB1aH9I7jYtsYUvsyaIPe BKS - Bulldozer.stem.mp4\n",
            "Processing file 19k3TPpqbWkqDd6M-MrvLKR2P8_cb1Og7 Secretariat - Over The Top.stem.mp4\n",
            "Processing file 19dZ7AaK6UG9_vvGXLsvfJv4mgzndMVYO The Long Wait - Dark Horses.stem.mp4\n",
            "Retrieving folder 19WzbsAvBhC32b_gXHw_F9HU8zn9Pz2DS train\n",
            "Processing file 19m1LtGLsoliZup5S0I4Scz-1f_-UarS2 ANiMAL - Easy Tiger.stem.mp4\n",
            "Processing file 19ocHBeBVF_hRA0TtkBqDN2iUQzMikc29 AvaLuna - Waterduct.stem.mp4\n",
            "Processing file 19n0ML2L3ht993Ubked5RCkuomZ9mRgJK Bill Chudziak - Children Of No-one.stem.mp4\n",
            "Processing file 19zOIMlIZGXfZs9UpMOEdvhVPn7eK6xC7 Cnoc An Tursa - Bannockburn.stem.mp4\n",
            "Processing file 1A4uX-vCsJAEDKBt7vQXfykQDHqurT1i_ Leaf - Summerghost.stem.mp4\n",
            "Processing file 1A74DzKn1Ww6Ki39W2Vg326dkMITHQkG5 Music Delta - Disco.stem.mp4\n",
            "Processing file 1A3qSMrHZXF0-9Ekq4aOxkPJmpPO9Tst6 Port St Willow - Stay Even.stem.mp4\n",
            "Processing file 19sxrTFbmU9C0fKE0eL9E48m99CfgnjjG The Long Wait - Back Home To Blue.stem.mp4\n",
            "Processing file 1A54IpV6eAQuPtrFYjCkqpp5iJlAVsRNN The Wrong Uns - Rothko.stem.mp4\n",
            "Processing file 1A6Bx3TrTG8_UfuEbxsTF5__czolLNY44 Young Griffo - Blood To Bone.stem.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19fPvncz6GIowwfFiR8SUYPsZzYuXOl9-\n",
            "To: /content/musdb18/test/Arise - Run Run Run.stem.mp4\n",
            "100%|██████████| 35.3M/35.3M [00:00<00:00, 157MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19gsWaBKuTdtKgXsISQxpnb1wv4iRX_a_\n",
            "To: /content/musdb18/test/Ben Carrigan - We will Talk About It All Tonight.stem.mp4\n",
            "100%|██████████| 41.0M/41.0M [00:00<00:00, 90.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19gIET2rx8fUBB1aH9I7jYtsYUvsyaIPe\n",
            "To: /content/musdb18/test/BKS - Bulldozer.stem.mp4\n",
            "100%|██████████| 54.2M/54.2M [00:00<00:00, 114MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19k3TPpqbWkqDd6M-MrvLKR2P8_cb1Og7\n",
            "To: /content/musdb18/test/Secretariat - Over The Top.stem.mp4\n",
            "100%|██████████| 40.4M/40.4M [00:00<00:00, 45.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19dZ7AaK6UG9_vvGXLsvfJv4mgzndMVYO\n",
            "To: /content/musdb18/test/The Long Wait - Dark Horses.stem.mp4\n",
            "100%|██████████| 49.2M/49.2M [00:00<00:00, 100MB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19m1LtGLsoliZup5S0I4Scz-1f_-UarS2\n",
            "To: /content/musdb18/train/ANiMAL - Easy Tiger.stem.mp4\n",
            "100%|██████████| 33.1M/33.1M [00:00<00:00, 48.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19ocHBeBVF_hRA0TtkBqDN2iUQzMikc29\n",
            "To: /content/musdb18/train/AvaLuna - Waterduct.stem.mp4\n",
            "100%|██████████| 41.7M/41.7M [00:00<00:00, 177MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19n0ML2L3ht993Ubked5RCkuomZ9mRgJK\n",
            "To: /content/musdb18/train/Bill Chudziak - Children Of No-one.stem.mp4\n",
            "100%|██████████| 37.2M/37.2M [00:00<00:00, 110MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19zOIMlIZGXfZs9UpMOEdvhVPn7eK6xC7\n",
            "To: /content/musdb18/train/Cnoc An Tursa - Bannockburn.stem.mp4\n",
            "100%|██████████| 47.4M/47.4M [00:00<00:00, 84.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1A4uX-vCsJAEDKBt7vQXfykQDHqurT1i_\n",
            "To: /content/musdb18/train/Leaf - Summerghost.stem.mp4\n",
            "100%|██████████| 37.3M/37.3M [00:00<00:00, 71.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1A74DzKn1Ww6Ki39W2Vg326dkMITHQkG5\n",
            "To: /content/musdb18/train/Music Delta - Disco.stem.mp4\n",
            "100%|██████████| 20.1M/20.1M [00:00<00:00, 88.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1A3qSMrHZXF0-9Ekq4aOxkPJmpPO9Tst6\n",
            "To: /content/musdb18/train/Port St Willow - Stay Even.stem.mp4\n",
            "100%|██████████| 51.0M/51.0M [00:02<00:00, 23.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19sxrTFbmU9C0fKE0eL9E48m99CfgnjjG\n",
            "To: /content/musdb18/train/The Long Wait - Back Home To Blue.stem.mp4\n",
            "100%|██████████| 41.9M/41.9M [00:00<00:00, 80.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1A54IpV6eAQuPtrFYjCkqpp5iJlAVsRNN\n",
            "To: /content/musdb18/train/The Wrong Uns - Rothko.stem.mp4\n",
            "100%|██████████| 32.6M/32.6M [00:00<00:00, 106MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1A6Bx3TrTG8_UfuEbxsTF5__czolLNY44\n",
            "To: /content/musdb18/train/Young Griffo - Blood To Bone.stem.mp4\n",
            "100%|██████████| 41.0M/41.0M [00:00<00:00, 95.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install musdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8gnvwMGElQl",
        "outputId": "54c27701-5dd9-42b3-def8-836031ef5a6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: musdb in /usr/local/lib/python3.11/dist-packages (0.4.2)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.11/dist-packages (from musdb) (2.0.2)\n",
            "Requirement already satisfied: stempeg>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from musdb) (0.2.3)\n",
            "Requirement already satisfied: pyaml in /usr/local/lib/python3.11/dist-packages (from musdb) (25.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from musdb) (4.67.1)\n",
            "Requirement already satisfied: ffmpeg-python>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from stempeg>=0.2.3->musdb) (0.2.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml->musdb) (6.0.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python>=0.2.0->stempeg>=0.2.3->musdb) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pyenv/pyenv.git ~/.pyenv\n",
        "\n",
        "# Set the root for pyenv\n",
        "os.environ['PYENV_ROOT'] = os.path.expanduser(\"~/.pyenv\")\n",
        "# Prepend pyenv's bin folder to PATH\n",
        "os.environ['PATH'] = os.environ['PYENV_ROOT'] + '/bin:' + os.environ['PATH']\n",
        "\n",
        "# Confirm pyenv is callable\n",
        "!pyenv --version\n",
        "!apt-get install libffi-dev\n",
        "!pyenv install 3.8.13\n",
        "!pyenv global 3.8.13\n",
        "!pyenv exec pip install spleeter\n",
        "!pyenv exec spleeter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZvxzI1sE2lS",
        "outputId": "92f9a261-e5f4-49ad-c56c-987d7587a882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/root/.pyenv'...\n",
            "remote: Enumerating objects: 25664, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 25664 (delta 22), reused 19 (delta 15), pack-reused 25622 (from 3)\u001b[K\n",
            "Receiving objects: 100% (25664/25664), 5.90 MiB | 21.75 MiB/s, done.\n",
            "Resolving deltas: 100% (17226/17226), done.\n",
            "pyenv 2.5.4-1-gc579b636\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libffi-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 63.7 kB of archives.\n",
            "After this operation, 336 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libffi-dev amd64 3.4.2-4 [63.7 kB]\n",
            "Fetched 63.7 kB in 0s (181 kB/s)\n",
            "Selecting previously unselected package libffi-dev:amd64.\n",
            "(Reading database ... 125044 files and directories currently installed.)\n",
            "Preparing to unpack .../libffi-dev_3.4.2-4_amd64.deb ...\n",
            "Unpacking libffi-dev:amd64 (3.4.2-4) ...\n",
            "Setting up libffi-dev:amd64 (3.4.2-4) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Downloading Python-3.8.13.tar.xz...\n",
            "-> https://www.python.org/ftp/python/3.8.13/Python-3.8.13.tar.xz\n",
            "Installing Python-3.8.13...\n",
            "Installed Python-3.8.13 to /root/.pyenv/versions/3.8.13\n",
            "Collecting spleeter\n",
            "  Downloading spleeter-2.4.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 KB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpeg-python<0.3.0,>=0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Collecting tensorflow<2.10.0,>=2.5.0\n",
            "  Downloading tensorflow-2.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.8/511.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting norbert<0.3.0,>=0.2.1\n",
            "  Downloading norbert-0.2.1-py2.py3-none-any.whl (11 kB)\n",
            "Collecting typer<0.4.0,>=0.3.2\n",
            "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
            "Collecting httpx[http2]<0.20.0,>=0.19.0\n",
            "  Downloading httpx-0.19.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.3/77.3 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas<2.0.0,>=1.3.0\n",
            "  Downloading pandas-1.5.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting future\n",
            "  Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 KB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore<0.14.0,>=0.13.3\n",
            "  Downloading httpcore-0.13.7-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sniffio\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Collecting charset-normalizer\n",
            "  Downloading charset_normalizer-3.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 KB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986[idna2008]<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting certifi\n",
            "  Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 KB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2<5,>=3\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy\n",
            "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.8.1\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 KB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz>=2020.1\n",
            "  Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.9/507.9 KB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy>=1.20.3\n",
            "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting absl-py>=1.0.0\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 KB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
            "  Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 KB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h5py>=2.9.0\n",
            "  Downloading h5py-3.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /root/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (56.0.0)\n",
            "Collecting packaging\n",
            "  Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
            "  Downloading grpcio-1.70.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-pasta>=0.1.1\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting astunparse>=1.6.0\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting termcolor>=1.1.0\n",
            "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting protobuf<3.20,>=3.9.2\n",
            "  Downloading protobuf-3.19.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six>=1.12.0\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting libclang>=13.0.0\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=3.6.6\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Collecting keras-preprocessing>=1.1.1\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wrapt>=1.11.0\n",
            "  Downloading wrapt-1.17.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 KB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click<7.2.0,>=7.1.1\n",
            "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.8/82.8 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wheel<1.0,>=0.23.0\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe<7,>=6.0\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting hpack<5,>=4.0\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Collecting h11<0.13,>=0.11\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 KB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting anyio==3.*\n",
            "  Downloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna>=2.8\n",
            "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting exceptiongroup\n",
            "  Downloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting requests<3,>=2.21.0\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 KB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting werkzeug>=1.0.1\n",
            "  Downloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.0/228.0 KB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.8/210.8 KB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 KB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 KB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting importlib-metadata>=4.4\n",
            "  Downloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
            "Collecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 KB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting MarkupSafe>=2.1.1\n",
            "  Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)\n",
            "Collecting zipp>=3.20\n",
            "  Downloading zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.4.6\n",
            "  Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.1/83.1 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 KB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, rfc3986, pytz, libclang, keras, flatbuffers, zipp, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, sniffio, six, pyasn1, protobuf, packaging, opt-einsum, oauthlib, numpy, MarkupSafe, idna, hyperframe, hpack, h11, grpcio, gast, future, exceptiongroup, click, charset-normalizer, certifi, cachetools, absl-py, werkzeug, typer, scipy, rsa, requests, python-dateutil, pyasn1-modules, keras-preprocessing, importlib-metadata, h5py, h2, google-pasta, ffmpeg-python, astunparse, anyio, requests-oauthlib, pandas, norbert, markdown, httpcore, google-auth, httpx, google-auth-oauthlib, tensorboard, tensorflow, spleeter\n",
            "Successfully installed MarkupSafe-2.1.5 absl-py-2.1.0 anyio-3.7.1 astunparse-1.6.3 cachetools-5.5.2 certifi-2025.1.31 charset-normalizer-3.4.1 click-7.1.2 exceptiongroup-1.2.2 ffmpeg-python-0.2.0 flatbuffers-1.12 future-1.0.0 gast-0.4.0 google-auth-2.38.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.70.0 h11-0.12.0 h2-4.1.0 h5py-3.11.0 hpack-4.0.0 httpcore-0.13.7 httpx-0.19.0 hyperframe-6.0.1 idna-3.10 importlib-metadata-8.5.0 keras-2.9.0 keras-preprocessing-1.1.2 libclang-18.1.1 markdown-3.7 norbert-0.2.1 numpy-1.24.4 oauthlib-3.2.2 opt-einsum-3.4.0 packaging-24.2 pandas-1.5.3 protobuf-3.19.6 pyasn1-0.6.1 pyasn1-modules-0.4.1 python-dateutil-2.9.0.post0 pytz-2025.1 requests-2.32.3 requests-oauthlib-2.0.0 rfc3986-1.5.0 rsa-4.9 scipy-1.10.1 six-1.17.0 sniffio-1.3.1 spleeter-2.4.0 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.3 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.34.0 termcolor-2.4.0 typer-0.3.2 typing-extensions-4.12.2 urllib3-2.2.3 werkzeug-3.0.6 wheel-0.45.1 wrapt-1.17.2 zipp-3.20.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mUsage: spleeter [OPTIONS] COMMAND [ARGS]...\n",
            "\n",
            "Options:\n",
            "  --version  Return Spleeter version\n",
            "  --help     Show this message and exit.\n",
            "\n",
            "Commands:\n",
            "  evaluate  Evaluate a model on the musDB test dataset\n",
            "  separate  Separate audio file(s)\n",
            "  train     Train a source separation model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db_path = '/content/musdb18'"
      ],
      "metadata": {
        "id": "32x05a9iCAIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import musdb\n",
        "\n",
        "MUS_DB_PATH = db_path\n",
        "\n",
        "mus = musdb.DB(root=MUS_DB_PATH)\n",
        "mus_train = musdb.DB(root=MUS_DB_PATH,subsets=\"train\", split=\"train\")\n",
        "mus_valid = musdb.DB(root=MUS_DB_PATH,subsets=\"train\", split=\"valid\")\n",
        "mus_test = musdb.DB(root=MUS_DB_PATH,subsets=\"test\")\n",
        "print(mus_train[0])\n",
        "print(mus_test[0])"
      ],
      "metadata": {
        "id": "VJmYqgNjCEDY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 899
        },
        "outputId": "abad87bc-91ee-49e9-8b0c-df4c775eb360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "`np.float_` was removed in the NumPy 2.0 release. Use `np.float64` instead.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d337bbf1c4b3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmusdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mMUS_DB_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/musdb/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maudio_classes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiTrack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstempeg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/musdb/audio_classes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstempeg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stempeg/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \"\"\"\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_stems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStreamsReader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChannelsReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stempeg/read.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mstem_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0malways_3d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0mffmpeg_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"f32le\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0minfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m__expired_attributes__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m    398\u001b[0m                 \u001b[0;34mf\"`np.{attr}` was removed in the NumPy 2.0 release. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m                 \u001b[0;34mf\"{__expired_attributes__[attr]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: `np.float_` was removed in the NumPy 2.0 release. Use `np.float64` instead."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Installing SpeechBrain via pip\n",
        "BRANCH = 'develop'\n",
        "!python -m pip install git+https://github.com/speechbrain/speechbrain.git@$BRANCH\n",
        "\n",
        "# Clone SpeechBrain repository\n",
        "!git clone https://github.com/speechbrain/speechbrain/"
      ],
      "metadata": {
        "id": "_zRaodXFCGuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Musformer\n",
        "Custom Architecture to device a vocal classifier\n",
        "\n",
        "\n",
        "### Step1 : Simple Transformer Based Architecture\n"
      ],
      "metadata": {
        "id": "6Ruc1exjCHdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ############################################################################\n",
        "# Model: Transformer-based Vocal Separation\n",
        "# Encoder: Transformer\n",
        "# Decoder: Transformer\n",
        "# Input: Mixed audio waveform\n",
        "# Output: Separated vocals and music waveforms\n",
        "# Loss: SI-SDR (Scale-Invariant Signal-to-Distortion Ratio)\n",
        "# Training: MUSDB18 dataset\n",
        "##############################################################################\n",
        "\n",
        "# Seed needs to be set at top of yaml, before objects with parameters are instantiated\n",
        "seed: 1986\n",
        "__set_seed: !apply:torch.manual_seed [!ref <seed>]\n",
        "\n",
        "# Folder set up\n",
        "output_folder: !ref results/VocalSeparation/<seed>\n",
        "save_folder: !ref <output_folder>/save\n",
        "train_log: !ref <output_folder>/train_log.txt\n",
        "test_log: !ref <output_folder>/test_log.txt\n",
        "\n",
        "# Path where data manifest files are stored\n",
        "train_annotation: train.csv\n",
        "valid_annotation: valid.csv\n",
        "test_annotation: test.csv\n",
        "\n",
        "# The train logger writes training statistics to a file, as well as stdout.\n",
        "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
        "    save_file: !ref <train_log>\n",
        "\n",
        "# Training parameters\n",
        "number_of_epochs: 100\n",
        "batch_size: 16\n",
        "lr: 0.0001\n",
        "lr_final: 0.00001\n",
        "\n",
        "# Dataloader options\n",
        "train_dataloader_opts:\n",
        "    batch_size: !ref <batch_size>\n",
        "    shuffle: True\n",
        "\n",
        "valid_dataloader_opts:\n",
        "    batch_size: !ref <batch_size>\n",
        "\n",
        "test_dataloader_opts:\n",
        "    batch_size: !ref <batch_size>\n",
        "\n",
        "# Model parameters\n",
        "sample_rate: 16000  # Audio sample rate\n",
        "d_model: 256        # Transformer model dimension\n",
        "nhead: 8            # Number of attention heads\n",
        "num_encoder_layers: 4  # Number of encoder layers\n",
        "num_decoder_layers: 4  # Number of decoder layers\n",
        "dim_feedforward: 1024  # Feedforward layer dimension\n",
        "dropout: 0.1        # Dropout rate\n",
        "kernel_size: 3      # Kernel size for convolutional layers\n",
        "\n",
        "# Encoder: Converts waveform to latent representation\n",
        "encoder: !new:speechbrain.lobes.models.CNN.Conv1d\n",
        "    out_channels: !ref <d_model>\n",
        "    kernel_size: !ref <kernel_size>\n",
        "    stride: 1\n",
        "    padding: \"same\"\n",
        "\n",
        "# Transformer: Processes latent representation for separation\n",
        "transformer: !new:torch.nn.Transformer\n",
        "    d_model: !ref <d_model>\n",
        "    nhead: !ref <nhead>\n",
        "    num_encoder_layers: !ref <num_encoder_layers>\n",
        "    num_decoder_layers: !ref <num_decoder_layers>\n",
        "    dim_feedforward: !ref <dim_feedforward>\n",
        "    dropout: !ref <dropout>\n",
        "    batch_first: True\n",
        "\n",
        "# Decoder: Converts latent representation back to waveform\n",
        "decoder: !new:speechbrain.lobes.models.CNN.ConvTranspose1d\n",
        "    in_channels: !ref <d_model>\n",
        "    out_channels: 2  # Output channels for vocals and music\n",
        "    kernel_size: !ref <kernel_size>\n",
        "    stride: 1\n",
        "    padding: \"same\"\n",
        "\n",
        "# Positional encoding for transformer\n",
        "pos_enc: !new:speechbrain.lobes.models.transformer.Transformer.PositionalEncoding\n",
        "    input_size: !ref <d_model>\n",
        "    max_len: 5000  # Maximum sequence length\n",
        "\n",
        "# Loss function: SI-SDR (Scale-Invariant Signal-to-Distortion Ratio)\n",
        "loss: !new:speechbrain.nnet.loss.si_snr_loss\n",
        "\n",
        "# The first object passed to the Brain class is this \"Epoch Counter\"\n",
        "# which is saved by the Checkpointer so that training can be resumed\n",
        "# if it gets interrupted at any point.\n",
        "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
        "    limit: !ref <number_of_epochs>\n",
        "\n",
        "# Objects in \"modules\" dict will have their parameters moved to the correct\n",
        "# device, as well as having train()/eval() called on them by the Brain class\n",
        "modules:\n",
        "    encoder: !ref <encoder>\n",
        "    transformer: !ref <transformer>\n",
        "    decoder: !ref <decoder>\n",
        "    pos_enc: !ref <pos_enc>\n",
        "\n",
        "# Gathering all the submodels in a single model object.\n",
        "model: !new:torch.nn.ModuleList\n",
        "    - - !ref <encoder>\n",
        "      - !ref <transformer>\n",
        "      - !ref <decoder>\n",
        "\n",
        "# This function manages learning rate annealing over the epochs.\n",
        "lr_annealing: !new:speechbrain.nnet.schedulers.LinearScheduler\n",
        "    initial_value: !ref <lr>\n",
        "    final_value: !ref <lr_final>\n",
        "    epoch_count: !ref <number_of_epochs>\n",
        "\n",
        "# This optimizer will be constructed by the Brain class after all parameters\n",
        "# are moved to the correct device. Then it will be added to the checkpointer.\n",
        "opt_class: !name:torch.optim.Adam\n",
        "    lr: !ref <lr>\n",
        "\n",
        "# This object is used for saving the state of training both so that it\n",
        "# can be resumed if it gets interrupted, and also so that the best checkpoint\n",
        "# can be later loaded for evaluation or inference.\n",
        "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
        "    checkpoints_dir: !ref <save_folder>\n",
        "    recoverables:\n",
        "        model: !ref <model>\n",
        "        counter: !ref <epoch_counter>"
      ],
      "metadata": {
        "id": "dv3iHqbo4A-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%file train_transformer.py\n",
        "#!/usr/bin/env/python3\n",
        "\"\"\"Recipe for training a sequence-to-sequence machine translation system\n",
        "on \"ignotush\".\n",
        "The system employs a Transformer encoder, a decoder, and an attention mechanism\n",
        "between them.\n",
        "\n",
        "To run this recipe, do the following:\n",
        "> python train.py hparams/Transformers.yaml\n",
        "\n",
        "With the default hyperparameters, the system employs a Transformer encoder and decoder.\n",
        "\n",
        "The neural network is trained with the negative-log likelihood objective and\n",
        "characters are used as basic tokens for both english and ignotush.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import logging\n",
        "import speechbrain as sb\n",
        "from hyperpyyaml import load_hyperpyyaml\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "# Brain class for speech recognition training\n",
        "class Translate(sb.Brain):\n",
        "    \"\"\"Class that manages the training loop. See speechbrain.core.Brain.\"\"\"\n",
        "\n",
        "    def compute_forward(self, batch, stage):\n",
        "        \"\"\"Runs all the computation of the CTC + seq2seq ASR. It returns the\n",
        "        posterior probabilities of the CTC and seq2seq networks.\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        batch : PaddedBatch\n",
        "            This batch object contains all the relevant tensors for computation.\n",
        "        stage : sb.Stage\n",
        "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        predictions : torch.tensor\n",
        "            Log-probabilities predicted by the decoder.\n",
        "\n",
        "        At validation/test time, it returns the predicted tokens as well.\n",
        "        \"\"\"\n",
        "        # We first move the batch to the appropriate device.\n",
        "        # Your code here. Aim for 1 line.\n",
        "        batch = batch.to(self.device)\n",
        "\n",
        "        # Unpacking ignotush_encoded_chars and english_encoded_chars_bos\n",
        "        # Your code here. Aim for 1 line.\n",
        "        enc_ignotush, inp_lens = batch.ignotush_encoded_chars\n",
        "        enc_english_bos,  out_lens = batch.english_encoded_chars_bos\n",
        "\n",
        "        # Input embeddings\n",
        "        # Your code here. Aim for 1 line.\n",
        "        enc_emb = self.modules.encoder_emb(enc_ignotush)\n",
        "\n",
        "        # Positional Embeddings\n",
        "        # Your code here. Aim for 1 line.\n",
        "        pos_emb_enc = self.modules.pos_emb_enc(enc_emb)\n",
        "\n",
        "        # Summing up embeddings\n",
        "        # Your code here. Aim for 1 line.\n",
        "        enc_emb = pos_emb_enc + enc_emb\n",
        "\n",
        "        # Decoding embeddings\n",
        "        # Your code here. Aim for 3 lines.\n",
        "        dec_emb = self.modules.decoder_emb(enc_english_bos)\n",
        "        pos_emb_dec = self.modules.pos_emb_dec(dec_emb)\n",
        "        # Positional Embeddings\n",
        "        dec_emb = pos_emb_dec + dec_emb\n",
        "\n",
        "        # Getting target mask (to avoid looking ahead)\n",
        "        # Your code here. Aim for 1 line.\n",
        "        tgt_mask = self.hparams.lookahead_mask(enc_english_bos)\n",
        "\n",
        "        # Getting the source mask (all zeros is fine in this case to allow the\n",
        "        # network to embed both past and future contect)\n",
        "        # Your code here. Aim for 1 line.\n",
        "        src_mask = torch.zeros(enc_ignotush.size(1), enc_ignotush.size(1))\n",
        "\n",
        "        # Padding masks for source and targets (use padding_mas)\n",
        "        # Your code here. Aim for 2 lines.\n",
        "        src_key_padding_mask = self.hparams.padding_mask(enc_ignotush)\n",
        "        tgt_key_padding_mask = self.hparams.padding_mask(enc_english_bos)\n",
        "\n",
        "        # Running the Seq2Seq Transformer\n",
        "        # Your code here. Aim for 1 line.\n",
        "        decoder_outputs = self.modules.Seq2SeqTransformer(\n",
        "            src=enc_emb,\n",
        "            tgt=dec_emb,\n",
        "            src_mask=src_mask,\n",
        "            tgt_mask=tgt_mask,\n",
        "            memory_key_padding_mask=src_key_padding_mask,\n",
        "            tgt_key_padding_mask=tgt_key_padding_mask\n",
        "        )\n",
        "\n",
        "        # Compute logits\n",
        "        # Your code here. Aim for 1 line.\n",
        "        logits = self.modules.seq_lin(decoder_outputs)\n",
        "\n",
        "        # Apply log softmax\n",
        "        # Your code here. Aim for 1 line.\n",
        "        predictions = self.hparams.log_softmax(logits)\n",
        "\n",
        "\n",
        "        if stage == sb.Stage.TEST:\n",
        "\n",
        "            # Greedy Decoding\n",
        "            hyps = predictions.argmax(-1)\n",
        "\n",
        "            # getting the first index where the prediciton is eos_index\n",
        "            stop_indexes = (hyps==self.hparams.eos_index).int()\n",
        "            stop_indexes = stop_indexes.argmax(dim=1)\n",
        "\n",
        "            # Converting hyps from indexes to chars\n",
        "            hyp_lst = []\n",
        "            for hyp, stop_ind in zip(hyps, stop_indexes):\n",
        "                # in some cases the eos in not observed (e.g, for the last sentence\n",
        "                # in the batch)\n",
        "                if stop_ind == 0:\n",
        "                    stop_ind = -1\n",
        "                # Stopping when eos is observed\n",
        "                hyp = hyp[0:stop_ind]\n",
        "                # From index to character\n",
        "                hyp_lst.append(self.label_encoder.decode_ndim(hyp))\n",
        "            return predictions, hyp_lst\n",
        "\n",
        "        return predictions\n",
        "\n",
        "\n",
        "    def compute_objectives(self, predictions, batch, stage):\n",
        "        \"\"\"Computes the loss given the predicted and targeted outputs.\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        predictions : torch.tTensor\n",
        "            The output tensor from `compute_forward`.\n",
        "        batch : PaddedBatch\n",
        "            This batch object contains all the relevant tensors for computation.\n",
        "        stage : sb.Stage\n",
        "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        loss : torch.Tensor\n",
        "            A one-element tensor used for backpropagating the gradient.\n",
        "        \"\"\"\n",
        "        # Reading english_encoded_chars_eos\n",
        "        # Your code here. Aim for 1 line.\n",
        "        enc_english_eos, english_lens = batch.english_encoded_chars_eos\n",
        "\n",
        "\n",
        "        # Reading the predictions\n",
        "        if stage == sb.Stage.TEST:\n",
        "          predictions, hyp_lst = predictions\n",
        "\n",
        "          for id, label, hyp in zip(batch.id, batch.english_chars, hyp_lst):\n",
        "              print(id)\n",
        "              print(\"REF: \" + ''.join(label))\n",
        "              print(\"HYP: \" + ''.join(hyp))\n",
        "              print('--------')\n",
        "\n",
        "        # Compute the nnl_loss\n",
        "        # Your code here. Aim for 1 line.\n",
        "        loss = torch.nn.functional.nll_loss(\n",
        "            predictions.transpose(1, 2), enc_english_eos,\n",
        "            ignore_index=self.hparams.blank_index,\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def on_stage_end(self, stage, stage_loss, epoch):\n",
        "        \"\"\"Gets called at the end of an epoch.\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        stage : sb.Stage\n",
        "            One of sb.Stage.TRAIN, sb.Stage.VALID, sb.Stage.TEST\n",
        "        stage_loss : float\n",
        "            The average loss for all of the data processed in this stage.\n",
        "        epoch : int\n",
        "            The currently-starting epoch. This is passed\n",
        "            `None` during the test stage.\n",
        "        \"\"\"\n",
        "\n",
        "        # Store the train loss until the validation stage.\n",
        "        stage_stats = {\"loss\": stage_loss}\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            self.train_stats = stage_stats\n",
        "\n",
        "\n",
        "        # Perform end-of-iteration things, like annealing, logging, etc.\n",
        "        elif stage == sb.Stage.VALID:\n",
        "\n",
        "\n",
        "            # Update learning rate\n",
        "            old_lr, new_lr = self.hparams.lr_annealing(epoch)\n",
        "            sb.nnet.schedulers.update_learning_rate(self.optimizer, new_lr)\n",
        "\n",
        "            # The train_logger writes a summary to stdout and to the logfile.\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                stats_meta={\"epoch\": epoch, \"lr\": old_lr},\n",
        "                train_stats=self.train_stats,\n",
        "                valid_stats={\n",
        "                    \"loss\": stage_loss,\n",
        "                },\n",
        "            )\n",
        "            # Save the current checkpoint and delete previous checkpoints.\n",
        "            self.checkpointer.save_and_keep_only(\n",
        "                meta={\"loss\": stage_stats[\"loss\"]}, min_keys=[\"loss\"],\n",
        "            )\n",
        "\n",
        "        # We also write statistics about test data to stdout and to the logfile.\n",
        "        elif stage == sb.Stage.TEST:\n",
        "\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                stats_meta={\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
        "                test_stats={\n",
        "                    \"loss\": stage_loss,\n",
        "                },\n",
        "            )\n",
        "\n",
        "\n",
        "def dataio_prepare(hparams):\n",
        "    \"\"\"This function prepares the datasets to be used in the brain class.\n",
        "    It also defines the data processing pipeline through user-defined functions.\n",
        "\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    hparams : dict\n",
        "        This dictionary is loaded from the `train.yaml` file, and it includes\n",
        "        all the hyperparameters needed for dataset construction and loading.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    datasets : dict\n",
        "        Dictionary containing \"train\", \"valid\", and \"test\" keys that correspond\n",
        "        to the DynamicItemDataset objects.\n",
        "    \"\"\"\n",
        "    # Define text processing pipeline. We start from the raw text and then\n",
        "    # split it into characters. The tokens with BOS are used for feeding\n",
        "    # the decoder during training (right shifr), the tokens with EOS\n",
        "    # are used for computing the cost function.\n",
        "    @sb.utils.data_pipeline.takes(\"english\")\n",
        "    @sb.utils.data_pipeline.provides(\n",
        "        \"english_words\",\n",
        "        \"english_chars\",\n",
        "        \"english_encoded_chars_lst\",\n",
        "        \"english_encoded_chars\",\n",
        "        \"english_encoded_chars_eos\",\n",
        "        \"english_encoded_chars_bos\",\n",
        "        )\n",
        "    def ignotush_text_pipeline(english):\n",
        "        \"\"\"Processes the transcriptions to generate proper labels\"\"\"\n",
        "        yield english\n",
        "        english_chars = list(english)\n",
        "        yield english_chars\n",
        "        english_encoded_chars_lst = label_encoder.encode_sequence(english_chars)\n",
        "        yield english_encoded_chars_lst\n",
        "        english_encoded_chars = torch.LongTensor(english_encoded_chars_lst)\n",
        "        yield english_encoded_chars\n",
        "        english_encoded_chars_eos = torch.LongTensor(label_encoder.append_eos_index(english_encoded_chars_lst))\n",
        "        yield english_encoded_chars_eos\n",
        "        english_encoded_chars_bos = torch.LongTensor(label_encoder.prepend_bos_index(english_encoded_chars_lst))\n",
        "        yield english_encoded_chars_bos\n",
        "\n",
        "    @sb.utils.data_pipeline.takes(\"ignotush\")\n",
        "    @sb.utils.data_pipeline.provides(\"ignotush_words\", \"ignotush_chars\", \"ignotush_encoded_chars\")\n",
        "    def english_text_pipeline(ignotush):\n",
        "        \"\"\"Processes the transcriptions to generate proper labels\"\"\"\n",
        "        yield ignotush\n",
        "        ignotush_chars = list(ignotush)\n",
        "        yield ignotush_chars\n",
        "        ignotush_encoded_chars = torch.LongTensor(input_encoder.encode_sequence(ignotush_chars))\n",
        "        yield ignotush_encoded_chars\n",
        "\n",
        "    # Define datasets from json data manifest file\n",
        "    # Define datasets sorted by ascending lengths for efficiency\n",
        "    datasets = {}\n",
        "    data_info = {\n",
        "        \"train\": hparams[\"train_annotation\"],\n",
        "        \"valid\": hparams[\"valid_annotation\"],\n",
        "        \"test\": hparams[\"test_annotation\"],\n",
        "    }\n",
        "\n",
        "    # The label encoder will assign a different integer to each element\n",
        "    # in the output vocabulary\n",
        "    input_encoder = sb.dataio.encoder.CTCTextEncoder()\n",
        "    label_encoder = sb.dataio.encoder.CTCTextEncoder()\n",
        "\n",
        "    for dataset in data_info:\n",
        "        datasets[dataset] = sb.dataio.dataset.DynamicItemDataset.from_csv(\n",
        "            csv_path=data_info[dataset],\n",
        "            dynamic_items=[ignotush_text_pipeline, english_text_pipeline],\n",
        "            output_keys=[\n",
        "                \"id\",\n",
        "                \"english_words\",\n",
        "                \"english_chars\",\n",
        "                \"english_encoded_chars\",\n",
        "                \"english_encoded_chars_eos\",\n",
        "                \"english_encoded_chars_bos\",\n",
        "                \"ignotush_words\",\n",
        "                \"ignotush_chars\",\n",
        "                \"ignotush_encoded_chars\",\n",
        "            ],\n",
        "        )\n",
        "        hparams[f\"{dataset}_dataloader_opts\"][\"shuffle\"] = True\n",
        "\n",
        "\n",
        "    # Load or compute the label encoder\n",
        "    inp_enc_file = os.path.join(hparams[\"save_folder\"], \"input_encoder.txt\")\n",
        "\n",
        "    # The blank symbol is used to indicate padding\n",
        "    special_labels = {\"blank_label\": hparams[\"blank_index\"]}\n",
        "\n",
        "    input_encoder.load_or_create(\n",
        "        path=inp_enc_file,\n",
        "        from_didatasets=[datasets[\"train\"]],\n",
        "        output_key=\"ignotush_chars\",\n",
        "        special_labels=special_labels,\n",
        "        sequence_input=True,\n",
        "    )\n",
        "\n",
        "    # Load or compute the label encoder\n",
        "    lab_enc_file = os.path.join(hparams[\"save_folder\"], \"label_encoder.txt\")\n",
        "    special_labels = {\n",
        "        \"blank_label\": hparams[\"blank_index\"],\n",
        "        \"bos_label\": hparams[\"bos_index\"],\n",
        "        \"eos_label\": hparams[\"eos_index\"],\n",
        "    }\n",
        "    label_encoder.load_or_create(\n",
        "        path=lab_enc_file,\n",
        "        from_didatasets=[datasets[\"train\"]],\n",
        "        output_key=\"english_chars\",\n",
        "        special_labels=special_labels,\n",
        "        sequence_input=True,\n",
        "    )\n",
        "\n",
        "    return datasets, label_encoder\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Reading command line arguments\n",
        "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
        "\n",
        "    # Load hyperparameters file with command-line overrides\n",
        "    with open(hparams_file) as fin:\n",
        "        hparams = load_hyperpyyaml(fin, overrides)\n",
        "\n",
        "    # Create experiment directory\n",
        "    sb.create_experiment_directory(\n",
        "        experiment_directory=hparams[\"output_folder\"],\n",
        "        hyperparams_to_save=hparams_file,\n",
        "        overrides=overrides,\n",
        "    )\n",
        "\n",
        "\n",
        "    # We can now directly create the datasets for training, valid, and test\n",
        "    datasets, label_encoder = dataio_prepare(hparams)\n",
        "\n",
        "    # Trainer initialization\n",
        "    translate_brain = Translate(\n",
        "        modules=hparams[\"modules\"],\n",
        "        opt_class=hparams[\"opt_class\"],\n",
        "        hparams=hparams,\n",
        "        run_opts=run_opts,\n",
        "        checkpointer=hparams[\"checkpointer\"],\n",
        "    )\n",
        "\n",
        "    # Making label encoder accessible (needed for computer the character error rate)\n",
        "    translate_brain.label_encoder = label_encoder\n",
        "\n",
        "    # The `fit()` method iterates the training loop, calling the methods\n",
        "    # necessary to update the parameters of the model. Since all objects\n",
        "    # with changing state are managed by the Checkpointer, training can be\n",
        "    # stopped at any point, and will be resumed on next call.\n",
        "    translate_brain.fit(\n",
        "        translate_brain.hparams.epoch_counter,\n",
        "        datasets[\"train\"],\n",
        "        datasets[\"valid\"],\n",
        "        train_loader_kwargs=hparams[\"train_dataloader_opts\"],\n",
        "        valid_loader_kwargs=hparams[\"valid_dataloader_opts\"],\n",
        "    )\n",
        "\n",
        "    # Load best checkpoint for evaluation\n",
        "    test_stats = translate_brain.evaluate(\n",
        "        test_set=datasets[\"test\"],\n",
        "        min_key=\"WER\",\n",
        "        test_loader_kwargs=hparams[\"test_dataloader_opts\"],\n",
        "    )\n"
      ],
      "metadata": {
        "id": "nU7qfFJS-DtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U0KURLHs-DqS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
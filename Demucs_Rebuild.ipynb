{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 10005918,
          "sourceType": "datasetVersion",
          "datasetId": 6159348
        }
      ],
      "dockerImageVersionId": 30918,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Demucs_Rebuild",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mirchandani-mohnish/Musformer/blob/main/Demucs_Rebuild.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "jakerr5280_musdb18_music_source_separation_dataset_path = kagglehub.dataset_download('jakerr5280/musdb18-music-source-separation-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "A27O0TcP1PHI"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T19:10:36.15438Z",
          "iopub.execute_input": "2025-04-07T19:10:36.1546Z",
          "iopub.status.idle": "2025-04-07T19:10:37.276508Z",
          "shell.execute_reply.started": "2025-04-07T19:10:36.154579Z",
          "shell.execute_reply": "2025-04-07T19:10:37.27543Z"
        },
        "id": "JKcErsfg1PHN",
        "outputId": "aec13e43-6847-4ca1-802b-1617c5e0919a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/musdb18-music-source-separation-dataset/The Long Wait - Dark Horses.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Raft Monk - Tiring.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/BKS - Too Much.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Georgia Wonder - Siren.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/The Sunshine Garcia Band - For I Am The Moon.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Enda Reilly - Cur An Long Ag Seol.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Buitraker - Revo X.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/We Fell From The Sky - Not You.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/The Mountaineering Club - Mallory.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Skelpolu - Resurrection.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Secretariat - Over The Top.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Bobby Nobody - Stitch Up.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Arise - Run Run Run.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Carlos Gonzalez - A Place For Us.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Forkupines - Semantics.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/The Easton Ellises - Falcon 69.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Lyndsey Ollard - Catching Up.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Triviul feat. The Fiend - Widow.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Louis Cressy Band - Good Time.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Motor Tapes - Shore.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/AM Contra - Heart Peripheral.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Signe Jakobsen - What Have You Done To Me.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Moosmusic - Big Dummy Shake.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/M.E.R.C. Music - Knockout.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/The Doppler Shift - Atrophy.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Detsky Sad - Walkie Talkie.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/PR - Happy Daze.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Timboz - Pony.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/PR - Oh No.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Mu - Too Bright.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Hollow Ground - Ill Fate.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/The Easton Ellises (Baumi) - SDRNR.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Speak Softly - Like Horses.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Sambasevam Shanmugam - Kaathaadi.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Tom McKenzie - Directions.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Secretariat - Borderline.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Side Effects Project - Sing With Me.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Nerve 9 - Pray For The Rain.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Zeno - Signs.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Girls Under Glass - We Feel Alright.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Cristina Vane - So Easy.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Speak Softly - Broken Man.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/BKS - Bulldozer.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Punkdisco - Oral Hygiene.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Al James - Schoolboy Facination.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Dark Ride - Burning Bridges.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Drumtracks - Ghost Bitch.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Aimee Norwich - Child.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/James May - If You Say.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Rockabilly.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Steven Clark - Bounty.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Giselle - Moss.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Strand Of Oaks - Spacestation.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Patrick Talbot - Set Me Free.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Bill Chudziak - Children Of No-one.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Angela Thomas Wade - Milk Cow Blues.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Grants - PunchDrunk.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Grunge.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Traffic Experiment - Once More (With Feeling).stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Beatles.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Auctioneer - Our Future Faces.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Clara Berry And Wooldog - Air Traffic.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Patrick Talbot - A Reason To Leave.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/The Districts - Vermont.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Leaf - Come Around.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/North To Alaska - All The Same.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Skelpolu - Human Mistakes.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Dreamers Of The Ghetto - Heavy Love.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/ANiMAL - Rockshow.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Faces On Film - Waiting For Ga.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Snowmine - Curfews.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Swinging Steaks - Lost My Way.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Triviul - Dorothy.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Gospel.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Clara Berry And Wooldog - Stella.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Disco.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Reggae.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/The So So Glos - Emergency.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Leaf - Wicked.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/St Vitus - Word Gets Around.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Celestial Shore - Die For Us.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Young Griffo - Facade.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/AvaLuna - Waterduct.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Punk.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Actions - One Minute Smile.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Young Griffo - Blood To Bone.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Tim Taler - Stalker.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Hendrix.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Leaf - Summerghost.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Hop Along - Sister Cities.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/James May - All Souls Moon.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Meaxic - You Listen.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Country2.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/ANiMAL - Clinic A.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Traffic Experiment - Sirens.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Britpop.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Rock.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Chris Durban - Celebrate.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Triviul - Angelsaint.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/James May - On The Line.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/A Classic Education - NightOwl.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Skelpolu - Together Alone.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Titanium - Haunted Age.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Alexander Ross - Goodbye Bolero.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Secret Mountains - High Horse.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Wall Of Death - Femme.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Fergessen - The Wind.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Alexander Ross - Velvet Curtain.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Johnny Lokke - Whisper To A Scream.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Meaxic - Take A Step.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Jay Menon - Through My Eyes.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Flags - 54.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Clara Berry And Wooldog - Waltz For My Victims.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/ANiMAL - Easy Tiger.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Fergessen - Back From The Start.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Hollow Ground - Left Blind.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Sweet Lights - You Let Me Down.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Port St Willow - Stay Even.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Helado Negro - Mitad Del Mundo.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Black Bloc - If You Want Success.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Young Griffo - Pennies.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Voelund - Comfort Lives In Belief.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Fergessen - Nos Palpitants.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Creepoid - OldTree.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Actions - South Of The Water.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Lushlife - Toynbee Suite.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Matthew Entwistle - Dont You Ever.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/The Scarlet Brand - Les Fleurs Du Mal.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Country1.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/James May - Dont Let Go.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - 80s Rock.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Atlantis Bound - It Was My Fault For Waiting.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Invisible Familiars - Disturbing Wildlife.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Cnoc An Tursa - Bannockburn.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Hezekiah Jones - Borrowed Heart.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/BigTroubles - Phantom.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Remember December - C U Next Time.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Night Panther - Fire.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/The Long Wait - Back Home To Blue.stem.mp4\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install musdb\n",
        "!pip install mir_eval\n",
        "\n",
        "\n",
        "%%capture\n",
        "# Installing SpeechBrain via pip\n",
        "BRANCH = 'develop'\n",
        "!python -m pip install git+https://github.com/speechbrain/speechbrain.git@$BRANCH\n",
        "\n",
        "# Clone SpeechBrain repository\n",
        "!git clone https://github.com/speechbrain/speechbrain/"
      ],
      "metadata": {
        "trusted": true,
        "id": "a5s2sXRa1PHP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "db_path = '/kaggle/input/musdb18-music-source-separation-dataset'\n",
        "output_path = '/kaggle/working'"
      ],
      "metadata": {
        "trusted": true,
        "id": "rpCsBx331PHQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "np.float_ = np.float64\n",
        "import musdb\n",
        "\n",
        "MUS_DB_PATH = db_path\n",
        "\n",
        "mus = musdb.DB(root=MUS_DB_PATH)\n",
        "mus_train = musdb.DB(root=MUS_DB_PATH,subsets=\"train\", split=\"train\")\n",
        "mus_valid = musdb.DB(root=MUS_DB_PATH,subsets=\"train\", split=\"valid\")\n",
        "mus_test = musdb.DB(root=MUS_DB_PATH,subsets=\"test\")\n",
        "print(mus_train[0])\n",
        "print(mus_test[0])"
      ],
      "metadata": {
        "trusted": true,
        "id": "PzSfb4A31PHR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%file models.py\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from speechbrain.nnet.CNN import Conv1d, ConvTranspose1d\n",
        "# from speechbrain.nnet.activations import GLU\n",
        "from speechbrain.lobes.models.beats import GLU_Linear\n",
        "from torch.nn import GLU\n",
        "from speechbrain.nnet.RNN import LSTM\n",
        "from speechbrain.nnet.linear import Linear\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = Conv1d(\n",
        "            out_channels=out_channels,\n",
        "            in_channels=in_channels,\n",
        "            kernel_size=8,\n",
        "            stride=4,\n",
        "            # default_padding=2,\n",
        "            skip_transpose=True,\n",
        "        )\n",
        "        self.glu_conv = Conv1d(\n",
        "            out_channels=2*out_channels,\n",
        "            in_channels=out_channels,\n",
        "            kernel_size=1,\n",
        "            stride=1,\n",
        "            skip_transpose=True,\n",
        "        )\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.glu = GLU(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.size())\n",
        "        x = self.relu(self.conv(x))\n",
        "        # print(x.size())\n",
        "        x = self.glu(self.glu_conv(x))\n",
        "        # print(x.size())\n",
        "        return x\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.glu_conv = Conv1d(\n",
        "            out_channels=2*in_channels,\n",
        "            in_channels=in_channels,\n",
        "            kernel_size=1,\n",
        "            stride=1,\n",
        "            skip_transpose=True,\n",
        "        )\n",
        "        self.conv_tr = ConvTranspose1d(\n",
        "            out_channels=out_channels,\n",
        "            in_channels=in_channels,  # After GLU split\n",
        "            kernel_size=8,\n",
        "            stride=4,\n",
        "            # padding=2,\n",
        "            # output_padding=2,\n",
        "            skip_transpose=True,\n",
        "        )\n",
        "        self.glu = GLU(dim=1)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, x, skip=None):\n",
        "\n",
        "        if skip is not None:\n",
        "\n",
        "            # T changed after conv1d in encoder, fix it here\n",
        "            T_x = x.size(-1)\n",
        "            T_skip = skip.size(-1)\n",
        "\n",
        "            # Case 1: Decoder output is longer\n",
        "            if T_skip > T_x:\n",
        "                # Center-trim decoder output\n",
        "                start = (T_skip - T_x) // 2\n",
        "                skip = skip[..., start : start + T_x]\n",
        "\n",
        "            # Case 2: Skip is longer\n",
        "            elif T_skip < T_x:\n",
        "                # Center-pad decoder output\n",
        "                pad = T_x - T_skip\n",
        "                skip = nn.functional.pad(skip, (pad // 2, pad - pad // 2))\n",
        "\n",
        "\n",
        "            x = x + skip\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        x = self.glu(self.glu_conv(x))\n",
        "\n",
        "        x = self.relu(self.conv_tr(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class SourceSeparator(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels=2, num_sources=4):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            C_in: Input channels from last decoder (typically 8)\n",
        "            C_out: Output channels per source (2 for stereo)\n",
        "            num_sources: Number of sources to separate (e.g. 4 for vocals, drums, bass, other)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # Final linear layer (no activation)\n",
        "        self.output_proj = Linear(\n",
        "            input_size=in_channels,\n",
        "            n_neurons=num_sources * out_channels,  # 4 sources * 2 channels = 8\n",
        "            bias=True\n",
        "        )\n",
        "        self.num_sources = num_sources\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Input: [batch, C_in, time]\n",
        "        Output: [batch, num_sources, out_channels, time]\n",
        "        \"\"\"\n",
        "        # Permute to [batch, time, features]\n",
        "        # print(x.size())\n",
        "        x = x.permute(0, 2, 1)\n",
        "\n",
        "        # Project to source waveforms\n",
        "        x = self.output_proj(x)  # [batch, time, num_sources*out_channels]\n",
        "        # print(x.size())\n",
        "\n",
        "        # Reshape to separated sources\n",
        "        x = x.view(x.size(0), -1, self.num_sources, self.out_channels)\n",
        "        x = x.permute(0, 2, 1, 3)\n",
        "        # print(x.size())\n",
        "        # Return as [batch, sources, channels, time]\n",
        "        return x"
      ],
      "metadata": {
        "trusted": true,
        "id": "tlc_qVaU1PHS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%file hparams.yaml\n",
        "\n",
        "# ################################\n",
        "# Model: Demucs for source separation\n",
        "# https://hal.science/hal-02379796/document\n",
        "# Dataset : Musdb\n",
        "# ################################\n",
        "# Basic parameters\n",
        "seed: 1234\n",
        "__set_seed: !apply:speechbrain.utils.seed_everything [!ref <seed>]\n",
        "\n",
        "# Data params (unchanged from DPRNN)\n",
        "data_folder: !PLACEHOLDER\n",
        "\n",
        "experiment_name: demucs\n",
        "output_folder: !ref /kaggle/working/results/<experiment_name>/<seed>\n",
        "train_log: !ref <output_folder>/train_log.txt\n",
        "save_folder: !ref <output_folder>/save\n",
        "train_data: !ref <output_folder>/train.json\n",
        "valid_data: !ref <output_folder>/valid.json\n",
        "test_data: !ref <output_folder>/test.json\n",
        "skip_prep: False\n",
        "db_path: '/kaggle/input/musdb18-music-source-separation-dataset'\n",
        "\n",
        "\n",
        "# Experiment params\n",
        "precision: fp16\n",
        "num_sources: 2\n",
        "\n",
        "instrumental_classification: False\n",
        "noprogressbar: False\n",
        "save_audio: True\n",
        "sample_rate: 16000\n",
        "n_audio_to_save: 10\n",
        "\n",
        "####################### Training Parameters ####################################\n",
        "\n",
        "N_epochs: 3\n",
        "batch_size: 2\n",
        "lr: 0.00015\n",
        "clip_grad_norm: 5\n",
        "loss_upper_lim: 999999\n",
        "limit_training_signal_len: False\n",
        "training_signal_len: 32000000\n",
        "\n",
        "\n",
        "# Data augmentation (unchanged)\n",
        "use_wavedrop: False\n",
        "use_rand_shift: False\n",
        "min_shift: -8000\n",
        "max_shift: 8000\n",
        "\n",
        "\n",
        "# Frequency/time drop (unchanged)\n",
        "drop_freq: !new:speechbrain.augment.time_domain.DropFreq\n",
        "    drop_freq_low: 0\n",
        "    drop_freq_high: 1\n",
        "    drop_freq_count_low: 1\n",
        "    drop_freq_count_high: 3\n",
        "    drop_freq_width: 0.05\n",
        "\n",
        "drop_chunk: !new:speechbrain.augment.time_domain.DropChunk\n",
        "    drop_length_low: 1000\n",
        "    drop_length_high: 2000\n",
        "    drop_count_low: 1\n",
        "    drop_count_high: 5\n",
        "\n",
        "threshold_byloss: True\n",
        "threshold: -30\n",
        "\n",
        "################ Demucs Specific Parameters #############################\n",
        "## for Demucs V3/4\n",
        "# # Fourier Transform Parameters\n",
        "# n_fft: 2048\n",
        "# hop_length: 512\n",
        "\n",
        "\n",
        "kernel_size: 16\n",
        "# kernel_stride: 8\n",
        "\n",
        "# Dataloader options (unchanged)\n",
        "dataloader_opts:\n",
        "    batch_size: !ref <batch_size>\n",
        "    num_workers: 3\n",
        "\n",
        "######################## Network Definition ####################################\n",
        "\n",
        "\n",
        "Encoder1: !new:models.EncoderBlock\n",
        "    in_channels: 2\n",
        "    # kernel_size: !ref <kernel_size>\n",
        "    out_channels: 64\n",
        "\n",
        "\n",
        "Encoder2: !new:models.EncoderBlock\n",
        "    in_channels: 64\n",
        "    # kernel_size: !ref <kernel_size>\n",
        "    out_channels: 128\n",
        "\n",
        "\n",
        "Encoder3: !new:models.EncoderBlock\n",
        "    in_channels: 128\n",
        "    # kernel_size: !ref <kernel_size>\n",
        "    out_channels: 256\n",
        "\n",
        "\n",
        "Encoder4: !new:models.EncoderBlock\n",
        "    in_channels: 256\n",
        "    # kernel_size: !ref <kernel_size>\n",
        "    out_channels: 512\n",
        "\n",
        "\n",
        "Encoder5: !new:models.EncoderBlock\n",
        "    in_channels: 512\n",
        "    # kernel_size: !ref <kernel_size>\n",
        "    out_channels: 1024\n",
        "\n",
        "\n",
        "Encoder6: !new:models.EncoderBlock\n",
        "    in_channels: 1024\n",
        "    # kernel_size: !ref <kernel_size>\n",
        "    out_channels: 2048\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Decoder6: !new:models.DecoderBlock\n",
        "    in_channels: 2048\n",
        "    out_channels: 1024\n",
        "    # # kernel_size: !ref <kernel_size>\n",
        "    # stride: !ref <kernel_stride>\n",
        "\n",
        "\n",
        "Decoder5: !new:models.DecoderBlock\n",
        "    in_channels: 1024\n",
        "    out_channels: 512\n",
        "    # # kernel_size: !ref <kernel_size>\n",
        "    # stride: !ref <kernel_stride>\n",
        "\n",
        "\n",
        "Decoder4: !new:models.DecoderBlock\n",
        "    in_channels: 512\n",
        "    out_channels: 256\n",
        "    # kernel_size: !ref <kernel_size>\n",
        "    # stride: !ref <kernel_stride>\n",
        "\n",
        "\n",
        "Decoder3: !new:models.DecoderBlock\n",
        "    in_channels: 256\n",
        "    out_channels: 128\n",
        "    # kernel_size: !ref <kernel_size>\n",
        "    # stride: !ref <kernel_stride>\n",
        "\n",
        "\n",
        "Decoder2: !new:models.DecoderBlock\n",
        "    in_channels: 128\n",
        "    out_channels: 64\n",
        "    # kernel_size: !ref <kernel_size>\n",
        "    # stride: !ref <kernel_stride>\n",
        "\n",
        "\n",
        "Decoder1: !new:models.DecoderBlock\n",
        "    in_channels: 64\n",
        "    out_channels: 8\n",
        "    # kernel_size: !ref <kernel_size>\n",
        "    # stride: !ref <kernel_stride>\n",
        "\n",
        "\n",
        "Linear: !new:speechbrain.nnet.linear.Linear\n",
        "    input_size: 4096\n",
        "    bias: False\n",
        "    n_neurons: 2048\n",
        "\n",
        "BiLSTM: !new:speechbrain.nnet.RNN.LSTM\n",
        "    hidden_size: 2048\n",
        "    input_size: 2048\n",
        "    num_layers: 2\n",
        "    bidirectional: True\n",
        "    # batch_first: True\n",
        "\n",
        "LinearSeparator: !new:models.SourceSeparator\n",
        "    in_channels: 8\n",
        "    out_channels: 2\n",
        "    num_sources: !ref <num_sources>\n",
        "\n",
        "\n",
        "######################## Remaining Config ######################################\n",
        "optimizer: !name:torch.optim.Adam\n",
        "    lr: !ref <lr>\n",
        "    weight_decay: 0\n",
        "\n",
        "# loss: !name:speechbrain.nnet.losses.mse_loss\n",
        "loss: !name:speechbrain.nnet.losses.get_si_snr_with_pitwrapper\n",
        "\n",
        "\n",
        "lr_scheduler: !new:speechbrain.nnet.schedulers.ReduceLROnPlateau\n",
        "    factor: 0.5\n",
        "    patience: 2\n",
        "    dont_halve_until_epoch: 50\n",
        "\n",
        "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
        "    limit: !ref <N_epochs>\n",
        "\n",
        "modules:\n",
        "    encoder1: !ref <Encoder1>\n",
        "    encoder2: !ref <Encoder2>\n",
        "    encoder3: !ref <Encoder3>\n",
        "    encoder4: !ref <Encoder4>\n",
        "    encoder5: !ref <Encoder5>\n",
        "    encoder6: !ref <Encoder6>\n",
        "    lstm: !ref <BiLSTM>\n",
        "    linear: !ref <Linear>\n",
        "    decoder6: !ref <Decoder6>\n",
        "    decoder5: !ref <Decoder5>\n",
        "    decoder4: !ref <Decoder4>\n",
        "    decoder3: !ref <Decoder3>\n",
        "    decoder2: !ref <Decoder2>\n",
        "    decoder1: !ref <Decoder1>\n",
        "    linearSeparator: !ref <LinearSeparator>\n",
        "\n",
        "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
        "    checkpoints_dir: !ref <save_folder>\n",
        "    recoverables:\n",
        "        encoder1: !ref <Encoder1>\n",
        "        encoder2: !ref <Encoder2>\n",
        "        encoder3: !ref <Encoder3>\n",
        "        encoder4: !ref <Encoder4>\n",
        "        encoder5: !ref <Encoder5>\n",
        "        encoder6: !ref <Encoder6>\n",
        "        lstm: !ref <BiLSTM>\n",
        "        linear: !ref <Linear>\n",
        "        decoder6: !ref <Decoder6>\n",
        "        decoder5: !ref <Decoder5>\n",
        "        decoder4: !ref <Decoder4>\n",
        "        decoder3: !ref <Decoder3>\n",
        "        decoder2: !ref <Decoder2>\n",
        "        decoder1: !ref <Decoder1>\n",
        "        linearSeparator: !ref <LinearSeparator>\n",
        "        counter: !ref <epoch_counter>\n",
        "\n",
        "\n",
        "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
        "    save_file: !ref <train_log>"
      ],
      "metadata": {
        "trusted": true,
        "id": "R3YYX0x81PHT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%file train.py\n",
        "#!/usr/bin/env/python3\n",
        "\"\"\"Recipe for training a neural speech separation system on the wsjmix\n",
        "dataset. The system employs an encoder, a decoder, and a masking network.\n",
        "\n",
        "To run this recipe, do the following:\n",
        "> python train.py hparams/sepformer.yaml\n",
        "> python train.py hparams/dualpath_rnn.yaml\n",
        "> python train.py hparams/convtasnet.yaml\n",
        "\n",
        "The experiment file is flexible enough to support different neural\n",
        "networks. By properly changing the parameter files, you can try\n",
        "different architectures. The script supports both wsj2mix and\n",
        "wsj3mix.\n",
        "\n",
        "\n",
        "Authors\n",
        " * Cem Subakan 2020\n",
        " * Mirco Ravanelli 2020\n",
        " * Samuele Cornell 2020\n",
        " * Mirko Bronzi 2020\n",
        " * Jianyuan Zhong 2020\n",
        "\"\"\"\n",
        "## CHECKPOINT\n",
        "import csv\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "from hyperpyyaml import load_hyperpyyaml\n",
        "from tqdm import tqdm\n",
        "\n",
        "import speechbrain as sb\n",
        "import speechbrain.nnet.schedulers as schedulers\n",
        "from speechbrain.utils.distributed import run_on_main\n",
        "from speechbrain.utils.logger import get_logger\n",
        "from speechbrain.nnet.CNN import Conv1d, ConvTranspose1d\n",
        "# from speechbrain.nnet.activations import GLU\n",
        "from speechbrain.lobes.models.beats import GLU_Linear\n",
        "from torch.nn import GLU\n",
        "from speechbrain.nnet.RNN import LSTM\n",
        "from speechbrain.nnet.linear import Linear\n",
        "from models import EncoderBlock, DecoderBlock\n",
        "from speechbrain.nnet.losses import get_si_snr_with_pitwrapper\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import musdb\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define training procedure\n",
        "class DemucsSeparation(sb.Brain):\n",
        "    # def on_fit_start(self):\n",
        "\n",
        "\n",
        "    def compute_forward(self, mix, targets, stage, noise=None):\n",
        "        \"\"\"Forward computations from the mixture to the separated signals.\"\"\"\n",
        "\n",
        "        # Unpack lists and put tensors in the right device\n",
        "        mix, mix_lens = mix\n",
        "        mix, mix_lens = mix.to(self.device), mix_lens.to(self.device)\n",
        "\n",
        "        # Convert targets to tensor\n",
        "        # print([targets[i][0].size() for i in range(self.hparams.num_sources)])\n",
        "        targets = torch.cat(\n",
        "            [targets[i][0].unsqueeze(-1) for i in range(self.hparams.num_sources)],\n",
        "            dim=-1,\n",
        "        ).to(self.device)\n",
        "\n",
        "\n",
        "\n",
        "        mix_enc_1 = self.modules.encoder1(mix)\n",
        "\n",
        "        mix_enc_2 = self.modules.encoder2(mix_enc_1)\n",
        "\n",
        "        mix_enc_3 = self.modules.encoder3(mix_enc_2)\n",
        "        mix_enc_4 = self.modules.encoder4(mix_enc_3)\n",
        "        mix_enc_5 = self.modules.encoder5(mix_enc_4)\n",
        "        mix_enc_6 = self.modules.encoder6(mix_enc_5)\n",
        "\n",
        "        lstm_in = mix_enc_6.permute(0,2,1)\n",
        "        lstm_out, _ = self.modules.lstm(lstm_in) # outputs both -- outputs as well as hidden states -- we dont need hidden states\n",
        "        # print(lstm_out.size())\n",
        "        lin_out = self.modules.linear(lstm_out)\n",
        "        # print(lin_out.size())\n",
        "        lin_out = lin_out.permute(0,2,1)\n",
        "\n",
        "        mix_dec_6 = self.modules.decoder6(lin_out, skip=mix_enc_6)\n",
        "        mix_dec_5 = self.modules.decoder5(mix_dec_6, skip=mix_enc_5)\n",
        "        mix_dec_4 = self.modules.decoder4(mix_dec_5, skip=mix_enc_4)\n",
        "        mix_dec_3 = self.modules.decoder3(mix_dec_4, skip=mix_enc_3)\n",
        "        mix_dec_2 = self.modules.decoder2(mix_dec_3, skip=mix_enc_2)\n",
        "        mix_dec_1 = self.modules.decoder1(mix_dec_2, skip=mix_enc_1)\n",
        "\n",
        "        mix_out = self.modules.linearSeparator(mix_dec_1)\n",
        "\n",
        "\n",
        "        est_source = mix_out\n",
        "\n",
        "\n",
        "\n",
        "        # T changed after conv1d in encoder, fix it here\n",
        "        T_origin = targets.size(2)\n",
        "        T_est = est_source.size(2)\n",
        "\n",
        "        if T_origin > T_est:\n",
        "            est_source = F.pad(est_source, (0, 0, T_origin - T_est, 0))\n",
        "        else:\n",
        "            est_source = est_source[:, : , :T_origin, :]\n",
        "\n",
        "\n",
        "        return est_source, targets\n",
        "\n",
        "    def compute_objectives(self, predictions, targets):\n",
        "        \"\"\"Computes the sinr loss\"\"\"\n",
        "\n",
        "        return self.hparams.loss(targets.squeeze(dim=1), predictions.squeeze(dim=1)) # for pitwrapper\n",
        "        # return self.hparams.loss(targets=targets, predictions=predictions)\n",
        "## CHECKPOINT\n",
        "    def fit_batch(self, batch):\n",
        "        \"\"\"Trains one batch\"\"\"\n",
        "\n",
        "        # Unpacking batch list\n",
        "        mixture = batch.mix_sig\n",
        "        targets = [batch.voc_sig, batch.inst_sig]\n",
        "\n",
        "        with self.training_ctx:\n",
        "            predictions, targets = self.compute_forward(\n",
        "                mixture, targets, sb.Stage.TRAIN\n",
        "            )\n",
        "\n",
        "            loss = self.compute_objectives(predictions, targets)\n",
        "\n",
        "            # hard threshold the easy dataitems\n",
        "            if self.hparams.threshold_byloss:\n",
        "                th = self.hparams.threshold\n",
        "                loss = loss[loss > th]\n",
        "                if loss.nelement() > 0:\n",
        "                    loss = loss.mean()\n",
        "            else:\n",
        "                loss = loss.mean()\n",
        "\n",
        "        if loss.nelement() > 0 and loss < self.hparams.loss_upper_lim:\n",
        "            self.scaler.scale(loss).backward()\n",
        "            if self.hparams.clip_grad_norm >= 0:\n",
        "                self.scaler.unscale_(self.optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(\n",
        "                    self.modules.parameters(),\n",
        "                    self.hparams.clip_grad_norm,\n",
        "                )\n",
        "            self.scaler.step(self.optimizer)\n",
        "            self.scaler.update()\n",
        "        else:\n",
        "            self.nonfinite_count += 1\n",
        "            logger.info(\n",
        "                \"infinite loss or empty loss! it happened {} times so far - skipping this batch\".format(\n",
        "                    self.nonfinite_count\n",
        "                )\n",
        "            )\n",
        "            loss.data = torch.tensor(0.0).to(self.device)\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        return loss.detach().cpu()\n",
        "\n",
        "    def evaluate_batch(self, batch, stage):\n",
        "        \"\"\"Computations needed for validation/test batches\"\"\"\n",
        "        snt_id = batch.track_id\n",
        "        mixture = batch.mix_sig\n",
        "        targets = [batch.voc_sig, batch.inst_sig]\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            predictions, targets = self.compute_forward(mixture, targets, stage)\n",
        "            loss = self.compute_objectives(predictions, targets)\n",
        "\n",
        "        # Manage audio file saving\n",
        "        if stage == sb.Stage.TEST and self.hparams.save_audio:\n",
        "            if hasattr(self.hparams, \"n_audio_to_save\"):\n",
        "                if self.hparams.n_audio_to_save > 0:\n",
        "                    self.save_audio(snt_id[0], mixture, targets, predictions)\n",
        "                    self.hparams.n_audio_to_save += -1\n",
        "            else:\n",
        "                self.save_audio(snt_id[0], mixture, targets, predictions)\n",
        "\n",
        "        return loss.mean().detach()\n",
        "\n",
        "    def on_stage_end(self, stage, stage_loss, epoch):\n",
        "        \"\"\"Gets called at the end of a epoch.\"\"\"\n",
        "        # Compute/store important stats\n",
        "        stage_stats = {\"si-snr\": stage_loss}\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            self.train_stats = stage_stats\n",
        "\n",
        "        # Perform end-of-iteration things, like annealing, logging, etc.\n",
        "        if stage == sb.Stage.VALID:\n",
        "            # Learning rate annealing\n",
        "            if isinstance(\n",
        "                self.hparams.lr_scheduler, schedulers.ReduceLROnPlateau\n",
        "            ):\n",
        "                current_lr, next_lr = self.hparams.lr_scheduler(\n",
        "                    [self.optimizer], epoch, stage_loss\n",
        "                )\n",
        "                schedulers.update_learning_rate(self.optimizer, next_lr)\n",
        "            else:\n",
        "                # if we do not use the reducelronplateau, we do not change the lr\n",
        "                current_lr = self.hparams.optimizer.optim.param_groups[0][\"lr\"]\n",
        "\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                stats_meta={\"epoch\": epoch, \"lr\": current_lr},\n",
        "                train_stats=self.train_stats,\n",
        "                valid_stats=stage_stats,\n",
        "            )\n",
        "            self.checkpointer.save_and_keep_only(\n",
        "                meta={\"si-snr\": stage_stats[\"si-snr\"]}, min_keys=[\"si-snr\"]\n",
        "            )\n",
        "        elif stage == sb.Stage.TEST:\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                stats_meta={\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
        "                test_stats=stage_stats,\n",
        "            )\n",
        "\n",
        "\n",
        "    def save_results(self, test_data):\n",
        "        \"\"\"This script computes the SDR and SI-SNR metrics and saves\n",
        "        them into a csv file\"\"\"\n",
        "\n",
        "        # This package is required for SDR computation\n",
        "        from mir_eval.separation import bss_eval_sources\n",
        "\n",
        "        # Create folders where to store audio\n",
        "        save_file = os.path.join(self.hparams.output_folder, \"test_results.csv\")\n",
        "\n",
        "        # Variable init\n",
        "        all_sdrs = []\n",
        "        all_sdrs_i = []\n",
        "        all_sisnrs = []\n",
        "        all_sisnrs_i = []\n",
        "        csv_columns = [\"snt_id\", \"sdr\", \"sdr_i\", \"si-snr\", \"si-snr_i\"]\n",
        "\n",
        "        test_loader = sb.dataio.dataloader.make_dataloader(\n",
        "            test_data, **self.hparams.dataloader_opts\n",
        "        )\n",
        "\n",
        "        with open(save_file, \"w\", newline=\"\", encoding=\"utf-8\") as results_csv:\n",
        "            writer = csv.DictWriter(results_csv, fieldnames=csv_columns)\n",
        "            writer.writeheader()\n",
        "\n",
        "            # Loop over all test sentence\n",
        "            with tqdm(test_loader, dynamic_ncols=True) as t:\n",
        "                for i, batch in enumerate(t):\n",
        "                    # Apply Separation\n",
        "                    mixture, mix_len = batch.mix_sig\n",
        "                    snt_id = batch.track_id\n",
        "                    targets = [batch.voc_sig, batch.inst_sig]\n",
        "\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        predictions, targets = self.compute_forward(\n",
        "                            batch.mix_sig, targets, sb.Stage.TEST\n",
        "                        )\n",
        "\n",
        "                    # Compute SI-SNR\n",
        "                    predictions = predictions.permute(0,2,1,3).squeeze(dim=-1)\n",
        "                    targets = targets.permute(0,2,1,3).squeeze(dim=-1)\n",
        "                    # print(predictions.size())\n",
        "                    # print(targets.size())\n",
        "                    sisnr = get_si_snr_with_pitwrapper(predictions, targets)\n",
        "\n",
        "                    # Compute SI-SNR improvement\n",
        "                    mixture_signal = torch.stack(\n",
        "                        [mixture] * self.hparams.num_sources, dim=-1\n",
        "                    ).permute(0,2,1,3).squeeze(dim=-1)\n",
        "                    # print(\"---------------------\")\n",
        "                    # print(mixture.size())\n",
        "                    # print(mixture_signal.size())\n",
        "\n",
        "                    mixture_signal = mixture_signal.to(targets.device)\n",
        "                    sisnr_baseline = get_si_snr_with_pitwrapper(\n",
        "                        mixture_signal, targets\n",
        "                    )\n",
        "                    sisnr_i = sisnr - sisnr_baseline\n",
        "\n",
        "                    # Compute SDR\n",
        "                    sdr, _, _, _ = bss_eval_sources(\n",
        "                        targets[0].mean(dim=1).t().cpu().numpy(),\n",
        "                        predictions[0].mean(dim=1).t().detach().cpu().numpy(),\n",
        "                    )\n",
        "\n",
        "                    sdr_baseline, _, _, _ = bss_eval_sources(\n",
        "                        targets[0].mean(dim=1).t().cpu().numpy(),\n",
        "                        mixture_signal[0].mean(dim=1).t().detach().cpu().numpy(),\n",
        "                    )\n",
        "\n",
        "                    sdr_i = sdr.mean() - sdr_baseline.mean()\n",
        "\n",
        "                    # Saving on a csv file\n",
        "                    row = {\n",
        "                        \"snt_id\": snt_id[0],\n",
        "                        \"sdr\": sdr.mean(),\n",
        "                        \"sdr_i\": sdr_i,\n",
        "                        \"si-snr\": -sisnr.item(),\n",
        "                        \"si-snr_i\": -sisnr_i.item(),\n",
        "                    }\n",
        "                    writer.writerow(row)\n",
        "\n",
        "                    # Metric Accumulation\n",
        "                    all_sdrs.append(sdr.mean())\n",
        "                    all_sdrs_i.append(sdr_i.mean())\n",
        "                    all_sisnrs.append(-sisnr.item())\n",
        "                    all_sisnrs_i.append(-sisnr_i.item())\n",
        "\n",
        "                row = {\n",
        "                    \"snt_id\": \"avg\",\n",
        "                    \"sdr\": np.array(all_sdrs).mean(),\n",
        "                    \"sdr_i\": np.array(all_sdrs_i).mean(),\n",
        "                    \"si-snr\": np.array(all_sisnrs).mean(),\n",
        "                    \"si-snr_i\": np.array(all_sisnrs_i).mean(),\n",
        "                }\n",
        "                writer.writerow(row)\n",
        "\n",
        "        logger.info(\"Mean SISNR is {}\".format(np.array(all_sisnrs).mean()))\n",
        "        logger.info(\"Mean SISNRi is {}\".format(np.array(all_sisnrs_i).mean()))\n",
        "        logger.info(\"Mean SDR is {}\".format(np.array(all_sdrs).mean()))\n",
        "        logger.info(\"Mean SDRi is {}\".format(np.array(all_sdrs_i).mean()))\n",
        "\n",
        "    def save_audio(self, snt_id, mixture, targets, predictions):\n",
        "        \"saves the test audio (mixture, targets, and estimated sources) on disk\"\n",
        "\n",
        "        # Create output folder\n",
        "\n",
        "        save_path = os.path.join(self.hparams.save_folder, \"audio_results\")\n",
        "        if not os.path.exists(save_path):\n",
        "            os.mkdir(save_path)\n",
        "\n",
        "        for ns in range(self.hparams.num_sources):\n",
        "            # Estimated source\n",
        "            signal = predictions[0,: , :, ns]\n",
        "            signal = signal / signal.abs().max()\n",
        "            print(signal.size())\n",
        "            save_file = os.path.join(\n",
        "                save_path, \"item{}_source{}hat.wav\".format(snt_id, ns + 1)\n",
        "            )\n",
        "            torchaudio.save(\n",
        "                save_file, signal.cpu(), self.hparams.sample_rate\n",
        "            )\n",
        "\n",
        "            # Original source\n",
        "            signal = targets[0, :, : , ns]\n",
        "            signal = signal / signal.abs().max()\n",
        "            save_file = os.path.join(\n",
        "                save_path, \"item{}_source{}.wav\".format(snt_id, ns + 1)\n",
        "            )\n",
        "            torchaudio.save(\n",
        "                save_file, signal.cpu(), self.hparams.sample_rate\n",
        "            )\n",
        "\n",
        "        # Mixture\n",
        "        signal = mixture[0][0, :]\n",
        "        signal = signal / signal.abs().max()\n",
        "        print(signal.size())\n",
        "        save_file = os.path.join(save_path, \"item{}_mix.wav\".format(snt_id))\n",
        "        torchaudio.save(\n",
        "            save_file, signal.cpu(), self.hparams.sample_rate\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load hyperparameters file with command-line overrides\n",
        "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
        "    with open(hparams_file, encoding=\"utf-8\") as fin:\n",
        "        hparams = load_hyperpyyaml(fin, overrides)\n",
        "\n",
        "    # Initialize ddp (useful only for multi-GPU DDP training)\n",
        "    sb.utils.distributed.ddp_init_group(run_opts)\n",
        "\n",
        "    # Logger info\n",
        "    logger = get_logger(__name__)\n",
        "\n",
        "    # Create experiment directory\n",
        "    sb.create_experiment_directory(\n",
        "        experiment_directory=hparams[\"output_folder\"],\n",
        "        hyperparams_to_save=hparams_file,\n",
        "        overrides=overrides,\n",
        "    )\n",
        "\n",
        "    # Update precision to bf16 if the device is CPU and precision is fp16\n",
        "    if run_opts.get(\"device\") == \"cpu\" and hparams.get(\"precision\") == \"fp16\":\n",
        "        hparams[\"precision\"] = \"bf16\"\n",
        "\n",
        "\n",
        "\n",
        "        # Usage with SpeechBrain\n",
        "    train_data = LazyMusDBDataset(hparams[\"db_path\"], subset=\"train\", split=\"train\", target_sr=hparams[\"sample_rate\"], chunk_size=30)\n",
        "    valid_data = LazyMusDBDataset(hparams[\"db_path\"], subset=\"train\", split=\"valid\", target_sr=hparams[\"sample_rate\"], chunk_size=30)\n",
        "    test_data = LazyMusDBDataset(hparams[\"db_path\"], subset=\"test\", target_sr=hparams[\"sample_rate\"])\n",
        "\n",
        "\n",
        "    # Create DataLoader\n",
        "    train_loader = sb.dataio.dataloader.make_dataloader(\n",
        "        train_data,\n",
        "        batch_size=1,\n",
        "        collate_fn=sb.dataio.batch.PaddedBatch  # Handles variable lengths\n",
        "    )\n",
        "\n",
        "    valid_loader = sb.dataio.dataloader.make_dataloader(\n",
        "        valid_data,\n",
        "        batch_size=1,\n",
        "        collate_fn=sb.dataio.batch.PaddedBatch  # Handles variable lengths\n",
        "    )\n",
        "\n",
        "\n",
        "    # Brain class initialization\n",
        "    separator = DemucsSeparation(\n",
        "        modules=hparams[\"modules\"],\n",
        "        opt_class=hparams[\"optimizer\"],\n",
        "        hparams=hparams,\n",
        "        run_opts=run_opts,\n",
        "        checkpointer=hparams[\"checkpointer\"],\n",
        "    )\n",
        "\n",
        "\n",
        "    # Training\n",
        "    separator.fit(\n",
        "        separator.hparams.epoch_counter,\n",
        "        train_loader,\n",
        "        valid_loader,\n",
        "        train_loader_kwargs=hparams[\"dataloader_opts\"],\n",
        "        valid_loader_kwargs=hparams[\"dataloader_opts\"],\n",
        "    )\n",
        "\n",
        "    # Eval\n",
        "    separator.evaluate(test_data, min_key=\"si-snr\")\n",
        "    separator.save_results(test_data)\n",
        "    ## CHECKPOINT"
      ],
      "metadata": {
        "trusted": true,
        "id": "93qvrgMl1PHU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "yhyQf2pY1PHW"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}
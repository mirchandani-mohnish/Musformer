{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10005918,"sourceType":"datasetVersion","datasetId":6159348}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-31T19:40:43.832191Z","iopub.execute_input":"2025-03-31T19:40:43.832529Z","iopub.status.idle":"2025-03-31T19:40:43.870121Z","shell.execute_reply.started":"2025-03-31T19:40:43.832503Z","shell.execute_reply":"2025-03-31T19:40:43.869091Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/musdb18-music-source-separation-dataset/The Long Wait - Dark Horses.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Raft Monk - Tiring.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/BKS - Too Much.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Georgia Wonder - Siren.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/The Sunshine Garcia Band - For I Am The Moon.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Enda Reilly - Cur An Long Ag Seol.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Buitraker - Revo X.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/We Fell From The Sky - Not You.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/The Mountaineering Club - Mallory.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Skelpolu - Resurrection.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Secretariat - Over The Top.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Bobby Nobody - Stitch Up.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Arise - Run Run Run.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Carlos Gonzalez - A Place For Us.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Forkupines - Semantics.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/The Easton Ellises - Falcon 69.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Lyndsey Ollard - Catching Up.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Triviul feat. The Fiend - Widow.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Louis Cressy Band - Good Time.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Motor Tapes - Shore.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/AM Contra - Heart Peripheral.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Signe Jakobsen - What Have You Done To Me.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Moosmusic - Big Dummy Shake.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/M.E.R.C. Music - Knockout.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/The Doppler Shift - Atrophy.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Detsky Sad - Walkie Talkie.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/PR - Happy Daze.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Timboz - Pony.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/PR - Oh No.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Mu - Too Bright.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Hollow Ground - Ill Fate.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/The Easton Ellises (Baumi) - SDRNR.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Speak Softly - Like Horses.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Sambasevam Shanmugam - Kaathaadi.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Tom McKenzie - Directions.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Secretariat - Borderline.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Side Effects Project - Sing With Me.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Nerve 9 - Pray For The Rain.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Zeno - Signs.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Girls Under Glass - We Feel Alright.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Cristina Vane - So Easy.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Speak Softly - Broken Man.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/BKS - Bulldozer.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Punkdisco - Oral Hygiene.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/test/Al James - Schoolboy Facination.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Dark Ride - Burning Bridges.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Drumtracks - Ghost Bitch.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Aimee Norwich - Child.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/James May - If You Say.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Rockabilly.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Steven Clark - Bounty.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Giselle - Moss.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Strand Of Oaks - Spacestation.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Patrick Talbot - Set Me Free.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Bill Chudziak - Children Of No-one.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Angela Thomas Wade - Milk Cow Blues.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Grants - PunchDrunk.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Grunge.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Traffic Experiment - Once More (With Feeling).stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Beatles.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Auctioneer - Our Future Faces.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Clara Berry And Wooldog - Air Traffic.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Patrick Talbot - A Reason To Leave.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/The Districts - Vermont.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Leaf - Come Around.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/North To Alaska - All The Same.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Skelpolu - Human Mistakes.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Dreamers Of The Ghetto - Heavy Love.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/ANiMAL - Rockshow.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Faces On Film - Waiting For Ga.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Snowmine - Curfews.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Swinging Steaks - Lost My Way.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Triviul - Dorothy.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Gospel.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Clara Berry And Wooldog - Stella.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Disco.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Reggae.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/The So So Glos - Emergency.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Leaf - Wicked.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/St Vitus - Word Gets Around.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Celestial Shore - Die For Us.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Young Griffo - Facade.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/AvaLuna - Waterduct.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Punk.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Actions - One Minute Smile.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Young Griffo - Blood To Bone.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Tim Taler - Stalker.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Hendrix.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Leaf - Summerghost.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Hop Along - Sister Cities.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/James May - All Souls Moon.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Meaxic - You Listen.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Country2.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/ANiMAL - Clinic A.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Traffic Experiment - Sirens.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Britpop.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Rock.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Chris Durban - Celebrate.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Triviul - Angelsaint.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/James May - On The Line.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/A Classic Education - NightOwl.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Skelpolu - Together Alone.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Titanium - Haunted Age.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Alexander Ross - Goodbye Bolero.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Secret Mountains - High Horse.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Wall Of Death - Femme.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Fergessen - The Wind.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Alexander Ross - Velvet Curtain.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Johnny Lokke - Whisper To A Scream.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Meaxic - Take A Step.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Jay Menon - Through My Eyes.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Flags - 54.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Clara Berry And Wooldog - Waltz For My Victims.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/ANiMAL - Easy Tiger.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Fergessen - Back From The Start.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Hollow Ground - Left Blind.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Sweet Lights - You Let Me Down.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Port St Willow - Stay Even.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Helado Negro - Mitad Del Mundo.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Black Bloc - If You Want Success.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Young Griffo - Pennies.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Voelund - Comfort Lives In Belief.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Fergessen - Nos Palpitants.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Creepoid - OldTree.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Actions - South Of The Water.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Lushlife - Toynbee Suite.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Matthew Entwistle - Dont You Ever.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/The Scarlet Brand - Les Fleurs Du Mal.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - Country1.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/James May - Dont Let Go.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Music Delta - 80s Rock.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Atlantis Bound - It Was My Fault For Waiting.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Invisible Familiars - Disturbing Wildlife.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Cnoc An Tursa - Bannockburn.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Hezekiah Jones - Borrowed Heart.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/BigTroubles - Phantom.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Remember December - C U Next Time.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/Night Panther - Fire.stem.mp4\n/kaggle/input/musdb18-music-source-separation-dataset/train/The Long Wait - Back Home To Blue.stem.mp4\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!pip install musdb\n!pip install mir_eval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T19:40:43.871316Z","iopub.execute_input":"2025-03-31T19:40:43.871761Z","iopub.status.idle":"2025-03-31T19:40:52.605566Z","shell.execute_reply.started":"2025-03-31T19:40:43.871716Z","shell.execute_reply":"2025-03-31T19:40:52.604263Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: musdb in /usr/local/lib/python3.10/dist-packages (0.4.2)\nRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.10/dist-packages (from musdb) (1.26.4)\nRequirement already satisfied: stempeg>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from musdb) (0.2.3)\nRequirement already satisfied: pyaml in /usr/local/lib/python3.10/dist-packages (from musdb) (25.1.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from musdb) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.7->musdb) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.7->musdb) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.7->musdb) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.7->musdb) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.7->musdb) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.7->musdb) (2.4.1)\nRequirement already satisfied: ffmpeg-python>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from stempeg>=0.2.3->musdb) (0.2.0)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml->musdb) (6.0.2)\nRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python>=0.2.0->stempeg>=0.2.3->musdb) (1.0.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.7->musdb) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.7->musdb) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.7->musdb) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.7->musdb) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.7->musdb) (2024.2.0)\nRequirement already satisfied: mir_eval in /usr/local/lib/python3.10/dist-packages (0.8.2)\nRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from mir_eval) (1.26.4)\nRequirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mir_eval) (1.13.1)\nRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mir_eval) (4.4.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.15.4->mir_eval) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.15.4->mir_eval) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.15.4->mir_eval) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.15.4->mir_eval) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.15.4->mir_eval) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.15.4->mir_eval) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.15.4->mir_eval) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.15.4->mir_eval) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.15.4->mir_eval) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.15.4->mir_eval) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.15.4->mir_eval) (2024.2.0)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"\n%%capture\n# Installing SpeechBrain via pip\nBRANCH = 'develop'\n!python -m pip install git+https://github.com/speechbrain/speechbrain.git@$BRANCH\n\n# Clone SpeechBrain repository\n!git clone https://github.com/speechbrain/speechbrain/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T19:40:52.607671Z","iopub.execute_input":"2025-03-31T19:40:52.608048Z","iopub.status.idle":"2025-03-31T19:41:07.453573Z","shell.execute_reply.started":"2025-03-31T19:40:52.608017Z","shell.execute_reply":"2025-03-31T19:41:07.452165Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"db_path = '/kaggle/input/musdb18-music-source-separation-dataset'\noutput_path = '/kaggle/working'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T19:42:06.770126Z","iopub.execute_input":"2025-03-31T19:42:06.770515Z","iopub.status.idle":"2025-03-31T19:42:06.775868Z","shell.execute_reply.started":"2025-03-31T19:42:06.770484Z","shell.execute_reply":"2025-03-31T19:42:06.774393Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"%%file hparams.yaml\n# ################################\n# Model: SepFormer for source separation\n# https://arxiv.org/abs/2010.13154\n# Dataset : WSJ0-2mix and WSJ0-3mix\n# ################################\n# Basic parameters\n# Seed needs to be set at top of yaml, before objects with parameters are made\n#\n\nseed: 1234\n__set_seed: !apply:speechbrain.utils.seed_everything [!ref <seed>]\n\n# Data params\n\n# e.g. '/yourpath/wsj0-mix/2speakers'\n# end with 2speakers for wsj0-2mix or 3speakers for wsj0-3mix\ndata_folder: !PLACEHOLDER\n\n# the path for wsj0/si_tr_s/ folder -- only needed if dynamic mixing is used\n# e.g. /yourpath/wsj0-processed/si_tr_s/\nbase_folder_dm: /yourpath/wsj0-processed/si_tr_s/\n\nexperiment_name: convtasnet\noutput_folder: !ref /kaggle/working/results/<experiment_name>/<seed>\ntrain_log: !ref <output_folder>/train_log.txt\nsave_folder: !ref <output_folder>/save\ntrain_data: !ref <output_folder>/train.json\nvalid_data: !ref <output_folder>/valid.json\ntest_data: !ref <output_folder>/test.json\nskip_prep: False\ndb_path: '/kaggle/input/musdb18-music-source-separation-dataset'\n\n\n# Experiment params\nprecision: fp16 # bf16, fp16 or fp32\nnum_spks: 2 # set to 3 for wsj0-3mix\nnoprogressbar: False\nsave_audio: True # Save estimated sources on disk\nsample_rate: 8000\n\n####################### Training Parameters ####################################\nN_epochs: 90\nbatch_size: 1\nlr: 0.00015\nclip_grad_norm: 5\nloss_upper_lim: 999999  # this is the upper limit for an acceptable loss\n# if True, the training sequences are cut to a specified length\nlimit_training_signal_len: True\n# this is the length of sequences if we choose to limit\n# the signal length of training sequences\ntraining_signal_len: 240000 # shoudl give 30 seconds of audio\n\n# Set it to True to dynamically create mixtures at training time\ndynamic_mixing: False\n\n# Parameters for data augmentation\nuse_wavedrop: False\nuse_speedperturb: True\nuse_rand_shift: False\nmin_shift: -8000\nmax_shift: 8000\n\n# Speed perturbation\nspeed_changes: [95, 100, 105]  # List of speed changes for time-stretching\n\nspeed_perturb: !new:speechbrain.augment.time_domain.SpeedPerturb\n    orig_freq: !ref <sample_rate>\n    speeds: !ref <speed_changes>\n\n# Frequency drop: randomly drops a number of frequency bands to zero.\ndrop_freq_low: 0  # Min frequency band dropout probability\ndrop_freq_high: 1  # Max frequency band dropout probability\ndrop_freq_count_low: 1  # Min number of frequency bands to drop\ndrop_freq_count_high: 3  # Max number of frequency bands to drop\ndrop_freq_width: 0.05  # Width of frequency bands to drop\n\ndrop_freq: !new:speechbrain.augment.time_domain.DropFreq\n    drop_freq_low: !ref <drop_freq_low>\n    drop_freq_high: !ref <drop_freq_high>\n    drop_freq_count_low: !ref <drop_freq_count_low>\n    drop_freq_count_high: !ref <drop_freq_count_high>\n    drop_freq_width: !ref <drop_freq_width>\n\n# Time drop: randomly drops a number of temporal chunks.\ndrop_chunk_count_low: 1  # Min number of audio chunks to drop\ndrop_chunk_count_high: 5  # Max number of audio chunks to drop\ndrop_chunk_length_low: 1000  # Min length of audio chunks to drop\ndrop_chunk_length_high: 2000  # Max length of audio chunks to drop\n\ndrop_chunk: !new:speechbrain.augment.time_domain.DropChunk\n    drop_length_low: !ref <drop_chunk_length_low>\n    drop_length_high: !ref <drop_chunk_length_high>\n    drop_count_low: !ref <drop_chunk_count_low>\n    drop_count_high: !ref <drop_chunk_count_high>\n\n# loss thresholding -- this thresholds the training loss\nthreshold_byloss: True\nthreshold: -30\n\n# Encoder parameters\nN_encoder_out: 256\n# out_channels: 256\nkernel_size: 16\nkernel_stride: 8\n\n# Dataloader options\ndataloader_opts:\n    batch_size: !ref <batch_size>\n    num_workers: 1\n\n\n# Specifying the network\nEncoder: !new:speechbrain.lobes.models.dual_path.Encoder\n    kernel_size: !ref <kernel_size>\n    out_channels: !ref <N_encoder_out>\n\n# intra: !new:speechbrain.lobes.models.dual_path.SBRNNBlock\n#    num_layers: 1\n#    input_size: !ref <out_channels>\n#    hidden_channels: !ref <out_channels>\n#    dropout: 0\n#    bidirectional: True\n\n# inter: !new:speechbrain.lobes.models.dual_path.SBRNNBlock\n#    num_layers: 1\n#    input_size: !ref <out_channels>\n#    hidden_channels: !ref <out_channels>\n#    dropout: 0\n#    bidirectional: True\n\nMaskNet: !new:speechbrain.lobes.models.conv_tasnet.MaskNet\n    N: 256\n    B: 256\n    H: 512\n    P: 3\n    X: 6\n    R: 4\n    C: !ref <num_spks>\n    norm_type: 'gLN'\n    causal: True\n    mask_nonlinear: 'relu'\n\nDecoder: !new:speechbrain.lobes.models.dual_path.Decoder\n    in_channels: !ref <N_encoder_out>\n    out_channels: 1\n    kernel_size: !ref <kernel_size>\n    stride: !ref <kernel_stride>\n    bias: False\n\noptimizer: !name:torch.optim.Adam\n    lr: !ref <lr>\n    weight_decay: 0\n\nloss: !name:speechbrain.nnet.losses.get_si_snr_with_pitwrapper\n\nlr_scheduler: !new:speechbrain.nnet.schedulers.ReduceLROnPlateau\n    factor: 0.5\n    patience: 2\n    dont_halve_until_epoch: 85\n\nepoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n    limit: !ref <N_epochs>\n\nmodules:\n    encoder: !ref <Encoder>\n    decoder: !ref <Decoder>\n    masknet: !ref <MaskNet>\n\ncheckpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n    checkpoints_dir: !ref <save_folder>\n    recoverables:\n        encoder: !ref <Encoder>\n        decoder: !ref <Decoder>\n        masknet: !ref <MaskNet>\n        counter: !ref <epoch_counter>\n        lr_scheduler: !ref <lr_scheduler>\n\ntrain_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n    save_file: !ref <train_log>","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T19:42:09.182295Z","iopub.execute_input":"2025-03-31T19:42:09.182682Z","iopub.status.idle":"2025-03-31T19:42:09.191499Z","shell.execute_reply.started":"2025-03-31T19:42:09.182655Z","shell.execute_reply":"2025-03-31T19:42:09.190191Z"}},"outputs":[{"name":"stdout","text":"Writing hparams.yaml\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"%%file train.py\n#!/usr/bin/env/python3\n\"\"\"Recipe for training a neural speech separation system on the wsjmix\ndataset. The system employs an encoder, a decoder, and a masking network.\n\nTo run this recipe, do the following:\n> python train.py hparams/sepformer.yaml\n> python train.py hparams/dualpath_rnn.yaml\n> python train.py hparams/convtasnet.yaml\n\nThe experiment file is flexible enough to support different neural\nnetworks. By properly changing the parameter files, you can try\ndifferent architectures. The script supports both wsj2mix and\nwsj3mix.\n\n\nAuthors\n * Cem Subakan 2020\n * Mirco Ravanelli 2020\n * Samuele Cornell 2020\n * Mirko Bronzi 2020\n * Jianyuan Zhong 2020\n\"\"\"\n\nimport csv\nimport os\nimport sys\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport torchaudio\nfrom hyperpyyaml import load_hyperpyyaml\nfrom tqdm import tqdm\nimport pdb\n\nimport speechbrain as sb\nimport speechbrain.nnet.schedulers as schedulers\nfrom speechbrain.core import AMPConfig\nfrom speechbrain.utils.distributed import run_on_main\nfrom speechbrain.utils.logger import get_logger\nimport time\nfrom torch.utils.data import DataLoader\n\nimport musdb\n\n\n\n# Define training procedure\nclass Separation(sb.Brain):\n    def compute_forward(self, mix, targets, stage, noise=None):\n        \"\"\"Forward computations from the mixture to the separated signals.\"\"\"\n\n        # Unpack lists and put tensors in the right device\n        \n        mix, mix_lens = mix\n        \n        mix, mix_lens = mix.to(self.device), mix_lens.to(self.device)\n        \n\n        # Convert targets to tensor\n        targets = torch.cat(\n            [targets[i][0].unsqueeze(-1) for i in range(self.hparams.num_spks)],\n            dim=-1,\n        ).to(self.device)\n\n        # Add speech distortions\n        if stage == sb.Stage.TRAIN:\n            with torch.no_grad():\n      \n                if self.hparams.use_wavedrop:\n                    mix = self.hparams.drop_chunk(mix, mix_lens)\n                    mix = self.hparams.drop_freq(mix)\n\n                if self.hparams.limit_training_signal_len:\n                    mix, targets = self.cut_signals(mix, targets)\n\n        # Separation\n        mix_w = self.hparams.Encoder(mix)\n        est_mask = self.hparams.MaskNet(mix_w)\n        mix_w = torch.stack([mix_w] * self.hparams.num_spks)\n        sep_h = mix_w * est_mask\n\n        # Decoding\n        est_source = torch.cat(\n            [\n                self.hparams.Decoder(sep_h[i]).unsqueeze(-1)\n                for i in range(self.hparams.num_spks)\n            ],\n            dim=-1,\n        )\n\n        # T changed after conv1d in encoder, fix it here\n        T_origin = mix.size(1)\n        T_est = est_source.size(1)\n        if T_origin > T_est:\n            est_source = F.pad(est_source, (0, 0, 0, T_origin - T_est))\n        else:\n            est_source = est_source[:, :T_origin, :]\n\n        # pdb.set_trace()\n        \n\n        return est_source, targets\n\n    def compute_objectives(self, predictions, targets):\n        \"\"\"Computes the sinr loss\"\"\"\n        return self.hparams.loss(targets, predictions)\n\n    def fit_batch(self, batch):\n        \"\"\"Trains one batch\"\"\"\n\n        \n        amp = AMPConfig.from_name(self.precision)\n        should_step = (self.step % self.grad_accumulation_factor) == 0\n        # Unpacking batch list\n        mixture = batch.mix_sig\n        targets = [batch.voc_sig, batch.inst_sig] #mix_sig, voc_sig, inst_sig\n        predictions, targets = self.compute_forward(\n            mixture, targets, sb.Stage.TRAIN\n        )\n        loss = self.compute_objectives(predictions, targets)\n\n        if self.hparams.threshold_byloss:\n            th = self.hparams.threshold\n            loss = loss[loss > th]\n            if loss.nelement() > 0:\n                loss = loss.mean()\n        else:\n            loss = loss.mean()\n\n        if (\n            loss.nelement() > 0 and loss < self.hparams.loss_upper_lim\n        ):  # the fix for computational problems\n            loss.backward()\n            if self.hparams.clip_grad_norm >= 0:\n                torch.nn.utils.clip_grad_norm_(\n                    self.modules.parameters(),\n                    self.hparams.clip_grad_norm,\n                )\n            self.optimizer.step()\n        else:\n            self.nonfinite_count += 1\n            logger.info(\n                \"infinite loss or empty loss! it happened {} times so far - skipping this batch\".format(\n                    self.nonfinite_count\n                )\n            )\n            loss.data = torch.tensor(0.0).to(self.device)\n        self.optimizer.zero_grad()\n\n        return loss.detach().cpu()\n\n    def evaluate_batch(self, batch, stage):\n        \"\"\"Computations needed for validation/test batches\"\"\"\n        snt_id = batch.track_id\n        mixture = batch.mix_sig\n        targets = [batch.voc_sig, batch.inst_sig]\n     \n        with torch.no_grad():\n            predictions, targets = self.compute_forward(mixture, targets, stage)\n            loss = self.compute_objectives(predictions, targets)\n\n        # Manage audio file saving\n        if stage == sb.Stage.TEST and self.hparams.save_audio:\n            if hasattr(self.hparams, \"n_audio_to_save\"):\n                if self.hparams.n_audio_to_save > 0:\n                    self.save_audio(snt_id[0], mixture, targets, predictions)\n                    self.hparams.n_audio_to_save += -1\n            else:\n                self.save_audio(snt_id[0], mixture, targets, predictions)\n\n        return loss.mean().detach()\n\n    def on_stage_end(self, stage, stage_loss, epoch):\n        \"\"\"Gets called at the end of a epoch.\"\"\"\n        # Compute/store important stats\n        stage_stats = {\"si-snr\": stage_loss}\n        if stage == sb.Stage.TRAIN:\n            self.train_stats = stage_stats\n\n        # Perform end-of-iteration things, like annealing, logging, etc.\n        if stage == sb.Stage.VALID:\n            # Learning rate annealing\n            if isinstance(\n                self.hparams.lr_scheduler, schedulers.ReduceLROnPlateau\n            ):\n                current_lr, next_lr = self.hparams.lr_scheduler(\n                    [self.optimizer], epoch, stage_loss\n                )\n                schedulers.update_learning_rate(self.optimizer, next_lr)\n            else:\n                # if we do not use the reducelronplateau, we do not change the lr\n                current_lr = self.hparams.optimizer.optim.param_groups[0][\"lr\"]\n\n            self.hparams.train_logger.log_stats(\n                stats_meta={\"epoch\": epoch, \"lr\": current_lr},\n                train_stats=self.train_stats,\n                valid_stats=stage_stats,\n            )\n            self.checkpointer.save_and_keep_only(\n                meta={\"si-snr\": stage_stats[\"si-snr\"]}, min_keys=[\"si-snr\"]\n            )\n        elif stage == sb.Stage.TEST:\n            self.hparams.train_logger.log_stats(\n                stats_meta={\"Epoch loaded\": self.hparams.epoch_counter.current},\n                test_stats=stage_stats,\n            )\n\n\n    def cut_signals(self, mixture, targets):\n        \"\"\"This function selects a random segment of a given length within the mixture.\n        The corresponding targets are selected accordingly\"\"\"\n        randstart = torch.randint(\n            0,\n            1 + max(0, mixture.shape[1] - self.hparams.training_signal_len),\n            (1,),\n        ).item()\n        targets = targets[\n            :, randstart : randstart + self.hparams.training_signal_len, :\n        ]\n        mixture = mixture[\n            :, randstart : randstart + self.hparams.training_signal_len\n        ]\n        return mixture, targets\n\n    def reset_layer_recursively(self, layer):\n        \"\"\"Reinitializes the parameters of the neural networks\"\"\"\n        if hasattr(layer, \"reset_parameters\"):\n            layer.reset_parameters()\n        for child_layer in layer.modules():\n            if layer != child_layer:\n                self.reset_layer_recursively(child_layer)\n\n    def save_results(self, test_data):\n        \"\"\"This script computes the SDR and SI-SNR metrics and saves\n        them into a csv file\"\"\"\n\n        # This package is required for SDR computation\n        from mir_eval.separation import bss_eval_sources\n\n        # Create folders where to store audio\n        save_file = os.path.join(self.hparams.output_folder, \"test_results.csv\")\n\n        # Variable init\n        all_sdrs = []\n        all_sdrs_i = []\n        all_sisnrs = []\n        all_sisnrs_i = []\n        csv_columns = [\"snt_id\", \"sdr\", \"sdr_i\", \"si-snr\", \"si-snr_i\"]\n\n        test_loader = sb.dataio.dataloader.make_dataloader(\n            test_data, **self.hparams.dataloader_opts\n        )\n\n        with open(save_file, \"w\", newline=\"\", encoding=\"utf-8\") as results_csv:\n            writer = csv.DictWriter(results_csv, fieldnames=csv_columns)\n            writer.writeheader()\n\n            # Loop over all test sentence\n            with tqdm(test_loader, dynamic_ncols=True) as t:\n                for i, batch in enumerate(t):\n                    # Apply Separation\n                    mixture, mix_len = batch.mix_sig\n                    snt_id = batch.track_id\n                    targets = [batch.voc_sig, batch.inst_sig]\n                   \n\n                    with torch.no_grad():\n                        predictions, targets = self.compute_forward(\n                            batch.mix_sig, targets, sb.Stage.TEST\n                        )\n\n                    # Compute SI-SNR\n                    sisnr = self.compute_objectives(predictions, targets)\n\n                    # Compute SI-SNR improvement\n                    mixture_signal = torch.stack(\n                        [mixture] * self.hparams.num_spks, dim=-1\n                    )\n                    mixture_signal = mixture_signal.to(targets.device)\n                    sisnr_baseline = self.compute_objectives(\n                        mixture_signal, targets\n                    )\n                    sisnr_i = sisnr - sisnr_baseline\n\n                    # Compute SDR\n                    sdr, _, _, _ = bss_eval_sources(\n                        targets[0].t().cpu().numpy(),\n                        predictions[0].t().detach().cpu().numpy(),\n                    )\n\n                    sdr_baseline, _, _, _ = bss_eval_sources(\n                        targets[0].t().cpu().numpy(),\n                        mixture_signal[0].t().detach().cpu().numpy(),\n                    )\n\n                    sdr_i = sdr.mean() - sdr_baseline.mean()\n\n                    # Saving on a csv file\n                    row = {\n                        \"snt_id\": snt_id[0],\n                        \"sdr\": sdr.mean(),\n                        \"sdr_i\": sdr_i,\n                        \"si-snr\": -sisnr.item(),\n                        \"si-snr_i\": -sisnr_i.item(),\n                    }\n                    writer.writerow(row)\n\n                    # Metric Accumulation\n                    all_sdrs.append(sdr.mean())\n                    all_sdrs_i.append(sdr_i.mean())\n                    all_sisnrs.append(-sisnr.item())\n                    all_sisnrs_i.append(-sisnr_i.item())\n\n                row = {\n                    \"snt_id\": \"avg\",\n                    \"sdr\": np.array(all_sdrs).mean(),\n                    \"sdr_i\": np.array(all_sdrs_i).mean(),\n                    \"si-snr\": np.array(all_sisnrs).mean(),\n                    \"si-snr_i\": np.array(all_sisnrs_i).mean(),\n                }\n                writer.writerow(row)\n\n        logger.info(\"Mean SISNR is {}\".format(np.array(all_sisnrs).mean()))\n        logger.info(\"Mean SISNRi is {}\".format(np.array(all_sisnrs_i).mean()))\n        logger.info(\"Mean SDR is {}\".format(np.array(all_sdrs).mean()))\n        logger.info(\"Mean SDRi is {}\".format(np.array(all_sdrs_i).mean()))\n\n    def save_audio(self, snt_id, mixture, targets, predictions):\n        \"saves the test audio (mixture, targets, and estimated sources) on disk\"\n\n        # Create output folder\n        save_path = os.path.join(self.hparams.save_folder, \"audio_results\")\n        if not os.path.exists(save_path):\n            os.mkdir(save_path)\n\n        for ns in range(self.hparams.num_spks):\n            # Estimated source\n            signal = predictions[0, :, ns]\n            signal = signal / signal.abs().max()\n            save_file = os.path.join(\n                save_path, \"item{}_source{}hat.wav\".format(snt_id, ns + 1)\n            )\n            torchaudio.save(\n                save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n            )\n\n            # Original source\n            signal = targets[0, :, ns]\n            signal = signal / signal.abs().max()\n            save_file = os.path.join(\n                save_path, \"item{}_source{}.wav\".format(snt_id, ns + 1)\n            )\n            torchaudio.save(\n                save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n            )\n\n        # Mixture\n        signal = mixture[0][0, :]\n        signal = signal / signal.abs().max()\n        save_file = os.path.join(save_path, \"item{}_mix.wav\".format(snt_id))\n        torchaudio.save(\n            save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n        )\n\n\ndef dataio_prep(hparams):\n    \"\"\"Creates data processing pipeline\"\"\"\n\n\n        \n    MUS_DB_PATH = hparams[\"db_path\"]\n    \n    mus = musdb.DB(root=MUS_DB_PATH)\n    \n    mus_train = musdb.DB(root=MUS_DB_PATH,subsets=\"train\", split=\"train\")\n    mus_valid = musdb.DB(root=MUS_DB_PATH,subsets=\"train\", split=\"valid\")\n    mus_test = musdb.DB(root=MUS_DB_PATH,subsets=\"test\")\n\n\n        \n    def create_json(mus_obj):\n      json_dict = {}\n      for i, track in enumerate(mus_obj):\n        \n        file_name = track.name\n        file_path = track.path\n        file_rate = track.rate\n        \n        json_dict[file_name] = {\n                  \"track\": track\n          }\n        \n        return json_dict\n          \n    train_obj = create_json(mus_train)\n    test_obj = create_json(mus_test)\n    valid_obj = create_json(mus_valid)\n    \n   \n    \n    \n  \n    def convert_musdb_to_torch(track, target_sr=8000, chunk_size_seconds=1):\n        \"\"\"\n        Converts a musdb track to a PyTorch tensor with efficient resampling.\n    \n        Args:\n            track: A musdb track object (e.g., `mus_train[0]`).\n            target_sr (int): The target sampling rate for resampling.\n            chunk_size_seconds (int): Number of seconds per processing chunk.\n    \n        Returns:\n            torch.Tensor: The resampled waveform tensor of shape (num_channels, num_samples).\n        \"\"\"\n        # Convert to tensor and move channels first (PyTorch format)\n        \n        audio_tensor = torch.from_numpy(track.audio).float().permute(1, 0)  # Shape: (num_channels, num_samples)\n        orig_sr = track.rate  # Original sample rate\n\n        chunk_size = orig_sr * chunk_size_seconds  # Convert chunk size to samples\n    \n        resampled_chunks = []\n    \n        for i in range(0, audio_tensor.shape[1], chunk_size):\n            chunk = audio_tensor[:, i:i + chunk_size]  # Extract chunk\n            resampled_chunk = torchaudio.functional.resample(chunk, orig_freq=orig_sr, new_freq=target_sr)\n            resampled_chunks.append(resampled_chunk)\n    \n        # Concatenate back the processed chunks\n        # print(\"PROCESSING CHUNKS\")\n        resampled_audio = torch.cat(resampled_chunks, dim=1)\n        # print(resampled_audio.shape)\n        resampled_audio = resampled_audio.mean(dim=0, keepdim=False)\n        # print(resampled_audio.shape)\n        # print(resampled_audio.shape)\n        return resampled_audio\n    \n    \n    @sb.utils.data_pipeline.takes(\"track\")\n    @sb.utils.data_pipeline.provides(\"track_id\",\"mix_sig\", \"voc_sig\", \"inst_sig\")\n    def audio_pipeline_mix(track):\n\n        #  track.chunk_duration = 5.0\n        # track.chunk_start = random.uniform(0, track.duration - track.chunk_duration)\n        \n        # # while True:\n        # #     track = random.choice(mus.tracks)\n        #     track.chunk_duration = 5.0\n        #     track.chunk_start = random.uniform(0, track.duration - track.chunk_duration)\n        #     x = track.audio.T\n        #     y = track.targets['vocals'].audio.T\n        \n            \n        mix_sig = convert_musdb_to_torch(track, hparams[\"sample_rate\"], chunk_size_seconds=1)\n        voc_sig = convert_musdb_to_torch(track.targets[\"vocals\"], hparams[\"sample_rate\"], chunk_size_seconds=1)\n        inst_sig = convert_musdb_to_torch(track.targets[\"accompaniment\"], hparams[\"sample_rate\"], chunk_size_seconds=1)\n        track_id = track.name\n        \n        return track_id, mix_sig, voc_sig, inst_sig\n\n\n    \n    \n    train_data = sb.dataio.dataset.DynamicItemDataset(train_obj, dynamic_items=[audio_pipeline_mix], output_keys=[\"track_id\",\"mix_sig\", \"voc_sig\", \"inst_sig\"])\n    valid_data = sb.dataio.dataset.DynamicItemDataset(valid_obj, dynamic_items=[audio_pipeline_mix], output_keys=[\"track_id\",\"mix_sig\", \"voc_sig\", \"inst_sig\"])\n    test_data = sb.dataio.dataset.DynamicItemDataset(test_obj, dynamic_items=[audio_pipeline_mix], output_keys=[\"track_id\",\"mix_sig\", \"voc_sig\", \"inst_sig\"])\n    datasets = [train_data, valid_data, test_data]\n    \n    \n    return datasets\n    \n\n\nif __name__ == \"__main__\":\n    # Load hyperparameters file with command-line overrides\n    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n    with open(hparams_file, encoding=\"utf-8\") as fin:\n        hparams = load_hyperpyyaml(fin, overrides)\n\n    # Initialize ddp (useful only for multi-GPU DDP training)\n    sb.utils.distributed.ddp_init_group(run_opts)\n\n    # Logger info\n    logger = get_logger(__name__)\n\n    # Create experiment directory\n    sb.create_experiment_directory(\n        experiment_directory=hparams[\"output_folder\"],\n        hyperparams_to_save=hparams_file,\n        overrides=overrides,\n    )\n\n    # Update precision to bf16 if the device is CPU and precision is fp16\n    if run_opts.get(\"device\") == \"cpu\" and hparams.get(\"precision\") == \"fp16\":\n        hparams[\"precision\"] = \"bf16\"\n\n    # Check if wsj0_tr is set with dynamic mixing\n    if hparams[\"dynamic_mixing\"] and not os.path.exists(\n        hparams[\"base_folder_dm\"]\n    ):\n        raise ValueError(\n            \"Please, specify a valid base_folder_dm folder when using dynamic mixing\"\n        )\n\n    \n    train_data, valid_data, test_data = dataio_prep(hparams)\n   \n     \n    print(type(train_data))\n\n    # Brain class initialization\n    separator = Separation(\n        modules=hparams[\"modules\"],\n        opt_class=hparams[\"optimizer\"],\n        hparams=hparams,\n        run_opts=run_opts,\n        checkpointer=hparams[\"checkpointer\"],\n    )\n  \n    # Training\n    # print(\"STARTING FIT\")\n    separator.fit(\n        separator.hparams.epoch_counter,\n        train_data,\n        valid_data,\n        train_loader_kwargs=hparams[\"dataloader_opts\"],\n        valid_loader_kwargs=hparams[\"dataloader_opts\"],\n    )\n\n    # # Eval\n    separator.evaluate(test_data, min_key=\"si-snr\")\n    separator.save_results(test_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# To start from scratch, you need to remove the output folder.\n# Otherwise, speechbrain starts from the last valid checkpoint.\n#!rm -rf ./results/AudioMNIST/Autoencoder/\n\n!python train.py hparams.yaml --data_folder=db_path --device \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T20:06:34.024567Z","iopub.execute_input":"2025-03-31T20:06:34.025014Z"}},"outputs":[{"name":"stdout","text":"speechbrain.utils.quirks - Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]\nspeechbrain.utils.quirks - Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\nspeechbrain.core - Beginning experiment!\nspeechbrain.core - Experiment folder: /kaggle/working/results/convtasnet/1234\n<class 'speechbrain.dataio.dataset.DynamicItemDataset'>\nspeechbrain.core - Info: precision arg from hparam file is used\nspeechbrain.core - Info: noprogressbar arg from hparam file is used\nspeechbrain.core - Gradscaler enabled: `False`\nspeechbrain.core - Using training precision: `--precision=bf16`\nspeechbrain.core - Using evaluation precision: `--eval_precision=fp32`\nspeechbrain.core - Separation Model Statistics:\n* Total Number of Trainable Parameters: 6.6M\n* Total Number of Parameters: 6.6M\n* Trainable Parameters represent 100.0000% of the total size.\nspeechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\nspeechbrain.utils.epoch_loop - Going into epoch 1\n  0%|                                                     | 0/1 [00:00<?, ?it/s]INSIDE FIT BATCH\ncompute_forward ended\n100%|███████████████████████████| 1/1 [02:09<00:00, 129.92s/it, train_loss=25.2]\n  0%|                                                     | 0/1 [00:00<?, ?it/s]","output_type":"stream"}],"execution_count":null}]}
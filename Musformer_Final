{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10005918,"sourceType":"datasetVersion","datasetId":6159348}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Musformer\nAlthough misleading, but the name seemed nice. The goal of this project is to build a source separation model in speechbrain. The idea is to replicate building a model in the waveform domain directly. We see that multiple models try to solve the music sourse separation as a problem and most state-of-the-art models reach an SiSDR ratio of 9 to tackle the same. \n\nMost models working on this problem came into existence as a solution to the SDX (Sound Demixing) challenge. A few of the existing solutions are as follows: \n- **MMDenseLSTM**: Combines dense blocks with LSTMs for lightweight waveform separation.\n- **Demucs (v1/v2)**: U-Net with bidirectional LSTMs; later versions add transformers.\n- **ConvTasNet**: Efficient temporal convolutional network with learned encoder/decoder.\n- **DPRNNet**: Dual-path RNN with attention, offering SOTA results at higher compute costs.\n- **BandSplitRNN**: Separates audio into frequency bands processed by independent RNNs before recombination.\n- **Wave-U-Net**: Adapts medical imaging's U-Net architecture for waveform-based source separation with learned down/upsampling.\n- **Open-Unmix**: Spectrogram-based separation model using three-layer BiLSTMs with industry-standard implementation.\n- **ResUNetDecouple**: U-Net variant with residual connections that decouples magnitude and phase processing.\n- **TDCN++**: Improved temporal convolutional network with global skip connections and stacked dilation patterns.\n- **Spleeter**: Facebook's lightweight CNN-based separator using spectrogram masking with pretrained models.\n\nOf these, two models which catch one's eye are convtasnet, which seemed to provide good results with the most optimally efficient architecture and demucs, which uses an advanced convolutional architecure built on top of Wave-U-Net and stretches its performance to state-of-the-art levels.","metadata":{}},{"cell_type":"markdown","source":"## Disclaimers\nThis notebook refers to the tip of the iceberg of multiple approaches tried along the way in order to reach here. It provides for a summary of the underlying work done around trials and errors in speech separation. More about the same is appended in the Archives section at the end of this report notebook ","metadata":{}},{"cell_type":"markdown","source":"## Step1 : Gaining Context (Literature Review)\n\n### A bit about the Dataset\nFirst things first, lets talk about the dataset and the models a bit. MUSDB18 is the benchmark dataset for music source separation, containing 150 full-track recordings (100 for training, 50 for test) with isolated stems for vocals, drums, bass, and other instruments. It provides professionally mixed 44.1kHz stereo audio, enabling evaluation of waveform-domain separation models. The dataset covers diverse genres and production styles, making it ideal for testing real-world generalization. It has become the standard benchmark for models like Open-Unmix, Demucs, and D3Net, with SI-SDR and SDR as primary metrics. The included Python toolbox (musdb) provides data loading, evaluation, and stem mixing utilities. Musdb is however dependent on something known as STEM files i.e. music tensor files combined and compressed into one. We use the kaggle uploaded version of the dataset which saves us the trouble of downloading, unzipping and uploading the same. You can find the dataset here: https://www.kaggle.com/datasets/jakerr5280/musdb18-music-source-separation-dataset\n\n### A bit about the models\n#### ConvTasNet\nKey Idea: A fully convolutional, end-to-end waveform model that avoids spectrograms entirely.\n\nEncoder-Decoder: Uses 1D convolutions to learn a latent representation of the waveform.\n\nTemporal Convolutional Network (TCN): Processes the latent features with stacked dilated convolutions for long-range dependencies.\n\nMask Estimation: Applies a soft mask in the latent space to separate sources.\n\nAdvantages:\n\nLightweight and parallelizable (no RNNs).\n\nStrong performance on speech and music separation.\n\nLimitations:\n\nMay struggle with very long-term dependencies due to fixed receptive fields.\n#### Demucs v2\nKey Idea: A hybrid U-Net + Bi-LSTM architecture that processes raw waveforms.\n\nU-Net Structure: Encoder-decoder with skip connections for multiscale feature extraction.\n\nBidirectional LSTMs: Added between encoder and decoder to capture long-term temporal relationships.\n\nImprovements in v2:\n\nDeeper architecture with more layers.\n\nBetter training strategies (e.g., dynamic mixing).\n\nOptional transformer layers in later variants.\n\nAdvantages:\n\nStrong separation quality, especially for music.\n\nHandles variable-length inputs well.\n\nLimitations:\n\nComputationally heavier than ConvTasNet due to LSTMs.\n","metadata":{}},{"cell_type":"markdown","source":"## Step 2: Installing Stuff and Basic Setup\n","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install musdb\n!pip install mir_eval\n\n# Installing SpeechBrain via pip\nBRANCH = 'develop'\n!python -m pip install git+https://github.com/speechbrain/speechbrain.git@$BRANCH\n\n# Clone SpeechBrain repository\n!git clone https://github.com/speechbrain/speechbrain/","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"db_path = '/kaggle/input/musdb18-music-source-separation-dataset'\noutput_path = '/kaggle/working'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T01:49:20.317622Z","iopub.execute_input":"2025-04-14T01:49:20.319076Z","iopub.status.idle":"2025-04-14T01:49:20.323977Z","shell.execute_reply.started":"2025-04-14T01:49:20.319033Z","shell.execute_reply":"2025-04-14T01:49:20.322775Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"!pip install musdb\n!pip install mir_eval\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T01:27:30.537915Z","iopub.execute_input":"2025-04-14T01:27:30.538617Z","iopub.status.idle":"2025-04-14T01:27:39.184382Z","shell.execute_reply.started":"2025-04-14T01:27:30.538589Z","shell.execute_reply":"2025-04-14T01:27:39.182908Z"}},"outputs":[{"name":"stdout","text":"Collecting musdb\n  Downloading musdb-0.4.2-py2.py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.11/dist-packages (from musdb) (1.26.4)\nCollecting stempeg>=0.2.3 (from musdb)\n  Downloading stempeg-0.2.3-py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: pyaml in /usr/local/lib/python3.11/dist-packages (from musdb) (25.1.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from musdb) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->musdb) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->musdb) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->musdb) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->musdb) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->musdb) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->musdb) (2.4.1)\nCollecting ffmpeg-python>=0.2.0 (from stempeg>=0.2.3->musdb)\n  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml->musdb) (6.0.2)\nRequirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python>=0.2.0->stempeg>=0.2.3->musdb) (1.0.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.7->musdb) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.7->musdb) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.7->musdb) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.7->musdb) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.7->musdb) (2024.2.0)\nDownloading musdb-0.4.2-py2.py3-none-any.whl (13 kB)\nDownloading stempeg-0.2.3-py3-none-any.whl (963 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\nInstalling collected packages: ffmpeg-python, stempeg, musdb\nSuccessfully installed ffmpeg-python-0.2.0 musdb-0.4.2 stempeg-0.2.3\nCollecting mir_eval\n  Downloading mir_eval-0.8.2-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.11/dist-packages (from mir_eval) (1.26.4)\nRequirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mir_eval) (1.15.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mir_eval) (4.4.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.15.4->mir_eval) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.15.4->mir_eval) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.15.4->mir_eval) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.15.4->mir_eval) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.15.4->mir_eval) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.15.4->mir_eval) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.15.4->mir_eval) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.15.4->mir_eval) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.15.4->mir_eval) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.15.4->mir_eval) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.15.4->mir_eval) (2024.2.0)\nDownloading mir_eval-0.8.2-py3-none-any.whl (102 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.8/102.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: mir_eval\nSuccessfully installed mir_eval-0.8.2\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"import os\nimport numpy as np\nnp.float_ = np.float64\nimport musdb\n\nMUS_DB_PATH = db_path\n\nmus = musdb.DB(root=MUS_DB_PATH)\nmus_train = musdb.DB(root=MUS_DB_PATH,subsets=\"train\", split=\"train\")\nmus_valid = musdb.DB(root=MUS_DB_PATH,subsets=\"train\", split=\"valid\")\nmus_test = musdb.DB(root=MUS_DB_PATH,subsets=\"test\")\nprint(mus_train[0])\nprint(mus_test[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T01:49:23.555888Z","iopub.execute_input":"2025-04-14T01:49:23.556239Z","iopub.status.idle":"2025-04-14T01:50:04.898048Z","shell.execute_reply.started":"2025-04-14T01:49:23.556208Z","shell.execute_reply":"2025-04-14T01:50:04.896900Z"}},"outputs":[{"name":"stdout","text":"A Classic Education - NightOwl\nAM Contra - Heart Peripheral\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"!pip install museval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T02:29:20.213838Z","iopub.execute_input":"2025-04-14T02:29:20.214554Z","iopub.status.idle":"2025-04-14T02:29:24.990693Z","shell.execute_reply.started":"2025-04-14T02:29:20.214520Z","shell.execute_reply":"2025-04-14T02:29:24.989497Z"}},"outputs":[{"name":"stdout","text":"Collecting museval\n  Downloading museval-0.4.1-py2.py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: musdb>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from museval) (0.4.2)\nRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from museval) (2.2.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from museval) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from museval) (1.15.2)\nCollecting simplejson>=3.19.0 (from museval)\n  Downloading simplejson-3.20.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\nRequirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (from museval) (0.13.1)\nRequirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from museval) (4.23.0)\nRequirement already satisfied: stempeg>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from musdb>=0.4.0->museval) (0.2.3)\nRequirement already satisfied: pyaml in /usr/local/lib/python3.11/dist-packages (from musdb>=0.4.0->museval) (25.1.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from musdb>=0.4.0->museval) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->museval) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->museval) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->museval) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->museval) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->museval) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->museval) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->museval) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->museval) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->museval) (2025.2)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->museval) (25.3.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->museval) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->museval) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->museval) (0.22.3)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile->museval) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile->museval) (2.22)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->museval) (1.17.0)\nRequirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema->museval) (4.13.1)\nRequirement already satisfied: ffmpeg-python>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from stempeg>=0.2.3->musdb>=0.4.0->museval) (0.2.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->museval) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->museval) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->museval) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->museval) (2024.2.0)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml->musdb>=0.4.0->museval) (6.0.2)\nRequirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python>=0.2.0->stempeg>=0.2.3->musdb>=0.4.0->museval) (1.0.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->museval) (2024.2.0)\nDownloading museval-0.4.1-py2.py3-none-any.whl (20 kB)\nDownloading simplejson-3.20.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: simplejson, museval\nSuccessfully installed museval-0.4.1 simplejson-3.20.1\n","output_type":"stream"}],"execution_count":42},{"cell_type":"markdown","source":"## Step 3: Baseline Models\n\nWe can use the baseline models available in torch as well as in the original repository of demucs in order to have a fair comparison of our implementations.\n\nWe use the repository created by facebook research in order to implement the demucs baseline model. We use their pretrained model on our dataset","metadata":{}},{"cell_type":"code","source":"\n# Installing SpeechBrain via pip\nBRANCH = 'v2'\n!python -m pip install git+https://github.com/facebookresearch/demucs.git@$BRANCH\n\n# Clone Demucs repository\n!git clone https://github.com/facebookresearch/demucs.git --branch 'v2'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T00:05:42.628646Z","iopub.execute_input":"2025-04-14T00:05:42.629606Z","iopub.status.idle":"2025-04-14T00:07:31.067872Z","shell.execute_reply.started":"2025-04-14T00:05:42.629556Z","shell.execute_reply":"2025-04-14T00:07:31.066756Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/facebookresearch/demucs.git@v2\n  Cloning https://github.com/facebookresearch/demucs.git (to revision v2) to /tmp/pip-req-build-gq0lj0fk\n  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/demucs.git /tmp/pip-req-build-gq0lj0fk\n  Running command git checkout -b v2 --track origin/v2\n  Switched to a new branch 'v2'\n  Branch 'v2' set up to track remote branch 'v2' from 'origin'.\n  Resolved https://github.com/facebookresearch/demucs.git to commit 64ed2cb029301743b2714b3c8fe930c00945842c\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting diffq<0.2.0 (from demucs==2.0.3)\n  Downloading diffq-0.1.1.tar.gz (34 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting lameenc>=1.2 (from demucs==2.0.3)\n  Downloading lameenc-1.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (9.9 kB)\nCollecting julius>=0.2.3 (from demucs==2.0.3)\n  Downloading julius-0.2.7.tar.gz (59 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from demucs==2.0.3) (1.26.4)\nRequirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from demucs==2.0.3) (2.5.1+cu124)\nRequirement already satisfied: torchaudio>=0.8 in /usr/local/lib/python3.11/dist-packages (from demucs==2.0.3) (2.5.1+cu124)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from demucs==2.0.3) (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.1->demucs==2.0.3)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.1->demucs==2.0.3)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.1->demucs==2.0.3)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.1->demucs==2.0.3)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.1->demucs==2.0.3)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.1->demucs==2.0.3)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.1->demucs==2.0.3)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.1->demucs==2.0.3) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->demucs==2.0.3) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->demucs==2.0.3) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->demucs==2.0.3) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->demucs==2.0.3) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->demucs==2.0.3) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->demucs==2.0.3) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.1->demucs==2.0.3) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->demucs==2.0.3) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->demucs==2.0.3) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->demucs==2.0.3) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->demucs==2.0.3) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->demucs==2.0.3) (2024.2.0)\nDownloading lameenc-1.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (249 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.7/249.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: demucs, diffq, julius\n  Building wheel for demucs (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for demucs: filename=demucs-2.0.3-py3-none-any.whl size=44652 sha256=c0dc9e204449963f77b54e8a5be633f3eb2c323ef86bff138a95d604900f3ac0\n  Stored in directory: /tmp/pip-ephem-wheel-cache-0y94p01m/wheels/13/63/ef/f135563cc28c964ceb0365ecf358eb915d64241f3319c4b0a5\n  Building wheel for diffq (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for diffq: filename=diffq-0.1.1-py3-none-any.whl size=18962 sha256=9bca7d9244676b88702dd9fb7ce92befd9ee36e3f2136e55943623322592be1c\n  Stored in directory: /root/.cache/pip/wheels/e2/9c/6e/98f7ff95859ab18d48294f909735bb4bda7d898272ff045a49\n  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21869 sha256=7bc669c3ecdda33cbc8891dae77b233a827704735a4abea0dd31f8ad38f1c717\n  Stored in directory: /root/.cache/pip/wheels/16/15/d4/edd724cefe78050a6ba3344b8b0c6672db829a799dbb9f81ff\nSuccessfully built demucs diffq julius\nInstalling collected packages: lameenc, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, julius, diffq, demucs\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed demucs-2.0.3 diffq-0.1.1 julius-0.2.7 lameenc-1.8.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nCloning into 'demucs'...\nremote: Enumerating objects: 5813, done.\u001b[K\nremote: Total 5813 (delta 0), reused 0 (delta 0), pack-reused 5813 (from 1)\u001b[K\nReceiving objects: 100% (5813/5813), 76.72 MiB | 39.14 MiB/s, done.\nResolving deltas: 100% (1130/1130), done.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!git clone https://github.com/facebookresearch/demucs.git --branch 'v2'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T01:14:52.827437Z","iopub.execute_input":"2025-04-14T01:14:52.827748Z","iopub.status.idle":"2025-04-14T01:14:56.144885Z","shell.execute_reply.started":"2025-04-14T01:14:52.827718Z","shell.execute_reply":"2025-04-14T01:14:56.143695Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'demucs'...\nremote: Enumerating objects: 5813, done.\u001b[K\nremote: Total 5813 (delta 0), reused 0 (delta 0), pack-reused 5813 (from 1)\u001b[K\nReceiving objects: 100% (5813/5813), 76.73 MiB | 41.75 MiB/s, done.\nResolving deltas: 100% (1125/1125), done.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!ls demucs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T01:17:05.784321Z","iopub.execute_input":"2025-04-14T01:17:05.784625Z","iopub.status.idle":"2025-04-14T01:17:05.906019Z","shell.execute_reply.started":"2025-04-14T01:17:05.784599Z","shell.execute_reply":"2025-04-14T01:17:05.904698Z"}},"outputs":[{"name":"stdout","text":"baselines\t    docs\t\t  Makefile\t    run.py\nCODE_OF_CONDUCT.md  dora.py\t\t  MANIFEST.in\t    run_slurm.py\nCONTRIBUTING.md     environment-cpu.yml   README.md\t    setup.cfg\ndemucs\t\t    environment-cuda.yml  requirements.txt  setup.py\nDemucs.ipynb\t    hubconf.py\t\t  results\t    test.mp3\ndemucs.png\t    LICENSE\t\t  result_table.py   valid_table.py\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"%cd /kaggle/working/demucs\n!pip install -e .","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T01:25:43.149368Z","iopub.execute_input":"2025-04-14T01:25:43.149718Z","iopub.status.idle":"2025-04-14T01:25:50.902142Z","shell.execute_reply.started":"2025-04-14T01:25:43.149689Z","shell.execute_reply":"2025-04-14T01:25:50.900985Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/demucs\nObtaining file:///kaggle/working/demucs\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: diffq<0.2.0 in /usr/local/lib/python3.11/dist-packages (from demucs==2.0.3) (0.1.1)\nRequirement already satisfied: lameenc>=1.2 in /usr/local/lib/python3.11/dist-packages (from demucs==2.0.3) (1.8.1)\nRequirement already satisfied: julius>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from demucs==2.0.3) (0.2.7)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from demucs==2.0.3) (1.26.4)\nRequirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from demucs==2.0.3) (2.5.1+cu124)\nRequirement already satisfied: torchaudio>=0.8 in /usr/local/lib/python3.11/dist-packages (from demucs==2.0.3) (2.5.1+cu124)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from demucs==2.0.3) (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs==2.0.3) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.1->demucs==2.0.3) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->demucs==2.0.3) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->demucs==2.0.3) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->demucs==2.0.3) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->demucs==2.0.3) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->demucs==2.0.3) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->demucs==2.0.3) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.1->demucs==2.0.3) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->demucs==2.0.3) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->demucs==2.0.3) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->demucs==2.0.3) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->demucs==2.0.3) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->demucs==2.0.3) (2024.2.0)\nInstalling collected packages: demucs\n  Running setup.py develop for demucs\nSuccessfully installed demucs-2.0.3\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"!python3 -m demucs -h","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T02:49:14.238521Z","iopub.execute_input":"2025-04-14T02:49:14.238864Z","iopub.status.idle":"2025-04-14T02:49:19.096648Z","shell.execute_reply.started":"2025-04-14T02:49:14.238835Z","shell.execute_reply":"2025-04-14T02:49:19.095273Z"}},"outputs":[{"name":"stdout","text":"usage: demucs [-h] [--raw RAW] [--no_raw] [-m MUSDB] [--is_wav] [--metadata METADATA] [--wav WAV]\n              [--concat] [--samplerate SAMPLERATE] [--audio_channels AUDIO_CHANNELS]\n              [--samples SAMPLES] [--data_stride DATA_STRIDE] [-w WORKERS]\n              [--eval_workers EVAL_WORKERS] [-d DEVICE] [--eval_cpu] [--dummy DUMMY] [--test TEST]\n              [--test_pretrained TEST_PRETRAINED] [--rank RANK] [--world_size WORLD_SIZE]\n              [--master MASTER] [--checkpoints CHECKPOINTS] [--evals EVALS] [--save] [--logs LOGS]\n              [--models MODELS] [-R] [--seed SEED] [-e EPOCHS] [-r REPEAT] [-b BATCH_SIZE]\n              [--lr LR] [--mse] [--init INIT] [--no_augment] [--repitch REPITCH]\n              [--max_tempo MAX_TEMPO] [--remix_group_size REMIX_GROUP_SIZE] [--shifts SHIFTS]\n              [--overlap OVERLAP] [--growth GROWTH] [--depth DEPTH] [--lstm_layers LSTM_LAYERS]\n              [--channels CHANNELS] [--kernel_size KERNEL_SIZE] [--conv_stride CONV_STRIDE]\n              [--context CONTEXT] [--rescale RESCALE] [--no_resample] [--no_glu] [--no_rewrite]\n              [--normalize] [--no_norm_wav] [--tasnet] [--split_valid] [--X X] [--show]\n              [--save_model] [--save_state SAVE_STATE] [--half] [--q-min-size Q_MIN_SIZE]\n              [--qat QAT] [--diffq DIFFQ] [--ms-target MS_TARGET]\n\nTrain and evaluate Demucs.\n\noptions:\n  -h, --help            show this help message and exit\n  --raw RAW             Path to raw audio, can be faster, see python3 -m demucs.raw to extract.\n  --no_raw\n  -m MUSDB, --musdb MUSDB\n                        Path to musdb root\n  --is_wav              Indicate that the MusDB dataset is in wav format (i.e. MusDB-HQ).\n  --metadata METADATA   Folder where metadata information is stored.\n  --wav WAV             Path to a wav dataset. This should contain a 'train' and a 'valid'\n                        subfolder.\n  --concat              Concat MusDB and wav dataset when provided.\n  --samplerate SAMPLERATE\n  --audio_channels AUDIO_CHANNELS\n  --samples SAMPLES     number of samples to feed in\n  --data_stride DATA_STRIDE\n                        Stride for chunks, shorter = longer epochs\n  -w WORKERS, --workers WORKERS\n                        Loader workers\n  --eval_workers EVAL_WORKERS\n                        Final evaluation workers\n  -d DEVICE, --device DEVICE\n                        Device to train on, default is cuda if available else cpu\n  --eval_cpu            Eval on test will be run on cpu.\n  --dummy DUMMY         Dummy parameter, useful to create a new checkpoint file\n  --test TEST           Just run the test pipeline + one validation. This should be a filename\n                        relative to the models/ folder.\n  --test_pretrained TEST_PRETRAINED\n                        Just run the test pipeline + one validation, on a pretrained model.\n  --rank RANK\n  --world_size WORLD_SIZE\n  --master MASTER\n  --checkpoints CHECKPOINTS\n                        Folder where to store checkpoints etc\n  --evals EVALS         Folder where to store evals and waveforms\n  --save                Save estimated for the test set waveforms\n  --logs LOGS           Folder where to store logs\n  --models MODELS       Folder where to store trained models\n  -R, --restart         Restart training, ignoring previous run\n  --seed SEED\n  -e EPOCHS, --epochs EPOCHS\n                        Number of epochs\n  -r REPEAT, --repeat REPEAT\n                        Repeat the train set, longer epochs\n  -b BATCH_SIZE, --batch_size BATCH_SIZE\n  --lr LR\n  --mse                 Use MSE instead of L1\n  --init INIT           Initialize from a pre-trained model.\n  --no_augment          No basic data augmentation.\n  --repitch REPITCH     Probability to do tempo/pitch change\n  --max_tempo MAX_TEMPO\n                        Maximum relative tempo change in % when using repitch.\n  --remix_group_size REMIX_GROUP_SIZE\n                        Shuffle sources using group of this size. Useful to somewhat replicate\n                        multi-gpu training on less GPUs.\n  --shifts SHIFTS       Number of random shifts used for the shift trick.\n  --overlap OVERLAP     Overlap when --split_valid is passed.\n  --growth GROWTH       Number of channels between two layers will increase by this factor\n  --depth DEPTH         Number of layers for the encoder and decoder\n  --lstm_layers LSTM_LAYERS\n                        Number of layers for the LSTM\n  --channels CHANNELS   Number of channels for the first encoder layer\n  --kernel_size KERNEL_SIZE\n                        Kernel size for the (transposed) convolutions\n  --conv_stride CONV_STRIDE\n                        Stride for the (transposed) convolutions\n  --context CONTEXT     Context size for the decoder convolutions before the transposed\n                        convolutions\n  --rescale RESCALE     Initial weight rescale reference\n  --no_resample         No Resampling of the input/output x2\n  --no_glu              Replace all GLUs by ReLUs\n  --no_rewrite          No 1x1 rewrite convolutions\n  --normalize\n  --no_norm_wav\n  --tasnet\n  --split_valid         Predict chunks by chunks for valid and test. Required for tasnet\n  --X X\n  --show                Show model architecture, size and exit\n  --save_model          Skip traning, just save final model for the current checkpoint value.\n  --save_state SAVE_STATE\n                        Skip training, just save state for the current checkpoint value. You\n                        should provide a model name as argument.\n  --half                When saving the model, uses half precision.\n  --q-min-size Q_MIN_SIZE\n                        Only quantize layers over this size (in MB)\n  --qat QAT             If provided, use QAT training with that many bits.\n  --diffq DIFFQ\n  --ms-target MS_TARGET\n                        Model size target in MB, when using DiffQ. Best model will be kept only if\n                        it is smaller than this target.\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"# !python3 -m demucs -b 1  --samplerate 8000 --split_valid --device \"cpu\" --samples 240000 -e 5 --musdb \"{db_path}\"\n!python3 -m demucs -b 1 --workers=1 --test_pretrained demucs_quantized --musdb \"{db_path}\" --samples=240000 --samplerate=8000 --device \"cpu\" ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T03:28:06.397711Z","iopub.execute_input":"2025-04-14T03:28:06.398061Z","iopub.status.idle":"2025-04-14T03:43:08.912281Z","shell.execute_reply.started":"2025-04-14T03:28:06.398036Z","shell.execute_reply":"2025-04-14T03:43:08.910699Z"}},"outputs":[{"name":"stdout","text":"Experiment musdb=musdb18-music-source-separation-dataset test_pretrained=demucs_quantized batch_size=1\nDownloading: \"https://dl.fbaipublicfiles.com/demucs/v3.0/demucs_quantized-07afea75.th\" to /root/.cache/torch/hub/checkpoints/demucs_quantized-07afea75.th\n100%|████████████████████████████████████████| 148M/148M [00:06<00:00, 23.4MB/s]\n/kaggle/working/demucs/demucs/utils.py:286: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = th.load(buf, \"cpu\")\n/kaggle/working/demucs/demucs/__main__.py:133: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  saved = th.load(checkpoint, map_location='cpu')\nAgumentation pipeline: Sequential(\n  (0): Shift()\n  (1): FlipSign()\n  (2): FlipChannels()\n  (3): Scale()\n  (4): Remix()\n)\nNumber of training samples adjusted to 447146\n^C\nTraceback (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"/kaggle/working/demucs/demucs/__main__.py\", line 328, in <module>\n    main()\n  File \"/kaggle/working/demucs/demucs/__main__.py\", line 214, in main\n    train_set, valid_set = get_compressed_datasets(args, samples)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/demucs/demucs/compressed.py\", line 98, in get_compressed_datasets\n    _build_musdb_metadata(metadata_file, args.musdb, args.workers)\n  File \"/kaggle/working/demucs/demucs/compressed.py\", line 90, in _build_musdb_metadata\n    metadata = _build_metadata(tracks, workers)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/demucs/demucs/compressed.py\", line 82, in _build_metadata\n    with futures.ProcessPoolExecutor(workers) as pool:\n  File \"/usr/lib/python3.11/concurrent/futures/_base.py\", line 647, in __exit__\n    self.shutdown(wait=True)\n  File \"/usr/lib/python3.11/concurrent/futures/process.py\", line 851, in shutdown\n    self._executor_manager_thread.join()\n  File \"/usr/lib/python3.11/threading.py\", line 1119, in join\n    self._wait_for_tstate_lock()\n  File \"/usr/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n    if lock.acquire(block, timeout):\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nKeyboardInterrupt\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"!ls metadata","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T03:14:43.810956Z","iopub.execute_input":"2025-04-14T03:14:43.811393Z","iopub.status.idle":"2025-04-14T03:14:43.933941Z","shell.execute_reply.started":"2025-04-14T03:14:43.811361Z","shell.execute_reply":"2025-04-14T03:14:43.932502Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"# !python3 -m demucs -b 1  --samplerate 8000 --split_valid --device \"cpu\" --samples 240000 -e 5 --musdb \"{db_path}\"\n!python3 -m demucs --workers=1 -b 1 --test_pretrained tasnet --samples=240000 --samplerate=8000 --device \"cpu\" --musdb \"{db_path}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T03:03:14.002767Z","iopub.execute_input":"2025-04-14T03:03:14.003260Z","iopub.status.idle":"2025-04-14T03:04:08.755285Z","shell.execute_reply.started":"2025-04-14T03:03:14.003209Z","shell.execute_reply":"2025-04-14T03:04:08.754038Z"}},"outputs":[{"name":"stdout","text":"Experiment musdb=musdb18-music-source-separation-dataset samplerate=8000 samples=240000 device=cpu test_pretrained=tasnet batch_size=1\n/kaggle/working/demucs/demucs/__main__.py:133: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  saved = th.load(checkpoint, map_location='cpu')\nAgumentation pipeline: Sequential(\n  (0): Shift()\n  (1): FlipSign()\n  (2): FlipChannels()\n  (3): Scale()\n  (4): Remix()\n)\nNumber of training samples adjusted to 240000\n^C\nTraceback (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"/kaggle/working/demucs/demucs/__main__.py\", line 328, in <module>\n    main()\n  File \"/kaggle/working/demucs/demucs/__main__.py\", line 214, in main\n    train_set, valid_set = get_compressed_datasets(args, samples)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/demucs/demucs/compressed.py\", line 98, in get_compressed_datasets\n    _build_musdb_metadata(metadata_file, args.musdb, args.workers)\n  File \"/kaggle/working/demucs/demucs/compressed.py\", line 90, in _build_musdb_metadata\n    metadata = _build_metadata(tracks, workers)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/demucs/demucs/compressed.py\", line 82, in _build_metadata\n    with futures.ProcessPoolExecutor(workers) as pool:\n  File \"/usr/lib/python3.11/concurrent/futures/_base.py\", line 647, in __exit__\n    self.shutdown(wait=True)\n  File \"/usr/lib/python3.11/concurrent/futures/process.py\", line 851, in shutdown\n    self._executor_manager_thread.join()\n  File \"/usr/lib/python3.11/threading.py\", line 1119, in join\n    self._wait_for_tstate_lock()\n  File \"/usr/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n    if lock.acquire(block, timeout):\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nKeyboardInterrupt\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"python3 -m demucs -b 1  --musdb MUSDB_PATH --tasnet --samplerate=8000 --samples=240000 --split_valid --init tasnet # Conv-Tasnet","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Musformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T19:11:05.864744Z",
     "iopub.status.busy": "2025-04-16T19:11:05.864334Z",
     "iopub.status.idle": "2025-04-16T19:11:09.952767Z",
     "shell.execute_reply": "2025-04-16T19:11:09.952093Z",
     "shell.execute_reply.started": "2025-04-16T19:11:05.864707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.11-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (23.2)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from kagglehub) (5.4.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.66.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->kagglehub) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->kagglehub) (2020.6.20)\n",
      "Downloading kagglehub-0.3.11-py3-none-any.whl (63 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: kagglehub\n",
      "Successfully installed kagglehub-0.3.11\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T15:20:48.444152Z",
     "iopub.status.busy": "2025-04-16T15:20:48.443092Z",
     "iopub.status.idle": "2025-04-16T15:22:14.682422Z",
     "shell.execute_reply": "2025-04-16T15:22:14.681137Z",
     "shell.execute_reply.started": "2025-04-16T15:20:48.444124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/jakerr5280/musdb18-music-source-separation-dataset?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.06G/4.06G [00:51<00:00, 84.2MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data source import complete.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
    "# THEN FEEL FREE TO DELETE THIS CELL.\n",
    "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
    "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
    "# NOTEBOOK.\n",
    "import kagglehub\n",
    "jakerr5280_musdb18_music_source_separation_dataset_path = kagglehub.dataset_download('jakerr5280/musdb18-music-source-separation-dataset')\n",
    "\n",
    "print('Data source import complete.')\n",
    "\n",
    "\n",
    "import os\n",
    "db_path = '/notebooks/data'\n",
    "output_path = '/notebooks/results'\n",
    "\n",
    "\n",
    "# Create destination if needed\n",
    "os.makedirs(db_path, exist_ok=True)\n",
    "\n",
    "\n",
    "# Create destination if needed\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T15:00:17.750544Z",
     "iopub.status.busy": "2025-04-18T15:00:17.750049Z",
     "iopub.status.idle": "2025-04-18T15:00:17.785726Z",
     "shell.execute_reply": "2025-04-18T15:00:17.784608Z",
     "shell.execute_reply.started": "2025-04-18T15:00:17.750505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created successfully at: /notebooks/metrics.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "def create_metrics_csv(file_path):\n",
    "    headers = [\n",
    "        \"model_name\", \"n_epochs\", \"learning_rate\", \"chunk_size\", \"sample_rate\", \"sdr\", \"sdr_i\", \"si-snr\", \"si-snr_i\"\n",
    "    ]\n",
    "    \n",
    "    Path(file_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(file_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)\n",
    "    \n",
    "    print(f\"CSV file created successfully at: {file_path}\")\n",
    "\n",
    "if result_file_path is not None:\n",
    "    create_metrics_csv(result_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T17:38:59.562374Z",
     "iopub.status.busy": "2025-04-18T17:38:59.562004Z",
     "iopub.status.idle": "2025-04-18T17:38:59.569336Z",
     "shell.execute_reply": "2025-04-18T17:38:59.568635Z",
     "shell.execute_reply.started": "2025-04-18T17:38:59.562349Z"
    }
   },
   "outputs": [],
   "source": [
    "db_path = '/notebooks/data'\n",
    "output_path = '/notebooks/results'\n",
    "result_file_path = '/notebooks/metrics.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T15:22:14.686597Z",
     "iopub.status.busy": "2025-04-16T15:22:14.686335Z",
     "iopub.status.idle": "2025-04-16T15:22:23.598155Z",
     "shell.execute_reply": "2025-04-16T15:22:23.596651Z",
     "shell.execute_reply.started": "2025-04-16T15:22:14.686571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved /root/.cache/kagglehub/datasets/jakerr5280/musdb18-music-source-separation-dataset/versions/1 to /notebooks/data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "try:\n",
    "    shutil.move(jakerr5280_musdb18_music_source_separation_dataset_path + '/train', db_path)\n",
    "    shutil.move(jakerr5280_musdb18_music_source_separation_dataset_path + '/test', db_path)  # Moves the entire directory\n",
    "    print(f\"Moved {jakerr5280_musdb18_music_source_separation_dataset_path} to {db_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-16T15:23:09.277557Z",
     "iopub.status.busy": "2025-04-16T15:23:09.277169Z",
     "iopub.status.idle": "2025-04-16T15:23:09.297120Z",
     "shell.execute_reply": "2025-04-16T15:23:09.296250Z",
     "shell.execute_reply.started": "2025-04-16T15:23:09.277526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/data/train/James May - Dont Let Go.stem.mp4\n",
      "/notebooks/data/train/North To Alaska - All The Same.stem.mp4\n",
      "/notebooks/data/train/Titanium - Haunted Age.stem.mp4\n",
      "/notebooks/data/train/Music Delta - Gospel.stem.mp4\n",
      "/notebooks/data/train/Drumtracks - Ghost Bitch.stem.mp4\n",
      "/notebooks/data/train/A Classic Education - NightOwl.stem.mp4\n",
      "/notebooks/data/train/Leaf - Wicked.stem.mp4\n",
      "/notebooks/data/train/Dreamers Of The Ghetto - Heavy Love.stem.mp4\n",
      "/notebooks/data/train/Remember December - C U Next Time.stem.mp4\n",
      "/notebooks/data/train/Port St Willow - Stay Even.stem.mp4\n",
      "/notebooks/data/train/Patrick Talbot - A Reason To Leave.stem.mp4\n",
      "/notebooks/data/train/Meaxic - You Listen.stem.mp4\n",
      "/notebooks/data/train/Actions - South Of The Water.stem.mp4\n",
      "/notebooks/data/train/Helado Negro - Mitad Del Mundo.stem.mp4\n",
      "/notebooks/data/train/ANiMAL - Clinic A.stem.mp4\n",
      "/notebooks/data/train/James May - All Souls Moon.stem.mp4\n",
      "/notebooks/data/train/James May - On The Line.stem.mp4\n",
      "/notebooks/data/train/Jay Menon - Through My Eyes.stem.mp4\n",
      "/notebooks/data/train/Snowmine - Curfews.stem.mp4\n",
      "/notebooks/data/train/Triviul - Angelsaint.stem.mp4\n",
      "/notebooks/data/train/Hezekiah Jones - Borrowed Heart.stem.mp4\n",
      "/notebooks/data/train/Invisible Familiars - Disturbing Wildlife.stem.mp4\n",
      "/notebooks/data/train/BigTroubles - Phantom.stem.mp4\n",
      "/notebooks/data/train/Night Panther - Fire.stem.mp4\n",
      "/notebooks/data/train/The Districts - Vermont.stem.mp4\n",
      "/notebooks/data/train/Flags - 54.stem.mp4\n",
      "/notebooks/data/train/Music Delta - Grunge.stem.mp4\n",
      "/notebooks/data/train/Atlantis Bound - It Was My Fault For Waiting.stem.mp4\n",
      "/notebooks/data/train/Alexander Ross - Velvet Curtain.stem.mp4\n",
      "/notebooks/data/train/ANiMAL - Rockshow.stem.mp4\n",
      "/notebooks/data/train/Young Griffo - Facade.stem.mp4\n",
      "/notebooks/data/train/Cnoc An Tursa - Bannockburn.stem.mp4\n",
      "/notebooks/data/train/James May - If You Say.stem.mp4\n",
      "/notebooks/data/train/Sweet Lights - You Let Me Down.stem.mp4\n",
      "/notebooks/data/train/ANiMAL - Easy Tiger.stem.mp4\n",
      "/notebooks/data/train/Faces On Film - Waiting For Ga.stem.mp4\n",
      "/notebooks/data/train/Auctioneer - Our Future Faces.stem.mp4\n",
      "/notebooks/data/train/Music Delta - Disco.stem.mp4\n",
      "/notebooks/data/train/Music Delta - 80s Rock.stem.mp4\n",
      "/notebooks/data/train/Lushlife - Toynbee Suite.stem.mp4\n",
      "/notebooks/data/train/Matthew Entwistle - Dont You Ever.stem.mp4\n",
      "/notebooks/data/train/Angela Thomas Wade - Milk Cow Blues.stem.mp4\n",
      "/notebooks/data/train/Bill Chudziak - Children Of No-one.stem.mp4\n",
      "/notebooks/data/train/Tim Taler - Stalker.stem.mp4\n",
      "/notebooks/data/train/Grants - PunchDrunk.stem.mp4\n",
      "/notebooks/data/train/Secret Mountains - High Horse.stem.mp4\n",
      "/notebooks/data/train/Clara Berry And Wooldog - Waltz For My Victims.stem.mp4\n",
      "/notebooks/data/train/Fergessen - Back From The Start.stem.mp4\n",
      "/notebooks/data/train/Music Delta - Beatles.stem.mp4\n",
      "/notebooks/data/train/The Scarlet Brand - Les Fleurs Du Mal.stem.mp4\n",
      "/notebooks/data/train/Triviul - Dorothy.stem.mp4\n",
      "/notebooks/data/train/Leaf - Summerghost.stem.mp4\n",
      "/notebooks/data/train/Wall Of Death - Femme.stem.mp4\n",
      "/notebooks/data/train/Music Delta - Country2.stem.mp4\n",
      "/notebooks/data/train/Hollow Ground - Left Blind.stem.mp4\n",
      "/notebooks/data/train/Steven Clark - Bounty.stem.mp4\n",
      "/notebooks/data/train/Chris Durban - Celebrate.stem.mp4\n",
      "/notebooks/data/train/Music Delta - Rockabilly.stem.mp4\n",
      "/notebooks/data/train/Skelpolu - Together Alone.stem.mp4\n",
      "/notebooks/data/train/The So So Glos - Emergency.stem.mp4\n",
      "/notebooks/data/train/Music Delta - Reggae.stem.mp4\n",
      "/notebooks/data/train/Traffic Experiment - Sirens.stem.mp4\n",
      "/notebooks/data/train/Alexander Ross - Goodbye Bolero.stem.mp4\n",
      "/notebooks/data/train/Music Delta - Rock.stem.mp4\n",
      "/notebooks/data/train/Celestial Shore - Die For Us.stem.mp4\n",
      "/notebooks/data/train/Leaf - Come Around.stem.mp4\n",
      "/notebooks/data/train/Clara Berry And Wooldog - Air Traffic.stem.mp4\n",
      "/notebooks/data/train/Meaxic - Take A Step.stem.mp4\n",
      "/notebooks/data/train/Johnny Lokke - Whisper To A Scream.stem.mp4\n",
      "/notebooks/data/train/Music Delta - Punk.stem.mp4\n",
      "/notebooks/data/train/AvaLuna - Waterduct.stem.mp4\n",
      "/notebooks/data/train/Music Delta - Britpop.stem.mp4\n",
      "/notebooks/data/train/Dark Ride - Burning Bridges.stem.mp4\n",
      "/notebooks/data/train/Swinging Steaks - Lost My Way.stem.mp4\n",
      "/notebooks/data/train/Creepoid - OldTree.stem.mp4\n",
      "/notebooks/data/train/Strand Of Oaks - Spacestation.stem.mp4\n",
      "/notebooks/data/train/Fergessen - Nos Palpitants.stem.mp4\n",
      "/notebooks/data/train/Skelpolu - Human Mistakes.stem.mp4\n",
      "/notebooks/data/train/Fergessen - The Wind.stem.mp4\n",
      "/notebooks/data/train/Music Delta - Country1.stem.mp4\n",
      "/notebooks/data/train/Patrick Talbot - Set Me Free.stem.mp4\n",
      "/notebooks/data/train/Hop Along - Sister Cities.stem.mp4\n",
      "/notebooks/data/train/Young Griffo - Blood To Bone.stem.mp4\n",
      "/notebooks/data/train/Giselle - Moss.stem.mp4\n",
      "/notebooks/data/train/Actions - One Minute Smile.stem.mp4\n",
      "/notebooks/data/train/Black Bloc - If You Want Success.stem.mp4\n",
      "/notebooks/data/train/St Vitus - Word Gets Around.stem.mp4\n",
      "/notebooks/data/train/Music Delta - Hendrix.stem.mp4\n",
      "/notebooks/data/train/Young Griffo - Pennies.stem.mp4\n",
      "/notebooks/data/train/Traffic Experiment - Once More (With Feeling).stem.mp4\n",
      "/notebooks/data/train/Aimee Norwich - Child.stem.mp4\n",
      "/notebooks/data/train/The Long Wait - Back Home To Blue.stem.mp4\n",
      "/notebooks/data/train/Clara Berry And Wooldog - Stella.stem.mp4\n",
      "/notebooks/data/train/Voelund - Comfort Lives In Belief.stem.mp4\n",
      "/notebooks/data/test/Punkdisco - Oral Hygiene.stem.mp4\n",
      "/notebooks/data/test/The Easton Ellises - Falcon 69.stem.mp4\n",
      "/notebooks/data/test/Zeno - Signs.stem.mp4\n",
      "/notebooks/data/test/The Sunshine Garcia Band - For I Am The Moon.stem.mp4\n",
      "/notebooks/data/test/The Mountaineering Club - Mallory.stem.mp4\n",
      "/notebooks/data/test/Secretariat - Over The Top.stem.mp4\n",
      "/notebooks/data/test/Forkupines - Semantics.stem.mp4\n",
      "/notebooks/data/test/BKS - Too Much.stem.mp4\n",
      "/notebooks/data/test/Mu - Too Bright.stem.mp4\n",
      "/notebooks/data/test/Motor Tapes - Shore.stem.mp4\n",
      "/notebooks/data/test/Moosmusic - Big Dummy Shake.stem.mp4\n",
      "/notebooks/data/test/Lyndsey Ollard - Catching Up.stem.mp4\n",
      "/notebooks/data/test/AM Contra - Heart Peripheral.stem.mp4\n",
      "/notebooks/data/test/Speak Softly - Like Horses.stem.mp4\n",
      "/notebooks/data/test/Triviul feat. The Fiend - Widow.stem.mp4\n",
      "/notebooks/data/test/Raft Monk - Tiring.stem.mp4\n",
      "/notebooks/data/test/M.E.R.C. Music - Knockout.stem.mp4\n",
      "/notebooks/data/test/We Fell From The Sky - Not You.stem.mp4\n",
      "/notebooks/data/test/Al James - Schoolboy Facination.stem.mp4\n",
      "/notebooks/data/test/Buitraker - Revo X.stem.mp4\n",
      "/notebooks/data/test/Skelpolu - Resurrection.stem.mp4\n",
      "/notebooks/data/test/Secretariat - Borderline.stem.mp4\n",
      "/notebooks/data/test/Bobby Nobody - Stitch Up.stem.mp4\n",
      "/notebooks/data/test/Cristina Vane - So Easy.stem.mp4\n",
      "/notebooks/data/test/Enda Reilly - Cur An Long Ag Seol.stem.mp4\n",
      "/notebooks/data/test/Speak Softly - Broken Man.stem.mp4\n",
      "/notebooks/data/test/Georgia Wonder - Siren.stem.mp4\n",
      "/notebooks/data/test/Carlos Gonzalez - A Place For Us.stem.mp4\n",
      "/notebooks/data/test/Signe Jakobsen - What Have You Done To Me.stem.mp4\n",
      "/notebooks/data/test/Side Effects Project - Sing With Me.stem.mp4\n",
      "/notebooks/data/test/PR - Happy Daze.stem.mp4\n",
      "/notebooks/data/test/Sambasevam Shanmugam - Kaathaadi.stem.mp4\n",
      "/notebooks/data/test/Tom McKenzie - Directions.stem.mp4\n",
      "/notebooks/data/test/Detsky Sad - Walkie Talkie.stem.mp4\n",
      "/notebooks/data/test/PR - Oh No.stem.mp4\n",
      "/notebooks/data/test/Nerve 9 - Pray For The Rain.stem.mp4\n",
      "/notebooks/data/test/The Easton Ellises (Baumi) - SDRNR.stem.mp4\n",
      "/notebooks/data/test/Louis Cressy Band - Good Time.stem.mp4\n",
      "/notebooks/data/test/Timboz - Pony.stem.mp4\n",
      "/notebooks/data/test/BKS - Bulldozer.stem.mp4\n",
      "/notebooks/data/test/Hollow Ground - Ill Fate.stem.mp4\n",
      "/notebooks/data/test/Arise - Run Run Run.stem.mp4\n",
      "/notebooks/data/test/Girls Under Glass - We Feel Alright.stem.mp4\n",
      "/notebooks/data/test/The Doppler Shift - Atrophy.stem.mp4\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk(db_path):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Musformer\n",
    "Although misleading, but the name seemed nice. The goal of this project is to try out multiple source separation models in speechbrain. The idea is to replicate building a model in the waveform domain directly. We see that multiple models try to solve the music sourse separation as a problem and most state-of-the-art models reach an SiSDR ratio of 9 to tackle the same. \n",
    "\n",
    "Most models working on this problem came into existence as a solution to the SDX (Sound Demixing) challenge. A few of the existing solutions are as follows: \n",
    "- **MMDenseLSTM**: Combines dense blocks with LSTMs for lightweight waveform separation.\n",
    "- **Demucs (v1/v2)**: U-Net with bidirectional LSTMs; later versions add transformers.\n",
    "- **ConvTasNet**: Efficient temporal convolutional network with learned encoder/decoder.\n",
    "- **DPRNNet**: Dual-path RNN with attention, offering SOTA results at higher compute costs.\n",
    "- **BandSplitRNN**: Separates audio into frequency bands processed by independent RNNs before recombination.\n",
    "- **Wave-U-Net**: Adapts medical imaging's U-Net architecture for waveform-based source separation with learned down/upsampling.\n",
    "- **Open-Unmix**: Spectrogram-based separation model using three-layer BiLSTMs with industry-standard implementation.\n",
    "- **ResUNetDecouple**: U-Net variant with residual connections that decouples magnitude and phase processing.\n",
    "- **TDCN++**: Improved temporal convolutional network with global skip connections and stacked dilation patterns.\n",
    "- **Spleeter**: Facebook's lightweight CNN-based separator using spectrogram masking with pretrained models.\n",
    "\n",
    "Of these, two models which catch one's eye are convtasnet, which seemed to provide good results with the most optimally efficient architecture and demucs, which uses an advanced convolutional architecure built on top of Wave-U-Net and stretches its performance to state-of-the-art levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disclaimers\n",
    "This notebook refers to the tip of the iceberg of multiple approaches tried along the way in order to reach here. It provides for a summary of the underlying work done around trials and errors in speech separation. More about the same is appended in the Archives section at the end of this report notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1 : Gaining Context (Literature Review)\n",
    "\n",
    "### A bit about the Dataset\n",
    "First things first, lets talk about the dataset and the models a bit. MUSDB18 is the benchmark dataset for music source separation, containing 150 full-track recordings (100 for training, 50 for test) with isolated stems for vocals, drums, bass, and other instruments. It provides professionally mixed 44.1kHz stereo audio, enabling evaluation of waveform-domain separation models. The dataset covers diverse genres and production styles, making it ideal for testing real-world generalization. It has become the standard benchmark for models like Open-Unmix, Demucs, and D3Net, with SI-SDR and SDR as primary metrics. The included Python toolbox (musdb) provides data loading, evaluation, and stem mixing utilities. Musdb is however dependent on something known as STEM files i.e. music tensor files combined and compressed into one. We use the kaggle uploaded version of the dataset which saves us the trouble of downloading, unzipping and uploading the same. You can find the dataset here: https://www.kaggle.com/datasets/jakerr5280/musdb18-music-source-separation-dataset\n",
    "\n",
    "### A bit about the models\n",
    "\n",
    "\n",
    "#### Demucs v2\n",
    "- Key Idea: A hybrid U-Net + Bi-LSTM architecture that processes raw waveforms.\n",
    "- U-Net Structure: Encoder-decoder with skip connections for multiscale feature extraction.\n",
    "- Bidirectional LSTMs: Added between encoder and decoder to capture long-term temporal relationships.\n",
    "\n",
    "Improvements in v2:\n",
    "- Deeper architecture with more layers.\n",
    "- Better training strategies (e.g., dynamic mixing).\n",
    "- Optional transformer layers in later variants.\n",
    "\n",
    "Advantages:\n",
    "- Strong separation quality, especially for music.\n",
    "- Handles variable-length inputs well.\n",
    "\n",
    "Limitations:\n",
    "- Computationally heavier than ConvTasNet due to LSTMs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Installing Stuff and Basic Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T17:39:09.263247Z",
     "iopub.status.busy": "2025-04-18T17:39:09.262879Z",
     "iopub.status.idle": "2025-04-18T17:39:35.831763Z",
     "shell.execute_reply": "2025-04-18T17:39:35.830384Z",
     "shell.execute_reply.started": "2025-04-18T17:39:09.263222Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install musdb\n",
    "!pip install mir_eval\n",
    "!pip install museval\n",
    "\n",
    "# Installing SpeechBrain via pip\n",
    "BRANCH = 'develop'\n",
    "!python -m pip install git+https://github.com/speechbrain/speechbrain.git@$BRANCH\n",
    "\n",
    "# Clone SpeechBrain repository\n",
    "!git clone https://github.com/speechbrain/speechbrain/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T11:24:58.454154Z",
     "iopub.status.busy": "2025-04-17T11:24:58.453926Z",
     "iopub.status.idle": "2025-04-17T11:24:58.885104Z",
     "shell.execute_reply": "2025-04-17T11:24:58.883941Z",
     "shell.execute_reply.started": "2025-04-17T11:24:58.454131Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m np\u001b[38;5;241m.\u001b[39mfloat_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmusdb\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m MUS_DB_PATH \u001b[38;5;241m=\u001b[39m \u001b[43mdb_path\u001b[49m\n\u001b[1;32m      8\u001b[0m mus \u001b[38;5;241m=\u001b[39m musdb\u001b[38;5;241m.\u001b[39mDB(root\u001b[38;5;241m=\u001b[39mMUS_DB_PATH)\n\u001b[1;32m      9\u001b[0m mus_train \u001b[38;5;241m=\u001b[39m musdb\u001b[38;5;241m.\u001b[39mDB(root\u001b[38;5;241m=\u001b[39mMUS_DB_PATH,subsets\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'db_path' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "np.float_ = np.float64\n",
    "import musdb\n",
    "\n",
    "MUS_DB_PATH = db_path\n",
    "\n",
    "mus = musdb.DB(root=MUS_DB_PATH)\n",
    "mus_train = musdb.DB(root=MUS_DB_PATH,subsets=\"train\", split=\"train\")\n",
    "mus_valid = musdb.DB(root=MUS_DB_PATH,subsets=\"train\", split=\"valid\")\n",
    "mus_test = musdb.DB(root=MUS_DB_PATH,subsets=\"test\")\n",
    "print(mus_train[0])\n",
    "print(mus_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T17:39:35.833692Z",
     "iopub.status.busy": "2025-04-18T17:39:35.833434Z",
     "iopub.status.idle": "2025-04-18T17:39:35.837453Z",
     "shell.execute_reply": "2025-04-18T17:39:35.836720Z",
     "shell.execute_reply.started": "2025-04-18T17:39:35.833667Z"
    }
   },
   "outputs": [],
   "source": [
    "db_path = '/notebooks/data'\n",
    "output_path = '/notebooks/results'\n",
    "result_file_path = '/notebooks/metrics.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T17:39:35.839074Z",
     "iopub.status.busy": "2025-04-18T17:39:35.838860Z",
     "iopub.status.idle": "2025-04-18T17:39:35.851657Z",
     "shell.execute_reply": "2025-04-18T17:39:35.850699Z",
     "shell.execute_reply.started": "2025-04-18T17:39:35.839053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%file dataset.py\n",
    "\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import musdb\n",
    "import numpy as np\n",
    "import speechbrain as sb\n",
    "import psutil\n",
    "\n",
    "\n",
    "class MusDBDataset(Dataset):\n",
    "    def __init__(self, root, subset=\"train\", split=None, target_sr=8000, chunk_size=15):\n",
    "        \"\"\"\n",
    "        True lazy-loading for MUSDB\n",
    "        :param chunk_size: in seconds\n",
    "        \"\"\"\n",
    "        if split is not None:\n",
    "            self.db = musdb.DB(root=root, subsets=subset, split=split, is_wav=False)\n",
    "        else:\n",
    "            self.db = musdb.DB(root=root, subsets=subset, is_wav=False)\n",
    "        self.target_sr = target_sr\n",
    "        self.chunk_size = chunk_size\n",
    "        self.tracks = [{\n",
    "            \"path\": track.path,\n",
    "            \"duration\": track.duration,\n",
    "            \"rate\": track.rate,\n",
    "            \"stem_id\": f\"{track.name}_{track.stem_id}\" # Needed for STEM access\n",
    "        } for track in self.db.tracks]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tracks)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        track_info = self.tracks[idx]\n",
    "        \n",
    "        # Load chunk directly from disk without full track loading\n",
    "        def load_stem_chunk(stem_name, random_chunk_val=0):\n",
    "            # MUSDB's internal lazy loading\n",
    "            track = self.db.tracks[idx]\n",
    "            if stem_name == \"mix\":\n",
    "                source = track\n",
    "            else:\n",
    "                source = track.targets[stem_name]\n",
    "            \n",
    "            # Calculate chunk bounds\n",
    "            start = random_chunk_val\n",
    "            stop = start + self.chunk_size * track_info[\"rate\"]\n",
    "            \n",
    "            # Load only the needed segment\n",
    "            audio = source.audio[start:stop]\n",
    "            \n",
    "            # Convert and resample\n",
    "            audio_tensor = torch.from_numpy(audio).float().permute(1, 0)\n",
    "            return torchaudio.functional.resample(\n",
    "                audio_tensor,\n",
    "                orig_freq=track_info[\"rate\"],\n",
    "                new_freq=self.target_sr\n",
    "            ).mean(dim=0, keepdim=False)\n",
    "            \n",
    "        \n",
    "            # chunk_size = orig_sr * chunk_size_seconds  # Convert chunk size to samples\n",
    "        \n",
    "            # resampled_chunks = []\n",
    "        \n",
    "            # for i in range(0, audio_tensor.shape[1], chunk_size):\n",
    "            #     chunk = audio_tensor[:, i:i + chunk_size]  # Extract chunk\n",
    "            #     resampled_chunk = torchaudio.functional.resample(chunk, orig_freq=orig_sr, new_freq=target_sr)\n",
    "            #     resampled_chunks.append(resampled_chunk)\n",
    "        \n",
    "            # # Concatenate back the processed chunks\n",
    "            # # print(\"PROCESSING CHUNKS\")\n",
    "            # resampled_audio = torch.cat(resampled_chunks, dim=1)\n",
    "            # # print(resampled_audio.shape)\n",
    "            # resampled_audio = resampled_audio.mean(dim=0, keepdim=False)\n",
    "            # # print(resampled_audio.shape)\n",
    "            # # print(resampled_audio.shape)\n",
    "            # return resampled_audio\n",
    "        # if random_chunk_start_val:\n",
    "        \n",
    "        random_chunk_start_val = 0\n",
    "        \n",
    "        return {\n",
    "            \"mix_sig\": load_stem_chunk(\"mix\", random_chunk_start_val),\n",
    "            \"voc_sig\": load_stem_chunk(\"vocals\",random_chunk_start_val),\n",
    "            \"inst_sig\": load_stem_chunk(\"accompaniment\",random_chunk_start_val),\n",
    "            \"track_id\": track_info['stem_id']\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Building ConvTasNet\n",
    "\n",
    "#### ConvTasNet\n",
    "- Key Idea: A fully convolutional, end-to-end waveform model that avoids spectrograms entirely.\n",
    "- Encoder-Decoder: Uses 1D convolutions to learn a latent representation of the waveform.\n",
    "- Temporal Convolutional Network (TCN): Processes the latent features with stacked dilated convolutions for long-range dependencies.\n",
    "- Mask Estimation: Applies a soft mask in the latent space to separate sources.\n",
    "\n",
    "Advantages:\n",
    "- Lightweight and parallelizable (no RNNs).\n",
    "- Strong performance on speech and music separation.\n",
    "\n",
    "Limitations:\n",
    "- May struggle with very long-term dependencies due to fixed receptive fields.\n",
    "\n",
    "Personal Interests:\n",
    "Convtasnet proves to be one of the smallest models which generally speaking outperforms most other state-of-the-art models (in the waveform domain). This is intruiging because it uses a simple encoder decoder architecture with a masknet type bottleneck. The version we use in this has 3.3 Million parameters and is successfully able to detach vocals from its accompaniements\n",
    "\n",
    "Reference and Sources:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T15:57:04.262742Z",
     "iopub.status.busy": "2025-04-18T15:57:04.262413Z",
     "iopub.status.idle": "2025-04-18T15:57:04.274398Z",
     "shell.execute_reply": "2025-04-18T15:57:04.273368Z",
     "shell.execute_reply.started": "2025-04-18T15:57:04.262714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting convtasnet-hparams.yaml\n"
     ]
    }
   ],
   "source": [
    "%%file convtasnet-hparams.yaml\n",
    "# ################################\n",
    "# Model: ConvTasNet for Music Vocal Separation\n",
    "# https://arxiv.org/abs/2010.13154\n",
    "# Dataset : Musdb\n",
    "# ################################\n",
    "# Basic parameters\n",
    "# Seed needs to be set at top of yaml, before objects with parameters are made\n",
    "\n",
    "seed: 1234\n",
    "__set_seed: !apply:speechbrain.utils.seed_everything [!ref <seed>]\n",
    "\n",
    "# Data params\n",
    "data_folder: !PLACEHOLDER\n",
    "\n",
    "\n",
    "experiment_name: convtasnet\n",
    "output_folder: !ref /notebooks/results/<experiment_name>/<seed>\n",
    "train_log: !ref <output_folder>/train_log.txt\n",
    "save_folder: !ref <output_folder>/save\n",
    "train_data: !ref <output_folder>/train.json\n",
    "valid_data: !ref <output_folder>/valid.json\n",
    "test_data: !ref <output_folder>/test.json\n",
    "skip_prep: False\n",
    "db_path: '/notebooks/data'\n",
    "\n",
    "result_file_path: !PLACEHOLDER\n",
    "\n",
    "\n",
    "# Experiment params\n",
    "precision: fp16 # bf16, fp16 or fp32\n",
    "\n",
    "instrumental_classification: False\n",
    "noprogressbar: False\n",
    "save_audio: True # Save estimated sources on disk\n",
    "sample_rate: 8000\n",
    "n_audio_to_save: 10\n",
    "chunk_size: 20\n",
    "\n",
    "####################### Training Parameters ####################################\n",
    "N_epochs: 30\n",
    "batch_size: 1\n",
    "lr: 0.00015\n",
    "clip_grad_norm: 5\n",
    "loss_upper_lim: 999999  # this is the upper limit for an acceptable loss\n",
    "num_sources: 2\n",
    "\n",
    "\n",
    "# loss thresholding -- this thresholds the training loss\n",
    "threshold_byloss: True\n",
    "threshold: -30\n",
    "\n",
    "# Encoder parameters\n",
    "N_encoder_out: 256\n",
    "# out_channels: 256\n",
    "kernel_size: 16\n",
    "kernel_stride: 8\n",
    "\n",
    "# Dataloader options\n",
    "dataloader_opts:\n",
    "    batch_size: !ref <batch_size>\n",
    "    num_workers: 1\n",
    "\n",
    "\n",
    "# Specifying the network\n",
    "Encoder: !new:speechbrain.lobes.models.dual_path.Encoder\n",
    "    kernel_size: !ref <kernel_size>\n",
    "    out_channels: !ref <N_encoder_out>\n",
    "\n",
    "\n",
    "MaskNet: !new:speechbrain.lobes.models.conv_tasnet.MaskNet\n",
    "    N: 256\n",
    "    B: 256\n",
    "    H: 512\n",
    "    P: 3\n",
    "    X: 6\n",
    "    R: 4\n",
    "    C: !ref <num_sources>\n",
    "    norm_type: 'gLN'\n",
    "    causal: True\n",
    "    mask_nonlinear: 'relu'\n",
    "\n",
    "\n",
    "Decoder: !new:speechbrain.lobes.models.dual_path.Decoder\n",
    "    in_channels: !ref <N_encoder_out>\n",
    "    out_channels: 1\n",
    "    kernel_size: !ref <kernel_size>\n",
    "    stride: !ref <kernel_stride>\n",
    "    bias: False\n",
    "\n",
    "optimizer: !name:torch.optim.Adam\n",
    "    lr: !ref <lr>\n",
    "    weight_decay: 0\n",
    "\n",
    "loss: !name:speechbrain.nnet.losses.get_si_snr_with_pitwrapper\n",
    "\n",
    "lr_scheduler: !new:speechbrain.nnet.schedulers.ReduceLROnPlateau\n",
    "    factor: 0.5\n",
    "    patience: 2\n",
    "    dont_halve_until_epoch: 85\n",
    "\n",
    "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
    "    limit: !ref <N_epochs>\n",
    "\n",
    "modules:\n",
    "    encoder: !ref <Encoder>\n",
    "    decoder: !ref <Decoder>\n",
    "    masknet: !ref <MaskNet>\n",
    "\n",
    "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
    "    checkpoints_dir: !ref <save_folder>\n",
    "    recoverables:\n",
    "        encoder: !ref <Encoder>\n",
    "        decoder: !ref <Decoder>\n",
    "        masknet: !ref <MaskNet>\n",
    "        counter: !ref <epoch_counter>\n",
    "        lr_scheduler: !ref <lr_scheduler>\n",
    "\n",
    "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
    "    save_file: !ref <train_log>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T16:21:04.443885Z",
     "iopub.status.busy": "2025-04-18T16:21:04.443375Z",
     "iopub.status.idle": "2025-04-18T16:21:04.484544Z",
     "shell.execute_reply": "2025-04-18T16:21:04.483521Z",
     "shell.execute_reply.started": "2025-04-18T16:21:04.443885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting convtasnet-train.py\n"
     ]
    }
   ],
   "source": [
    "%%file convtasnet-train.py\n",
    "#!/usr/bin/env/python3\n",
    "\"\"\"\n",
    "Recipe for vocal separation using convtasnet\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "\n",
    "import musdb\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import speechbrain as sb\n",
    "import psutil\n",
    "from dataset import MusDBDataset\n",
    "\n",
    "\n",
    "import speechbrain as sb\n",
    "import speechbrain.nnet.schedulers as schedulers\n",
    "from speechbrain.core import AMPConfig\n",
    "from speechbrain.utils.distributed import run_on_main\n",
    "from speechbrain.utils.logger import get_logger\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import musdb\n",
    "\n",
    "\n",
    "# Define training procedure\n",
    "class Separation(sb.Brain):\n",
    "    def compute_forward(self, mix, targets, stage, noise=None):\n",
    "        \"\"\"Forward computations from the mixture to the separated signals.\"\"\"\n",
    "\n",
    "        # Unpack lists and put tensors in the right device\n",
    "        mix, mix_lens = mix       \n",
    "        mix, mix_lens = mix.to(self.device), mix_lens.to(self.device)      \n",
    "\n",
    "        # Convert targets to tensor\n",
    "        targets = torch.cat(\n",
    "            [targets[i][0].unsqueeze(-1) for i in range(self.hparams.num_sources)],\n",
    "            dim=-1,\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Separation\n",
    "        mix_w = self.hparams.Encoder(mix)\n",
    "        est_mask = self.hparams.MaskNet(mix_w)\n",
    "        mix_w = torch.stack([mix_w] * self.hparams.num_sources)\n",
    "        sep_h = mix_w * est_mask\n",
    "        \n",
    "        # Decoding\n",
    "        est_source = torch.cat(\n",
    "            [\n",
    "                self.hparams.Decoder(sep_h[i]).unsqueeze(-1)\n",
    "                for i in range(self.hparams.num_sources)\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "\n",
    "        # pad estimates as per requirement \n",
    "        T_origin = mix.size(1)\n",
    "        T_est = est_source.size(1)\n",
    "        if T_origin > T_est:\n",
    "            est_source = F.pad(est_source, (0, 0, 0, T_origin - T_est))\n",
    "        else:\n",
    "            est_source = est_source[:, :T_origin, :]\n",
    "\n",
    "        return est_source, targets\n",
    "\n",
    "    def compute_objectives(self, predictions, targets):\n",
    "        \"\"\"Computes the sinr loss\"\"\"\n",
    "        return self.hparams.loss(targets, predictions)\n",
    "\n",
    "    def fit_batch(self, batch):\n",
    "        \"\"\"Trains one batch\"\"\"\n",
    "        # print(\"INSIDE FIT BATCH\")\n",
    "        \n",
    "        amp = AMPConfig.from_name(self.precision)\n",
    "        should_step = (self.step % self.grad_accumulation_factor) == 0\n",
    "        # Unpacking batch list\n",
    "        mixture = batch.mix_sig\n",
    "        targets = [batch.voc_sig, batch.inst_sig] #mix_sig, voc_sig, inst_sig\n",
    "       \n",
    "        \n",
    "        predictions, targets = self.compute_forward(\n",
    "            mixture, targets, sb.Stage.TRAIN\n",
    "        )\n",
    "        loss = self.compute_objectives(predictions, targets)\n",
    "\n",
    "        if self.hparams.threshold_byloss:\n",
    "            th = self.hparams.threshold\n",
    "            loss = loss[loss > th]\n",
    "            if loss.nelement() > 0:\n",
    "                loss = loss.mean()\n",
    "        else:\n",
    "            loss = loss.mean()\n",
    "\n",
    "        if (\n",
    "            loss.nelement() > 0 and loss < self.hparams.loss_upper_lim\n",
    "        ):  # the fix for computational problems\n",
    "            loss.backward()\n",
    "            if self.hparams.clip_grad_norm >= 0:\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    self.modules.parameters(),\n",
    "                    self.hparams.clip_grad_norm,\n",
    "                )\n",
    "            self.optimizer.step()\n",
    "        else:\n",
    "            self.nonfinite_count += 1\n",
    "            logger.info(\n",
    "                \"infinite loss or empty loss! it happened {} times so far - skipping this batch\".format(\n",
    "                    self.nonfinite_count\n",
    "                )\n",
    "            )\n",
    "            loss.data = torch.tensor(0.0).to(self.device)\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        return loss.detach().cpu()\n",
    "\n",
    "    def evaluate_batch(self, batch, stage):\n",
    "        \"\"\"Computations needed for validation/test batches\"\"\"\n",
    "        snt_id = batch.track_id\n",
    "        mixture = batch.mix_sig\n",
    "        targets = [batch.voc_sig, batch.inst_sig]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictions, targets = self.compute_forward(mixture, targets, stage)\n",
    "            loss = self.compute_objectives(predictions, targets)\n",
    "\n",
    "        # Manage audio file saving\n",
    "        if stage == sb.Stage.TEST and self.hparams.save_audio:\n",
    "            if hasattr(self.hparams, \"n_audio_to_save\"):\n",
    "                if self.hparams.n_audio_to_save > 0:\n",
    "                    self.save_audio(snt_id[0], mixture, targets, predictions)\n",
    "                    self.hparams.n_audio_to_save += -1\n",
    "            else:\n",
    "                self.save_audio(snt_id[0], mixture, targets, predictions)\n",
    "\n",
    "        return loss.mean().detach()\n",
    "\n",
    "    def on_stage_end(self, stage, stage_loss, epoch):\n",
    "        \"\"\"Gets called at the end of a epoch.\"\"\"\n",
    "        # Compute/store important stats\n",
    "        stage_stats = {\"si-snr\": stage_loss}\n",
    "        if stage == sb.Stage.TRAIN:\n",
    "            self.train_stats = stage_stats\n",
    "\n",
    "        # Perform end-of-iteration things, like annealing, logging, etc.\n",
    "        if stage == sb.Stage.VALID:\n",
    "            # Learning rate annealing\n",
    "            if isinstance(\n",
    "                self.hparams.lr_scheduler, schedulers.ReduceLROnPlateau\n",
    "            ):\n",
    "                current_lr, next_lr = self.hparams.lr_scheduler(\n",
    "                    [self.optimizer], epoch, stage_loss\n",
    "                )\n",
    "                schedulers.update_learning_rate(self.optimizer, next_lr)\n",
    "            else:\n",
    "                # if we do not use the reducelronplateau, we do not change the lr\n",
    "                current_lr = self.hparams.optimizer.optim.param_groups[0][\"lr\"]\n",
    "\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                stats_meta={\"epoch\": epoch, \"lr\": current_lr},\n",
    "                train_stats=self.train_stats,\n",
    "                valid_stats=stage_stats,\n",
    "            )\n",
    "            self.checkpointer.save_and_keep_only(\n",
    "                meta={\"si-snr\": stage_stats[\"si-snr\"]}, min_keys=[\"si-snr\"]\n",
    "            )\n",
    "        elif stage == sb.Stage.TEST:\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                stats_meta={\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
    "                test_stats=stage_stats,\n",
    "            )\n",
    "\n",
    "\n",
    "    def cut_signals(self, mixture, targets):\n",
    "        \"\"\"This function selects a random segment of a given length within the mixture.\n",
    "        The corresponding targets are selected accordingly\"\"\"\n",
    "        randstart = torch.randint(\n",
    "            0,\n",
    "            1 + max(0, mixture.shape[1] - self.hparams.training_signal_len),\n",
    "            (1,),\n",
    "        ).item()\n",
    "        targets = targets[\n",
    "            :, randstart : randstart + self.hparams.training_signal_len, :\n",
    "        ]\n",
    "        mixture = mixture[\n",
    "            :, randstart : randstart + self.hparams.training_signal_len\n",
    "        ]\n",
    "        return mixture, targets\n",
    "\n",
    "    def reset_layer_recursively(self, layer):\n",
    "        \"\"\"Reinitializes the parameters of the neural networks\"\"\"\n",
    "        if hasattr(layer, \"reset_parameters\"):\n",
    "            layer.reset_parameters()\n",
    "        for child_layer in layer.modules():\n",
    "            if layer != child_layer:\n",
    "                self.reset_layer_recursively(child_layer)\n",
    "\n",
    "    def save_results(self, test_loader):\n",
    "        \"\"\"This script computes the SDR and SI-SNR metrics and saves\n",
    "        them into a csv file\"\"\"\n",
    "\n",
    "        # This package is required for SDR computation\n",
    "        from mir_eval.separation import bss_eval_sources\n",
    "\n",
    "        # Create folders where to store audio\n",
    "        save_file = os.path.join(self.hparams.output_folder, \"test_results.csv\")\n",
    "\n",
    "        # Variable init\n",
    "        all_sdrs = []\n",
    "        all_sdrs_i = []\n",
    "        all_sisnrs = []\n",
    "        all_sisnrs_i = []\n",
    "        csv_columns = [\"snt_id\", \"sdr\", \"sdr_i\", \"si-snr\", \"si-snr_i\"]\n",
    "\n",
    "\n",
    "        def is_silent(source, threshold=1e-6):\n",
    "            return np.max(np.abs(source[0])) < threshold or np.max(np.abs(source[1])) < threshold\n",
    "\n",
    "        with open(save_file, \"w\", newline=\"\", encoding=\"utf-8\") as results_csv:\n",
    "            writer = csv.DictWriter(results_csv, fieldnames=csv_columns)\n",
    "            writer.writeheader()\n",
    "            skip_cnt = 0\n",
    "\n",
    "            # Loop over all test sentence\n",
    "            with tqdm(test_loader, dynamic_ncols=True) as t:\n",
    "                for i, batch in enumerate(t):\n",
    "                    # Apply Separation\n",
    "                    mixture, mix_len = batch.mix_sig\n",
    "                    snt_id = batch.track_id\n",
    "                    targets = [batch.voc_sig, batch.inst_sig]\n",
    "                   \n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        predictions, targets = self.compute_forward(\n",
    "                            batch.mix_sig, targets, sb.Stage.TEST\n",
    "                        )\n",
    "\n",
    "                    # Compute SI-SNR\n",
    "                    sisnr = self.compute_objectives(predictions, targets)\n",
    "\n",
    "                    # Compute SI-SNR improvement\n",
    "                    mixture_signal = torch.stack(\n",
    "                        [mixture] * self.hparams.num_sources, dim=-1\n",
    "                    )\n",
    "                    mixture_signal = mixture_signal.to(targets.device)\n",
    "                    sisnr_baseline = self.compute_objectives(\n",
    "                        mixture_signal, targets\n",
    "                    )\n",
    "                    sisnr_i = sisnr - sisnr_baseline\n",
    "                    \n",
    "     \n",
    "                    if not is_silent(targets[0].t().cpu().numpy()) and not is_silent(predictions[0].t().detach().cpu().numpy()) and not is_silent(mixture_signal[0].t().detach().cpu().numpy()):\n",
    "                        \n",
    "                    \n",
    "                        sdr, _, _, _ = bss_eval_sources(\n",
    "                            targets[0].t().cpu().numpy(),\n",
    "                            predictions[0].t().detach().cpu().numpy(),\n",
    "                            compute_permutation=False\n",
    "                        )\n",
    "    \n",
    "                        sdr_baseline, _, _, _ = bss_eval_sources(\n",
    "                            targets[0].t().cpu().numpy(),\n",
    "                            mixture_signal[0].t().detach().cpu().numpy(),\n",
    "                            compute_permutation=False\n",
    "                        )\n",
    "    \n",
    "                        sdr_i = sdr.mean() - sdr_baseline.mean()\n",
    "    \n",
    "                        # Saving on a csv file\n",
    "                        row = {\n",
    "                            \"snt_id\": snt_id[0],\n",
    "                            \"sdr\": sdr.mean(),\n",
    "                            \"sdr_i\": sdr_i,\n",
    "                            \"si-snr\": -sisnr.item(),\n",
    "                            \"si-snr_i\": -sisnr_i.item(),\n",
    "                        }\n",
    "                        writer.writerow(row)\n",
    "    \n",
    "                        # Metric Accumulation\n",
    "                        all_sdrs.append(sdr.mean())\n",
    "                        all_sdrs_i.append(sdr_i.mean())\n",
    "                        all_sisnrs.append(-sisnr.item())\n",
    "                        all_sisnrs_i.append(-sisnr_i.item())\n",
    "    \n",
    "                \n",
    "                    else:\n",
    "                        skip_cnt += 1\n",
    "                        print(f\"Warning: skipping silent target, this has happened {skip_cnt} times\")\n",
    "\n",
    "                row = {\n",
    "                    \"snt_id\": \"avg\",\n",
    "                    \"sdr\": np.array(all_sdrs).mean(),\n",
    "                    \"sdr_i\": np.array(all_sdrs_i).mean(),\n",
    "                    \"si-snr\": np.array(all_sisnrs).mean(),\n",
    "                    \"si-snr_i\": np.array(all_sisnrs_i).mean(),\n",
    "                }\n",
    "                writer.writerow(row)\n",
    "                \n",
    "        logger.info(\"Mean SISNR is {}\".format(np.array(all_sisnrs).mean()))\n",
    "        logger.info(\"Mean SISNRi is {}\".format(np.array(all_sisnrs_i).mean()))\n",
    "        logger.info(\"Mean SDR is {}\".format(np.array(all_sdrs).mean()))\n",
    "        logger.info(\"Mean SDRi is {}\".format(np.array(all_sdrs_i).mean()))\n",
    "        if(self.hparams.result_file_path != \"\"):\n",
    "            with open(self.hparams.result_file_path, \"a\", newline=\"\", encoding=\"utf-8\") as metrics_csv:\n",
    "                writer = csv.DictWriter(metrics_csv, fieldnames=[\"model_name\", \"n_epochs\", \"learning_rate\", \"chunk_size\", \"sample_rate\", \"sdr\", \"sdr_i\", \"si-snr\", \"si-snr_i\"])\n",
    "                row = {\n",
    "                        \"model_name\": self.hparams.experiment_name,\n",
    "                        \"learning_rate\": self.hparams.lr,\n",
    "                        \"n_epochs\": self.hparams.N_epochs,\n",
    "                        \"chunk_size\":self.hparams.chunk_size,\n",
    "                        \"sample_rate\":self.hparams.sample_rate,\n",
    "                        \"sdr\": np.array(all_sdrs).mean(),\n",
    "                        \"sdr_i\": np.array(all_sdrs_i).mean(),\n",
    "                        \"si-snr\": np.array(all_sisnrs).mean(),\n",
    "                        \"si-snr_i\": np.array(all_sisnrs_i).mean(),\n",
    "                    }\n",
    "                writer.writerow(row)\n",
    "\n",
    "    def save_audio(self, snt_id, mixture, targets, predictions):\n",
    "        \"saves the test audio (mixture, targets, and estimated sources) on disk\"\n",
    "\n",
    "        # Create output folder\n",
    "        save_path = os.path.join(self.hparams.save_folder, \"audio_results\")\n",
    "        if not os.path.exists(save_path):\n",
    "            os.mkdir(save_path)\n",
    "\n",
    "        for ns in range(self.hparams.num_sources):\n",
    "            # Estimated source\n",
    "            signal = predictions[0, :, ns]\n",
    "            signal = signal / signal.abs().max()\n",
    "            save_file = os.path.join(\n",
    "                save_path, \"item{}_source{}hat.wav\".format(snt_id, ns + 1)\n",
    "            )\n",
    "            torchaudio.save(\n",
    "                save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n",
    "            )\n",
    "\n",
    "            # Original source\n",
    "            signal = targets[0, :, ns]\n",
    "            signal = signal / signal.abs().max()\n",
    "            save_file = os.path.join(\n",
    "                save_path, \"item{}_source{}.wav\".format(snt_id, ns + 1)\n",
    "            )\n",
    "            torchaudio.save(\n",
    "                save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n",
    "            )\n",
    "\n",
    "        # Mixture\n",
    "        signal = mixture[0][0, :]\n",
    "        signal = signal / signal.abs().max()\n",
    "        save_file = os.path.join(save_path, \"item{}_mix.wav\".format(snt_id))\n",
    "        torchaudio.save(\n",
    "            save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load hyperparameters file with command-line overrides\n",
    "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
    "    with open(hparams_file, encoding=\"utf-8\") as fin:\n",
    "        hparams = load_hyperpyyaml(fin, overrides)\n",
    "\n",
    "    # Initialize ddp (useful only for multi-GPU DDP training)\n",
    "    sb.utils.distributed.ddp_init_group(run_opts)\n",
    "\n",
    "    # Logger info\n",
    "    logger = get_logger(__name__)\n",
    "\n",
    "    # Create experiment directory\n",
    "    sb.create_experiment_directory(\n",
    "        experiment_directory=hparams[\"output_folder\"],\n",
    "        hyperparams_to_save=hparams_file,\n",
    "        overrides=overrides,\n",
    "    )\n",
    "\n",
    "    # Update precision to bf16 if the device is CPU and precision is fp16\n",
    "    if run_opts.get(\"device\") == \"cpu\" and hparams.get(\"precision\") == \"fp16\":\n",
    "        hparams[\"precision\"] = \"bf16\"\n",
    "\n",
    "   \n",
    "\n",
    "    # Brain class initialization\n",
    "    separator = Separation(\n",
    "        modules=hparams[\"modules\"],\n",
    "        opt_class=hparams[\"optimizer\"],\n",
    "        hparams=hparams,\n",
    "        run_opts=run_opts,\n",
    "        checkpointer=hparams[\"checkpointer\"],\n",
    "    )\n",
    " \n",
    "    # Training\n",
    "        \n",
    "    # Usage with SpeechBrain\n",
    "    train_data = MusDBDataset(hparams[\"db_path\"], subset=\"train\", split=\"train\", target_sr=hparams[\"sample_rate\"], chunk_size=hparams[\"chunk_size\"])\n",
    "    valid_data = MusDBDataset(hparams[\"db_path\"], subset=\"train\", split=\"valid\", target_sr=hparams[\"sample_rate\"], chunk_size=hparams[\"chunk_size\"])\n",
    "    test_data = MusDBDataset(hparams[\"db_path\"], subset=\"test\", target_sr=hparams[\"sample_rate\"], chunk_size=hparams[\"chunk_size\"])\n",
    "    \n",
    "\n",
    "    # Create DataLoader\n",
    "    train_loader = sb.dataio.dataloader.make_dataloader(\n",
    "        train_data,\n",
    "        batch_size=hparams[\"batch_size\"],\n",
    "        collate_fn=sb.dataio.batch.PaddedBatch  # Handles variable lengths\n",
    "    )\n",
    "\n",
    "    valid_loader = sb.dataio.dataloader.make_dataloader(\n",
    "        valid_data,\n",
    "        batch_size=hparams[\"batch_size\"],\n",
    "        collate_fn=sb.dataio.batch.PaddedBatch  # Handles variable lengths\n",
    "    )\n",
    "\n",
    "    test_loader = sb.dataio.dataloader.make_dataloader(\n",
    "        test_data,\n",
    "        batch_size=hparams[\"batch_size\"],\n",
    "        collate_fn=sb.dataio.batch.PaddedBatch  # Handles variable lengths\n",
    "    )\n",
    "    \n",
    "    separator.fit(\n",
    "        separator.hparams.epoch_counter,\n",
    "        train_loader,\n",
    "        valid_loader,\n",
    "        train_loader_kwargs=hparams[\"dataloader_opts\"],\n",
    "        valid_loader_kwargs=hparams[\"dataloader_opts\"],\n",
    "    )\n",
    "\n",
    "    # # Eval\n",
    "    separator.evaluate(test_loader, min_key=\"si-snr\")\n",
    "    separator.save_results(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T16:21:10.818109Z",
     "iopub.status.busy": "2025-04-18T16:21:10.817434Z",
     "iopub.status.idle": "2025-04-18T16:32:46.533851Z",
     "shell.execute_reply": "2025-04-18T16:32:46.532769Z",
     "shell.execute_reply.started": "2025-04-18T16:21:10.818109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speechbrain.utils.quirks - Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
      "speechbrain.utils.quirks - Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
      "speechbrain.core - Beginning experiment!\n",
      "speechbrain.core - Experiment folder: /notebooks/results/convtasnet/1234\n",
      "speechbrain.core - Info: precision arg from hparam file is used\n",
      "speechbrain.core - Info: noprogressbar arg from hparam file is used\n",
      "speechbrain.core - Gradscaler enabled: `True`\n",
      "speechbrain.core - Using training precision: `--precision=fp16`\n",
      "speechbrain.core - Using evaluation precision: `--eval_precision=fp32`\n",
      "speechbrain.core - Separation Model Statistics:\n",
      "* Total Number of Trainable Parameters: 6.6M\n",
      "* Total Number of Parameters: 6.6M\n",
      "* Trainable Parameters represent 100.0000% of the total size.\n",
      "speechbrain.utils.checkpoints - Loading a checkpoint from /notebooks/results/convtasnet/1234/save/CKPT+2025-04-17+11-37-49+00\n",
      "speechbrain.utils.checkpoints - Loading a checkpoint from /notebooks/results/convtasnet/1234/save/CKPT+2025-04-17+11-14-02+00\n",
      "100%|███████████████████████████████████████████| 44/44 [04:55<00:00,  6.72s/it]\n",
      "speechbrain.utils.train_logger - Epoch loaded: 29 - test si-snr: 13.45\n",
      "  0%|                                                    | 0/44 [00:00<?, ?it/s]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      "  2%|█                                           | 1/44 [00:09<06:27,  9.01s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      "  5%|██                                          | 2/44 [00:19<06:45,  9.66s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      "  7%|███                                         | 3/44 [00:28<06:24,  9.39s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      "  9%|████                                        | 4/44 [00:37<06:12,  9.31s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 11%|█████                                       | 5/44 [00:44<05:28,  8.42s/it]Warning: skipping silent target, this has happened 1 times\n",
      " 14%|██████                                      | 6/44 [00:50<04:46,  7.54s/it]Warning: skipping silent target, this has happened 2 times\n",
      " 16%|███████                                     | 7/44 [00:57<04:42,  7.64s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 18%|████████                                    | 8/44 [01:09<05:17,  8.81s/it]Warning: skipping silent target, this has happened 3 times\n",
      " 20%|█████████                                   | 9/44 [01:16<04:49,  8.27s/it]Warning: skipping silent target, this has happened 4 times\n",
      " 23%|█████████▊                                 | 10/44 [01:21<04:10,  7.37s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 25%|██████████▊                                | 11/44 [01:31<04:28,  8.12s/it]Warning: skipping silent target, this has happened 5 times\n",
      " 27%|███████████▋                               | 12/44 [01:38<04:13,  7.91s/it]Warning: skipping silent target, this has happened 6 times\n",
      " 30%|████████████▋                              | 13/44 [01:49<04:32,  8.80s/it]Warning: skipping silent target, this has happened 7 times\n",
      " 32%|█████████████▋                             | 14/44 [01:58<04:23,  8.77s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 34%|██████████████▋                            | 15/44 [02:03<03:45,  7.77s/it]Warning: skipping silent target, this has happened 8 times\n",
      " 36%|███████████████▋                           | 16/44 [02:11<03:35,  7.69s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 39%|████████████████▌                          | 17/44 [02:22<03:55,  8.73s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 41%|█████████████████▌                         | 18/44 [02:32<03:56,  9.08s/it]Warning: skipping silent target, this has happened 9 times\n",
      " 43%|██████████████████▌                        | 19/44 [02:38<03:23,  8.13s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 45%|███████████████████▌                       | 20/44 [02:50<03:46,  9.46s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 48%|████████████████████▌                      | 21/44 [03:00<03:40,  9.59s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 50%|█████████████████████▌                     | 22/44 [03:10<03:34,  9.75s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 52%|██████████████████████▍                    | 23/44 [03:18<03:08,  8.97s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 55%|███████████████████████▍                   | 24/44 [03:22<02:33,  7.65s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 57%|████████████████████████▍                  | 25/44 [03:29<02:23,  7.55s/it]Warning: skipping silent target, this has happened 10 times\n",
      " 59%|█████████████████████████▍                 | 26/44 [03:35<02:04,  6.94s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 61%|██████████████████████████▍                | 27/44 [03:46<02:20,  8.27s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 64%|███████████████████████████▎               | 28/44 [03:58<02:26,  9.19s/it]Warning: skipping silent target, this has happened 11 times\n",
      " 66%|████████████████████████████▎              | 29/44 [04:04<02:05,  8.36s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 68%|█████████████████████████████▎             | 30/44 [04:13<01:57,  8.41s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 70%|██████████████████████████████▎            | 31/44 [04:20<01:43,  7.97s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 73%|███████████████████████████████▎           | 32/44 [04:32<01:51,  9.29s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 75%|████████████████████████████████▎          | 33/44 [04:40<01:39,  9.06s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 77%|█████████████████████████████████▏         | 34/44 [04:49<01:28,  8.88s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 80%|██████████████████████████████████▏        | 35/44 [05:01<01:27,  9.70s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 82%|███████████████████████████████████▏       | 36/44 [05:13<01:23, 10.48s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 84%|████████████████████████████████████▏      | 37/44 [05:25<01:17, 11.09s/it]Warning: skipping silent target, this has happened 12 times\n",
      " 86%|█████████████████████████████████████▏     | 38/44 [05:32<00:58,  9.75s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 89%|██████████████████████████████████████     | 39/44 [05:41<00:47,  9.59s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 91%|███████████████████████████████████████    | 40/44 [05:49<00:35,  8.99s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 93%|████████████████████████████████████████   | 41/44 [05:56<00:24,  8.32s/it]/notebooks/convtasnet-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/convtasnet-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 95%|█████████████████████████████████████████  | 42/44 [06:05<00:17,  8.70s/it]Warning: skipping silent target, this has happened 13 times\n",
      " 98%|██████████████████████████████████████████ | 43/44 [06:11<00:07,  7.85s/it]Warning: skipping silent target, this has happened 14 times\n",
      "100%|███████████████████████████████████████████| 44/44 [06:17<00:00,  8.58s/it]\n",
      "__main__ - Mean SISNR is -4.7064932703971865\n",
      "__main__ - Mean SISNRi is -1.5918735583623251\n",
      "__main__ - Mean SDR is -11.287826744262206\n",
      "__main__ - Mean SDRi is -11.90952736865888\n",
      "writing to file\n"
     ]
    }
   ],
   "source": [
    "!python3 convtasnet-train.py convtasnet-hparams.yaml --data_folder=db_path --result_file_path={result_file_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DPRNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T17:39:35.853919Z",
     "iopub.status.busy": "2025-04-18T17:39:35.853667Z",
     "iopub.status.idle": "2025-04-18T17:39:35.862069Z",
     "shell.execute_reply": "2025-04-18T17:39:35.861531Z",
     "shell.execute_reply.started": "2025-04-18T17:39:35.853897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dprnn-hparams.yaml\n"
     ]
    }
   ],
   "source": [
    "%%file dprnn-hparams.yaml\n",
    "# ################################\n",
    "# Model: DPRNN for Music vocal separation\n",
    "# https://arxiv.org/abs/2010.13154\n",
    "# Dataset : MusDB\n",
    "# ################################\n",
    "# Basic parameters\n",
    "# Seed needs to be set at top of yaml, before objects with parameters are made\n",
    "\n",
    "\n",
    "seed: 1234\n",
    "__set_seed: !apply:speechbrain.utils.seed_everything [!ref <seed>]\n",
    "\n",
    "# Data params\n",
    "\n",
    "data_folder: !PLACEHOLDER\n",
    "result_file_path: !PLACEHOLDER\n",
    "\n",
    "experiment_name: dprnn\n",
    "output_folder: !ref /notebooks/results/<experiment_name>/<seed>\n",
    "train_log: !ref <output_folder>/train_log.txt\n",
    "save_folder: !ref <output_folder>/save\n",
    "train_data: !ref <output_folder>/train.json\n",
    "valid_data: !ref <output_folder>/valid.json\n",
    "test_data: !ref <output_folder>/test.json\n",
    "skip_prep: False\n",
    "db_path: '/notebooks/data'\n",
    "\n",
    "\n",
    "# Experiment params\n",
    "precision: fp16 # bf16, fp16 or fp32\n",
    "\n",
    "instrumental_classification: False\n",
    "noprogressbar: False\n",
    "save_audio: True # Save estimated sources on disk\n",
    "sample_rate: 8000\n",
    "n_audio_to_save: 10\n",
    "chunk_size: 20\n",
    "\n",
    "####################### Training Parameters ####################################\n",
    "N_epochs: 30\n",
    "batch_size: 1\n",
    "lr: 0.00015\n",
    "clip_grad_norm: 5\n",
    "loss_upper_lim: 999999  # this is the upper limit for an acceptable loss\n",
    "num_sources: 2\n",
    "\n",
    "\n",
    "\n",
    "# loss thresholding -- this thresholds the training loss\n",
    "threshold_byloss: True\n",
    "threshold: -30\n",
    "\n",
    "# Encoder parameters\n",
    "N_encoder_out: 256\n",
    "out_channels: 256\n",
    "kernel_size: 16\n",
    "kernel_stride: 8\n",
    "\n",
    "# Dataloader options\n",
    "dataloader_opts:\n",
    "    batch_size: !ref <batch_size>\n",
    "    num_workers: 3\n",
    "\n",
    "\n",
    "# Specifying the network\n",
    "Encoder: !new:speechbrain.lobes.models.dual_path.Encoder\n",
    "    kernel_size: !ref <kernel_size>\n",
    "    out_channels: !ref <N_encoder_out>\n",
    "\n",
    "intra: !new:speechbrain.lobes.models.dual_path.SBRNNBlock\n",
    "    num_layers: 1\n",
    "    input_size: !ref <out_channels>\n",
    "    hidden_channels: !ref <out_channels>\n",
    "    dropout: 0\n",
    "    bidirectional: True\n",
    "\n",
    "inter: !new:speechbrain.lobes.models.dual_path.SBRNNBlock\n",
    "    num_layers: 1\n",
    "    input_size: !ref <out_channels>\n",
    "    hidden_channels: !ref <out_channels>\n",
    "    dropout: 0\n",
    "    bidirectional: True\n",
    "\n",
    "MaskNet: !new:speechbrain.lobes.models.dual_path.Dual_Path_Model\n",
    "    num_spks: !ref <num_sources>\n",
    "    in_channels: !ref <N_encoder_out>\n",
    "    out_channels: !ref <out_channels>\n",
    "    num_layers: 6\n",
    "    K: 250\n",
    "    intra_model: !ref <intra>\n",
    "    inter_model: !ref <inter>\n",
    "    norm: ln\n",
    "    linear_layer_after_inter_intra: True\n",
    "    skip_around_intra: True\n",
    "\n",
    "Decoder: !new:speechbrain.lobes.models.dual_path.Decoder\n",
    "    in_channels: !ref <N_encoder_out>\n",
    "    out_channels: 1\n",
    "    kernel_size: !ref <kernel_size>\n",
    "    stride: !ref <kernel_stride>\n",
    "    bias: False\n",
    "\n",
    "optimizer: !name:torch.optim.Adam\n",
    "    lr: !ref <lr>\n",
    "    weight_decay: 0\n",
    "\n",
    "loss: !name:speechbrain.nnet.losses.get_si_snr_with_pitwrapper\n",
    "\n",
    "lr_scheduler: !new:speechbrain.nnet.schedulers.ReduceLROnPlateau\n",
    "    factor: 0.5\n",
    "    patience: 2\n",
    "    dont_halve_until_epoch: 85\n",
    "\n",
    "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
    "    limit: !ref <N_epochs>\n",
    "\n",
    "modules:\n",
    "    encoder: !ref <Encoder>\n",
    "    decoder: !ref <Decoder>\n",
    "    masknet: !ref <MaskNet>\n",
    "\n",
    "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
    "    checkpoints_dir: !ref <save_folder>\n",
    "    recoverables:\n",
    "        encoder: !ref <Encoder>\n",
    "        decoder: !ref <Decoder>\n",
    "        masknet: !ref <MaskNet>\n",
    "        counter: !ref <epoch_counter>\n",
    "        lr_scheduler: !ref <lr_scheduler>\n",
    "\n",
    "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
    "    save_file: !ref <train_log>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T17:39:35.863305Z",
     "iopub.status.busy": "2025-04-18T17:39:35.862974Z",
     "iopub.status.idle": "2025-04-18T17:39:35.875576Z",
     "shell.execute_reply": "2025-04-18T17:39:35.875020Z",
     "shell.execute_reply.started": "2025-04-18T17:39:35.863285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dprnn-train.py\n"
     ]
    }
   ],
   "source": [
    "%%file dprnn-train.py\n",
    "#!/usr/bin/env/python3\n",
    "\"\"\"\n",
    "Recipe for vocal separation using convtasnet\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "\n",
    "import musdb\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import speechbrain as sb\n",
    "import psutil\n",
    "from dataset import MusDBDataset\n",
    "\n",
    "\n",
    "import speechbrain as sb\n",
    "import speechbrain.nnet.schedulers as schedulers\n",
    "from speechbrain.core import AMPConfig\n",
    "from speechbrain.utils.distributed import run_on_main\n",
    "from speechbrain.utils.logger import get_logger\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import musdb\n",
    "\n",
    "\n",
    "# Define training procedure\n",
    "class Separation(sb.Brain):\n",
    "    def compute_forward(self, mix, targets, stage, noise=None):\n",
    "        \"\"\"Forward computations from the mixture to the separated signals.\"\"\"\n",
    "\n",
    "        # Unpack lists and put tensors in the right device\n",
    "        mix, mix_lens = mix       \n",
    "        mix, mix_lens = mix.to(self.device), mix_lens.to(self.device)      \n",
    "\n",
    "        # Convert targets to tensor\n",
    "        targets = torch.cat(\n",
    "            [targets[i][0].unsqueeze(-1) for i in range(self.hparams.num_sources)],\n",
    "            dim=-1,\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Separation\n",
    "        mix_w = self.hparams.Encoder(mix)\n",
    "        est_mask = self.hparams.MaskNet(mix_w)\n",
    "        mix_w = torch.stack([mix_w] * self.hparams.num_sources)\n",
    "        sep_h = mix_w * est_mask\n",
    "        \n",
    "        # Decoding\n",
    "        est_source = torch.cat(\n",
    "            [\n",
    "                self.hparams.Decoder(sep_h[i]).unsqueeze(-1)\n",
    "                for i in range(self.hparams.num_sources)\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "\n",
    "        # pad estimates as per requirement \n",
    "        T_origin = mix.size(1)\n",
    "        T_est = est_source.size(1)\n",
    "        if T_origin > T_est:\n",
    "            est_source = F.pad(est_source, (0, 0, 0, T_origin - T_est))\n",
    "        else:\n",
    "            est_source = est_source[:, :T_origin, :]\n",
    "\n",
    "        return est_source, targets\n",
    "\n",
    "    def compute_objectives(self, predictions, targets):\n",
    "        \"\"\"Computes the sinr loss\"\"\"\n",
    "        return self.hparams.loss(targets, predictions)\n",
    "\n",
    "    def fit_batch(self, batch):\n",
    "        \"\"\"Trains one batch\"\"\"\n",
    "        # print(\"INSIDE FIT BATCH\")\n",
    "        \n",
    "        amp = AMPConfig.from_name(self.precision)\n",
    "        should_step = (self.step % self.grad_accumulation_factor) == 0\n",
    "        # Unpacking batch list\n",
    "        mixture = batch.mix_sig\n",
    "        targets = [batch.voc_sig, batch.inst_sig] #mix_sig, voc_sig, inst_sig\n",
    "       \n",
    "        \n",
    "        predictions, targets = self.compute_forward(\n",
    "            mixture, targets, sb.Stage.TRAIN\n",
    "        )\n",
    "        loss = self.compute_objectives(predictions, targets)\n",
    "\n",
    "        if self.hparams.threshold_byloss:\n",
    "            th = self.hparams.threshold\n",
    "            loss = loss[loss > th]\n",
    "            if loss.nelement() > 0:\n",
    "                loss = loss.mean()\n",
    "        else:\n",
    "            loss = loss.mean()\n",
    "\n",
    "        if (\n",
    "            loss.nelement() > 0 and loss < self.hparams.loss_upper_lim\n",
    "        ):  # the fix for computational problems\n",
    "            loss.backward()\n",
    "            if self.hparams.clip_grad_norm >= 0:\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    self.modules.parameters(),\n",
    "                    self.hparams.clip_grad_norm,\n",
    "                )\n",
    "            self.optimizer.step()\n",
    "        else:\n",
    "            self.nonfinite_count += 1\n",
    "            logger.info(\n",
    "                \"infinite loss or empty loss! it happened {} times so far - skipping this batch\".format(\n",
    "                    self.nonfinite_count\n",
    "                )\n",
    "            )\n",
    "            loss.data = torch.tensor(0.0).to(self.device)\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        return loss.detach().cpu()\n",
    "\n",
    "    def evaluate_batch(self, batch, stage):\n",
    "        \"\"\"Computations needed for validation/test batches\"\"\"\n",
    "        snt_id = batch.track_id\n",
    "        mixture = batch.mix_sig\n",
    "        targets = [batch.voc_sig, batch.inst_sig]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictions, targets = self.compute_forward(mixture, targets, stage)\n",
    "            loss = self.compute_objectives(predictions, targets)\n",
    "\n",
    "        # Manage audio file saving\n",
    "        if stage == sb.Stage.TEST and self.hparams.save_audio:\n",
    "            if hasattr(self.hparams, \"n_audio_to_save\"):\n",
    "                if self.hparams.n_audio_to_save > 0:\n",
    "                    self.save_audio(snt_id[0], mixture, targets, predictions)\n",
    "                    self.hparams.n_audio_to_save += -1\n",
    "            else:\n",
    "                self.save_audio(snt_id[0], mixture, targets, predictions)\n",
    "\n",
    "        return loss.mean().detach()\n",
    "\n",
    "    def on_stage_end(self, stage, stage_loss, epoch):\n",
    "        \"\"\"Gets called at the end of a epoch.\"\"\"\n",
    "        # Compute/store important stats\n",
    "        stage_stats = {\"si-snr\": stage_loss}\n",
    "        if stage == sb.Stage.TRAIN:\n",
    "            self.train_stats = stage_stats\n",
    "\n",
    "        # Perform end-of-iteration things, like annealing, logging, etc.\n",
    "        if stage == sb.Stage.VALID:\n",
    "            # Learning rate annealing\n",
    "            if isinstance(\n",
    "                self.hparams.lr_scheduler, schedulers.ReduceLROnPlateau\n",
    "            ):\n",
    "                current_lr, next_lr = self.hparams.lr_scheduler(\n",
    "                    [self.optimizer], epoch, stage_loss\n",
    "                )\n",
    "                schedulers.update_learning_rate(self.optimizer, next_lr)\n",
    "            else:\n",
    "                # if we do not use the reducelronplateau, we do not change the lr\n",
    "                current_lr = self.hparams.optimizer.optim.param_groups[0][\"lr\"]\n",
    "\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                stats_meta={\"epoch\": epoch, \"lr\": current_lr},\n",
    "                train_stats=self.train_stats,\n",
    "                valid_stats=stage_stats,\n",
    "            )\n",
    "            self.checkpointer.save_and_keep_only(\n",
    "                meta={\"si-snr\": stage_stats[\"si-snr\"]}, min_keys=[\"si-snr\"]\n",
    "            )\n",
    "        elif stage == sb.Stage.TEST:\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                stats_meta={\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
    "                test_stats=stage_stats,\n",
    "            )\n",
    "\n",
    "\n",
    "    def cut_signals(self, mixture, targets):\n",
    "        \"\"\"This function selects a random segment of a given length within the mixture.\n",
    "        The corresponding targets are selected accordingly\"\"\"\n",
    "        randstart = torch.randint(\n",
    "            0,\n",
    "            1 + max(0, mixture.shape[1] - self.hparams.training_signal_len),\n",
    "            (1,),\n",
    "        ).item()\n",
    "        targets = targets[\n",
    "            :, randstart : randstart + self.hparams.training_signal_len, :\n",
    "        ]\n",
    "        mixture = mixture[\n",
    "            :, randstart : randstart + self.hparams.training_signal_len\n",
    "        ]\n",
    "        return mixture, targets\n",
    "\n",
    "    def reset_layer_recursively(self, layer):\n",
    "        \"\"\"Reinitializes the parameters of the neural networks\"\"\"\n",
    "        if hasattr(layer, \"reset_parameters\"):\n",
    "            layer.reset_parameters()\n",
    "        for child_layer in layer.modules():\n",
    "            if layer != child_layer:\n",
    "                self.reset_layer_recursively(child_layer)\n",
    "\n",
    "    def save_results(self, test_loader):\n",
    "        \"\"\"This script computes the SDR and SI-SNR metrics and saves\n",
    "        them into a csv file\"\"\"\n",
    "\n",
    "        # This package is required for SDR computation\n",
    "        from mir_eval.separation import bss_eval_sources\n",
    "\n",
    "        # Create folders where to store audio\n",
    "        save_file = os.path.join(self.hparams.output_folder, \"test_results.csv\")\n",
    "\n",
    "        # Variable init\n",
    "        all_sdrs = []\n",
    "        all_sdrs_i = []\n",
    "        all_sisnrs = []\n",
    "        all_sisnrs_i = []\n",
    "        csv_columns = [\"snt_id\", \"sdr\", \"sdr_i\", \"si-snr\", \"si-snr_i\"]\n",
    "\n",
    "\n",
    "        def is_silent(source, threshold=1e-6):\n",
    "            return np.max(np.abs(source[0])) < threshold or np.max(np.abs(source[1])) < threshold\n",
    "\n",
    "        with open(save_file, \"w\", newline=\"\", encoding=\"utf-8\") as results_csv:\n",
    "            writer = csv.DictWriter(results_csv, fieldnames=csv_columns)\n",
    "            writer.writeheader()\n",
    "            skip_cnt = 0\n",
    "\n",
    "            # Loop over all test sentence\n",
    "            with tqdm(test_loader, dynamic_ncols=True) as t:\n",
    "                for i, batch in enumerate(t):\n",
    "                    # Apply Separation\n",
    "                    mixture, mix_len = batch.mix_sig\n",
    "                    snt_id = batch.track_id\n",
    "                    targets = [batch.voc_sig, batch.inst_sig]\n",
    "                   \n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        predictions, targets = self.compute_forward(\n",
    "                            batch.mix_sig, targets, sb.Stage.TEST\n",
    "                        )\n",
    "\n",
    "                    # Compute SI-SNR\n",
    "                    sisnr = self.compute_objectives(predictions, targets)\n",
    "\n",
    "                    # Compute SI-SNR improvement\n",
    "                    mixture_signal = torch.stack(\n",
    "                        [mixture] * self.hparams.num_sources, dim=-1\n",
    "                    )\n",
    "                    mixture_signal = mixture_signal.to(targets.device)\n",
    "                    sisnr_baseline = self.compute_objectives(\n",
    "                        mixture_signal, targets\n",
    "                    )\n",
    "                    sisnr_i = sisnr - sisnr_baseline\n",
    "                    \n",
    "     \n",
    "                    if not is_silent(targets[0].t().cpu().numpy()) and not is_silent(predictions[0].t().detach().cpu().numpy()) and not is_silent(mixture_signal[0].t().detach().cpu().numpy()):\n",
    "                        \n",
    "                    \n",
    "                        sdr, _, _, _ = bss_eval_sources(\n",
    "                            targets[0].t().cpu().numpy(),\n",
    "                            predictions[0].t().detach().cpu().numpy(),\n",
    "                            compute_permutation=False\n",
    "                        )\n",
    "    \n",
    "                        sdr_baseline, _, _, _ = bss_eval_sources(\n",
    "                            targets[0].t().cpu().numpy(),\n",
    "                            mixture_signal[0].t().detach().cpu().numpy(),\n",
    "                            compute_permutation=False\n",
    "                        )\n",
    "    \n",
    "                        sdr_i = sdr.mean() - sdr_baseline.mean()\n",
    "    \n",
    "                        # Saving on a csv file\n",
    "                        row = {\n",
    "                            \"snt_id\": snt_id[0],\n",
    "                            \"sdr\": sdr.mean(),\n",
    "                            \"sdr_i\": sdr_i,\n",
    "                            \"si-snr\": -sisnr.item(),\n",
    "                            \"si-snr_i\": -sisnr_i.item(),\n",
    "                        }\n",
    "                        writer.writerow(row)\n",
    "    \n",
    "                        # Metric Accumulation\n",
    "                        all_sdrs.append(sdr.mean())\n",
    "                        all_sdrs_i.append(sdr_i.mean())\n",
    "                        all_sisnrs.append(-sisnr.item())\n",
    "                        all_sisnrs_i.append(-sisnr_i.item())\n",
    "                    else:\n",
    "                        skip_cnt += 1\n",
    "                        print(f\"Warning: skipping silent target, this has happened {skip_cnt} times\")\n",
    "            row = {\n",
    "                \"snt_id\": \"avg\",\n",
    "                \"sdr\": np.array(all_sdrs).mean(),\n",
    "                \"sdr_i\": np.array(all_sdrs_i).mean(),\n",
    "                \"si-snr\": np.array(all_sisnrs).mean(),\n",
    "                \"si-snr_i\": np.array(all_sisnrs_i).mean(),\n",
    "            }\n",
    "            writer.writerow(row)\n",
    "\n",
    "        logger.info(\"Mean SISNR is {}\".format(np.array(all_sisnrs).mean()))\n",
    "        logger.info(\"Mean SISNRi is {}\".format(np.array(all_sisnrs_i).mean()))\n",
    "        logger.info(\"Mean SDR is {}\".format(np.array(all_sdrs).mean()))\n",
    "        logger.info(\"Mean SDRi is {}\".format(np.array(all_sdrs_i).mean()))\n",
    "        if(self.hparams.result_file_path != \"\"):\n",
    "            with open(self.hparams.result_file_path, \"a\", newline=\"\", encoding=\"utf-8\") as metrics_csv:\n",
    "                writer = csv.DictWriter(metrics_csv, fieldnames=[\"model_name\", \"n_epochs\", \"learning_rate\", \"chunk_size\", \"sample_rate\", \"sdr\", \"sdr_i\", \"si-snr\", \"si-snr_i\"])\n",
    "                row = {\n",
    "                        \"model_name\": self.hparams.experiment_name,\n",
    "                        \"learning_rate\": self.hparams.lr,\n",
    "                        \"n_epochs\": self.hparams.N_epochs,\n",
    "                        \"chunk_size\":self.hparams.chunk_size,\n",
    "                        \"sample_rate\":self.hparams.sample_rate,\n",
    "                        \"sdr\": np.array(all_sdrs).mean(),\n",
    "                        \"sdr_i\": np.array(all_sdrs_i).mean(),\n",
    "                        \"si-snr\": np.array(all_sisnrs).mean(),\n",
    "                        \"si-snr_i\": np.array(all_sisnrs_i).mean(),\n",
    "                    }\n",
    "                writer.writerow(row)\n",
    "\n",
    "    def save_audio(self, snt_id, mixture, targets, predictions):\n",
    "        \"saves the test audio (mixture, targets, and estimated sources) on disk\"\n",
    "\n",
    "        # Create output folder\n",
    "        save_path = os.path.join(self.hparams.save_folder, \"audio_results\")\n",
    "        if not os.path.exists(save_path):\n",
    "            os.mkdir(save_path)\n",
    "\n",
    "        for ns in range(self.hparams.num_sources):\n",
    "            # Estimated source\n",
    "            signal = predictions[0, :, ns]\n",
    "            signal = signal / signal.abs().max()\n",
    "            save_file = os.path.join(\n",
    "                save_path, \"item{}_source{}hat.wav\".format(snt_id, ns + 1)\n",
    "            )\n",
    "            torchaudio.save(\n",
    "                save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n",
    "            )\n",
    "\n",
    "            # Original source\n",
    "            signal = targets[0, :, ns]\n",
    "            signal = signal / signal.abs().max()\n",
    "            save_file = os.path.join(\n",
    "                save_path, \"item{}_source{}.wav\".format(snt_id, ns + 1)\n",
    "            )\n",
    "            torchaudio.save(\n",
    "                save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n",
    "            )\n",
    "\n",
    "        # Mixture\n",
    "        signal = mixture[0][0, :]\n",
    "        signal = signal / signal.abs().max()\n",
    "        save_file = os.path.join(save_path, \"item{}_mix.wav\".format(snt_id))\n",
    "        torchaudio.save(\n",
    "            save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load hyperparameters file with command-line overrides\n",
    "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
    "    with open(hparams_file, encoding=\"utf-8\") as fin:\n",
    "        hparams = load_hyperpyyaml(fin, overrides)\n",
    "\n",
    "    # Initialize ddp (useful only for multi-GPU DDP training)\n",
    "    sb.utils.distributed.ddp_init_group(run_opts)\n",
    "\n",
    "    # Logger info\n",
    "    logger = get_logger(__name__)\n",
    "\n",
    "    # Create experiment directory\n",
    "    sb.create_experiment_directory(\n",
    "        experiment_directory=hparams[\"output_folder\"],\n",
    "        hyperparams_to_save=hparams_file,\n",
    "        overrides=overrides,\n",
    "    )\n",
    "\n",
    "    # Update precision to bf16 if the device is CPU and precision is fp16\n",
    "    if run_opts.get(\"device\") == \"cpu\" and hparams.get(\"precision\") == \"fp16\":\n",
    "        hparams[\"precision\"] = \"bf16\"\n",
    "\n",
    "   \n",
    "\n",
    "    # Brain class initialization\n",
    "    separator = Separation(\n",
    "        modules=hparams[\"modules\"],\n",
    "        opt_class=hparams[\"optimizer\"],\n",
    "        hparams=hparams,\n",
    "        run_opts=run_opts,\n",
    "        checkpointer=hparams[\"checkpointer\"],\n",
    "    )\n",
    " \n",
    "    # Training\n",
    "        \n",
    "    # Usage with SpeechBrain\n",
    "    train_data = MusDBDataset(hparams[\"db_path\"], subset=\"train\", split=\"train\", target_sr=hparams[\"sample_rate\"], chunk_size=hparams[\"chunk_size\"])\n",
    "    valid_data = MusDBDataset(hparams[\"db_path\"], subset=\"train\", split=\"valid\", target_sr=hparams[\"sample_rate\"], chunk_size=hparams[\"chunk_size\"])\n",
    "    test_data = MusDBDataset(hparams[\"db_path\"], subset=\"test\", target_sr=hparams[\"sample_rate\"], chunk_size=hparams[\"chunk_size\"])\n",
    "    \n",
    "\n",
    "    # Create DataLoader\n",
    "    train_loader = sb.dataio.dataloader.make_dataloader(\n",
    "        train_data,\n",
    "        batch_size=hparams[\"batch_size\"],\n",
    "        collate_fn=sb.dataio.batch.PaddedBatch  # Handles variable lengths\n",
    "    )\n",
    "\n",
    "    valid_loader = sb.dataio.dataloader.make_dataloader(\n",
    "        valid_data,\n",
    "        batch_size=hparams[\"batch_size\"],\n",
    "        collate_fn=sb.dataio.batch.PaddedBatch  # Handles variable lengths\n",
    "    )\n",
    "\n",
    "    test_loader = sb.dataio.dataloader.make_dataloader(\n",
    "        test_data,\n",
    "        batch_size=hparams[\"batch_size\"],\n",
    "        collate_fn=sb.dataio.batch.PaddedBatch  # Handles variable lengths\n",
    "    )\n",
    "    # print(\"STARTING FIT\")\n",
    "    separator.fit(\n",
    "        separator.hparams.epoch_counter,\n",
    "        train_loader,\n",
    "        valid_loader,\n",
    "        train_loader_kwargs=hparams[\"dataloader_opts\"],\n",
    "        valid_loader_kwargs=hparams[\"dataloader_opts\"],\n",
    "    )\n",
    "\n",
    "    # # Eval\n",
    "    separator.evaluate(test_loader, min_key=\"si-snr\")\n",
    "    separator.save_results(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T17:39:35.876805Z",
     "iopub.status.busy": "2025-04-18T17:39:35.876207Z",
     "iopub.status.idle": "2025-04-18T17:51:05.432423Z",
     "shell.execute_reply": "2025-04-18T17:51:05.431248Z",
     "shell.execute_reply.started": "2025-04-18T17:39:35.876784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speechbrain.utils.quirks - Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
      "speechbrain.utils.quirks - Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
      "speechbrain.core - Beginning experiment!\n",
      "speechbrain.core - Experiment folder: /notebooks/results/dprnn/1234\n",
      "speechbrain.core - Info: precision arg from hparam file is used\n",
      "speechbrain.core - Info: noprogressbar arg from hparam file is used\n",
      "speechbrain.core - Gradscaler enabled: `True`\n",
      "speechbrain.core - Using training precision: `--precision=fp16`\n",
      "speechbrain.core - Using evaluation precision: `--eval_precision=fp32`\n",
      "speechbrain.core - Separation Model Statistics:\n",
      "* Total Number of Trainable Parameters: 14.6M\n",
      "* Total Number of Parameters: 14.6M\n",
      "* Trainable Parameters represent 100.0000% of the total size.\n",
      "speechbrain.utils.checkpoints - Loading a checkpoint from /notebooks/results/dprnn/1234/save/CKPT+2025-04-18+00-10-38+00\n",
      "speechbrain.utils.checkpoints - Loading a checkpoint from /notebooks/results/dprnn/1234/save/CKPT+2025-04-17+15-52-56+00\n",
      "100%|███████████████████████████████████████████| 44/44 [05:02<00:00,  6.87s/it]\n",
      "speechbrain.utils.train_logger - Epoch loaded: 21 - test si-snr: 11.66\n",
      "  0%|                                                    | 0/44 [00:00<?, ?it/s]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      "  2%|█                                           | 1/44 [00:06<04:38,  6.48s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      "  5%|██                                          | 2/44 [00:12<04:26,  6.34s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      "  7%|███                                         | 3/44 [00:19<04:30,  6.60s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      "  9%|████                                        | 4/44 [00:28<05:03,  7.59s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 11%|█████                                       | 5/44 [00:35<04:42,  7.25s/it]Warning: skipping silent target, this has happened 1 times\n",
      " 14%|██████                                      | 6/44 [00:41<04:16,  6.74s/it]Warning: skipping silent target, this has happened 2 times\n",
      " 16%|███████                                     | 7/44 [00:48<04:15,  6.89s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 18%|████████                                    | 8/44 [00:55<04:13,  7.05s/it]Warning: skipping silent target, this has happened 3 times\n",
      " 20%|█████████                                   | 9/44 [01:02<03:59,  6.84s/it]Warning: skipping silent target, this has happened 4 times\n",
      " 23%|█████████▊                                 | 10/44 [01:06<03:31,  6.23s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 25%|██████████▊                                | 11/44 [01:16<03:54,  7.12s/it]Warning: skipping silent target, this has happened 5 times\n",
      " 27%|███████████▋                               | 12/44 [01:23<03:49,  7.18s/it]Warning: skipping silent target, this has happened 6 times\n",
      " 30%|████████████▋                              | 13/44 [01:36<04:33,  8.84s/it]Warning: skipping silent target, this has happened 7 times\n",
      " 32%|█████████████▋                             | 14/44 [01:44<04:17,  8.58s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 34%|██████████████▋                            | 15/44 [01:49<03:45,  7.78s/it]Warning: skipping silent target, this has happened 8 times\n",
      " 36%|███████████████▋                           | 16/44 [01:57<03:33,  7.62s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 39%|████████████████▌                          | 17/44 [02:06<03:37,  8.07s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 41%|█████████████████▌                         | 18/44 [02:18<04:03,  9.38s/it]Warning: skipping silent target, this has happened 9 times\n",
      " 43%|██████████████████▌                        | 19/44 [02:24<03:26,  8.26s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 45%|███████████████████▌                       | 20/44 [02:31<03:10,  7.95s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 48%|████████████████████▌                      | 21/44 [02:40<03:08,  8.18s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 50%|█████████████████████▌                     | 22/44 [02:52<03:24,  9.30s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 52%|██████████████████████▍                    | 23/44 [02:58<02:55,  8.34s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 55%|███████████████████████▍                   | 24/44 [03:02<02:20,  7.00s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 57%|████████████████████████▍                  | 25/44 [03:09<02:12,  6.95s/it]Warning: skipping silent target, this has happened 10 times\n",
      " 59%|█████████████████████████▍                 | 26/44 [03:14<01:59,  6.63s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 61%|██████████████████████████▍                | 27/44 [03:27<02:20,  8.29s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 64%|███████████████████████████▎               | 28/44 [03:35<02:12,  8.27s/it]Warning: skipping silent target, this has happened 11 times\n",
      " 66%|████████████████████████████▎              | 29/44 [03:41<01:56,  7.76s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 68%|█████████████████████████████▎             | 30/44 [03:49<01:49,  7.82s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 70%|██████████████████████████████▎            | 31/44 [03:57<01:40,  7.73s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 73%|███████████████████████████████▎           | 32/44 [04:13<02:04, 10.39s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 75%|████████████████████████████████▎          | 33/44 [04:26<02:01, 11.05s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 77%|█████████████████████████████████▏         | 34/44 [04:38<01:53, 11.39s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 80%|██████████████████████████████████▏        | 35/44 [04:49<01:41, 11.32s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 82%|███████████████████████████████████▏       | 36/44 [04:57<01:21, 10.19s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 84%|████████████████████████████████████▏      | 37/44 [05:04<01:05,  9.29s/it]Warning: skipping silent target, this has happened 12 times\n",
      " 86%|█████████████████████████████████████▏     | 38/44 [05:11<00:50,  8.48s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 89%|██████████████████████████████████████     | 39/44 [05:20<00:43,  8.62s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 91%|███████████████████████████████████████    | 40/44 [05:28<00:33,  8.41s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 93%|████████████████████████████████████████   | 41/44 [05:33<00:22,  7.54s/it]/notebooks/dprnn-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/dprnn-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 95%|█████████████████████████████████████████  | 42/44 [05:40<00:14,  7.43s/it]Warning: skipping silent target, this has happened 13 times\n",
      " 98%|██████████████████████████████████████████ | 43/44 [05:46<00:06,  6.88s/it]Warning: skipping silent target, this has happened 14 times\n",
      "100%|███████████████████████████████████████████| 44/44 [05:52<00:00,  8.02s/it]\n",
      "__main__ - Mean SISNR is -2.120277292529742\n",
      "__main__ - Mean SISNRi is 0.9943424234787623\n",
      "__main__ - Mean SDR is -11.540835154956211\n",
      "__main__ - Mean SDRi is -12.162535779352888\n"
     ]
    }
   ],
   "source": [
    "!python3 dprnn-train.py dprnn-hparams.yaml --data_folder=db_path --result_file_path={result_file_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sepformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T17:51:05.434450Z",
     "iopub.status.busy": "2025-04-18T17:51:05.434144Z",
     "iopub.status.idle": "2025-04-18T17:51:05.447340Z",
     "shell.execute_reply": "2025-04-18T17:51:05.446547Z",
     "shell.execute_reply.started": "2025-04-18T17:51:05.434420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sepformer-hparams.yaml\n"
     ]
    }
   ],
   "source": [
    "%%file sepformer-hparams.yaml\n",
    "# ################################\n",
    "# Model: DPRNN for Music vocal separation\n",
    "# https://arxiv.org/abs/2010.13154\n",
    "# Dataset : MusDB\n",
    "# ################################\n",
    "# Basic parameters\n",
    "# Seed needs to be set at top of yaml, before objects with parameters are made\n",
    "\n",
    "\n",
    "seed: 1234\n",
    "__set_seed: !apply:speechbrain.utils.seed_everything [!ref <seed>]\n",
    "\n",
    "# Data params\n",
    "\n",
    "data_folder: !PLACEHOLDER\n",
    "result_file_path: !PLACEHOLDER\n",
    "\n",
    "\n",
    "experiment_name: sepformer\n",
    "output_folder: !ref /notebooks/results/<experiment_name>/<seed>\n",
    "train_log: !ref <output_folder>/train_log.txt\n",
    "save_folder: !ref <output_folder>/save\n",
    "train_data: !ref <output_folder>/train.json\n",
    "valid_data: !ref <output_folder>/valid.json\n",
    "test_data: !ref <output_folder>/test.json\n",
    "skip_prep: False\n",
    "db_path: '/notebooks/data'\n",
    "\n",
    "\n",
    "# Experiment params\n",
    "precision: fp16 # bf16, fp16 or fp32\n",
    "\n",
    "instrumental_classification: False\n",
    "noprogressbar: False\n",
    "save_audio: True # Save estimated sources on disk\n",
    "sample_rate: 8000\n",
    "n_audio_to_save: 10\n",
    "chunk_size: 30\n",
    "\n",
    "####################### Training Parameters ####################################\n",
    "N_epochs: 30\n",
    "batch_size: 1\n",
    "lr: 0.00015\n",
    "clip_grad_norm: 5\n",
    "loss_upper_lim: 999999  # this is the upper limit for an acceptable loss\n",
    "num_sources: 2\n",
    "\n",
    "\n",
    "\n",
    "# loss thresholding -- this thresholds the training loss\n",
    "threshold_byloss: True\n",
    "threshold: -30\n",
    "\n",
    "# Encoder parameters\n",
    "N_encoder_out: 256\n",
    "out_channels: 256\n",
    "kernel_size: 16\n",
    "kernel_stride: 8\n",
    "\n",
    "# Dataloader options\n",
    "# Set num_workers: 0 on MacOS due to behavior of the multiprocessing library\n",
    "dataloader_opts:\n",
    "    batch_size: !ref <batch_size>\n",
    "    num_workers: 3\n",
    "\n",
    "\n",
    "# Specifying the network\n",
    "Encoder: !new:speechbrain.lobes.models.dual_path.Encoder\n",
    "    kernel_size: !ref <kernel_size>\n",
    "    out_channels: !ref <N_encoder_out>\n",
    "\n",
    "\n",
    "SBtfintra: !new:speechbrain.lobes.models.dual_path.SBTransformerBlock\n",
    "    num_layers: 2\n",
    "    d_model: !ref <out_channels>\n",
    "    nhead: 4\n",
    "    d_ffn: 1024\n",
    "    dropout: 0\n",
    "    use_positional_encoding: True\n",
    "    norm_before: True\n",
    "\n",
    "SBtfinter: !new:speechbrain.lobes.models.dual_path.SBTransformerBlock\n",
    "    num_layers: 2\n",
    "    d_model: !ref <out_channels>\n",
    "    nhead: 4\n",
    "    d_ffn: 1024\n",
    "    dropout: 0\n",
    "    use_positional_encoding: True\n",
    "    norm_before: True\n",
    "\n",
    "MaskNet: !new:speechbrain.lobes.models.dual_path.Dual_Path_Model\n",
    "    num_spks: !ref <num_sources>\n",
    "    in_channels: !ref <N_encoder_out>\n",
    "    out_channels: !ref <out_channels>\n",
    "    num_layers: 2\n",
    "    K: 250\n",
    "    intra_model: !ref <SBtfintra>\n",
    "    inter_model: !ref <SBtfinter>\n",
    "    norm: ln\n",
    "    linear_layer_after_inter_intra: False\n",
    "    skip_around_intra: True\n",
    "\n",
    "Decoder: !new:speechbrain.lobes.models.dual_path.Decoder\n",
    "    in_channels: !ref <N_encoder_out>\n",
    "    out_channels: 1\n",
    "    kernel_size: !ref <kernel_size>\n",
    "    stride: !ref <kernel_stride>\n",
    "    bias: False\n",
    "\n",
    "optimizer: !name:torch.optim.Adam\n",
    "    lr: !ref <lr>\n",
    "    weight_decay: 0\n",
    "\n",
    "loss: !name:speechbrain.nnet.losses.get_si_snr_with_pitwrapper\n",
    "\n",
    "lr_scheduler: !new:speechbrain.nnet.schedulers.ReduceLROnPlateau\n",
    "    factor: 0.5\n",
    "    patience: 2\n",
    "    dont_halve_until_epoch: 85\n",
    "\n",
    "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
    "    limit: !ref <N_epochs>\n",
    "\n",
    "modules:\n",
    "    encoder: !ref <Encoder>\n",
    "    decoder: !ref <Decoder>\n",
    "    masknet: !ref <MaskNet>\n",
    "\n",
    "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
    "    checkpoints_dir: !ref <save_folder>\n",
    "    recoverables:\n",
    "        encoder: !ref <Encoder>\n",
    "        decoder: !ref <Decoder>\n",
    "        masknet: !ref <MaskNet>\n",
    "        counter: !ref <epoch_counter>\n",
    "        lr_scheduler: !ref <lr_scheduler>\n",
    "\n",
    "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
    "    save_file: !ref <train_log>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T17:51:05.449311Z",
     "iopub.status.busy": "2025-04-18T17:51:05.448978Z",
     "iopub.status.idle": "2025-04-18T17:51:05.471467Z",
     "shell.execute_reply": "2025-04-18T17:51:05.470385Z",
     "shell.execute_reply.started": "2025-04-18T17:51:05.449276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sepformer-train.py\n"
     ]
    }
   ],
   "source": [
    "%%file sepformer-train.py\n",
    "#!/usr/bin/env/python3\n",
    "\"\"\"\n",
    "Recipe for vocal separation using convtasnet\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "\n",
    "import musdb\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import speechbrain as sb\n",
    "import psutil\n",
    "from dataset import MusDBDataset\n",
    "\n",
    "\n",
    "import speechbrain as sb\n",
    "import speechbrain.nnet.schedulers as schedulers\n",
    "from speechbrain.core import AMPConfig\n",
    "from speechbrain.utils.distributed import run_on_main\n",
    "from speechbrain.utils.logger import get_logger\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import musdb\n",
    "\n",
    "\n",
    "# Define training procedure\n",
    "class Separation(sb.Brain):\n",
    "    def compute_forward(self, mix, targets, stage, noise=None):\n",
    "        \"\"\"Forward computations from the mixture to the separated signals.\"\"\"\n",
    "\n",
    "        # Unpack lists and put tensors in the right device\n",
    "        mix, mix_lens = mix       \n",
    "        mix, mix_lens = mix.to(self.device), mix_lens.to(self.device)      \n",
    "\n",
    "        # Convert targets to tensor\n",
    "        targets = torch.cat(\n",
    "            [targets[i][0].unsqueeze(-1) for i in range(self.hparams.num_sources)],\n",
    "            dim=-1,\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Separation\n",
    "        mix_w = self.hparams.Encoder(mix)\n",
    "        est_mask = self.hparams.MaskNet(mix_w)\n",
    "        mix_w = torch.stack([mix_w] * self.hparams.num_sources)\n",
    "        sep_h = mix_w * est_mask\n",
    "        \n",
    "        # Decoding\n",
    "        est_source = torch.cat(\n",
    "            [\n",
    "                self.hparams.Decoder(sep_h[i]).unsqueeze(-1)\n",
    "                for i in range(self.hparams.num_sources)\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "\n",
    "        # pad estimates as per requirement \n",
    "        T_origin = mix.size(1)\n",
    "        T_est = est_source.size(1)\n",
    "        if T_origin > T_est:\n",
    "            est_source = F.pad(est_source, (0, 0, 0, T_origin - T_est))\n",
    "        else:\n",
    "            est_source = est_source[:, :T_origin, :]\n",
    "\n",
    "        return est_source, targets\n",
    "\n",
    "    def compute_objectives(self, predictions, targets):\n",
    "        \"\"\"Computes the sinr loss\"\"\"\n",
    "        return self.hparams.loss(targets, predictions)\n",
    "\n",
    "    def fit_batch(self, batch):\n",
    "        \"\"\"Trains one batch\"\"\"\n",
    "        # print(\"INSIDE FIT BATCH\")\n",
    "        \n",
    "        amp = AMPConfig.from_name(self.precision)\n",
    "        should_step = (self.step % self.grad_accumulation_factor) == 0\n",
    "        # Unpacking batch list\n",
    "        mixture = batch.mix_sig\n",
    "        targets = [batch.voc_sig, batch.inst_sig] #mix_sig, voc_sig, inst_sig\n",
    "       \n",
    "        \n",
    "        predictions, targets = self.compute_forward(\n",
    "            mixture, targets, sb.Stage.TRAIN\n",
    "        )\n",
    "        loss = self.compute_objectives(predictions, targets)\n",
    "\n",
    "        if self.hparams.threshold_byloss:\n",
    "            th = self.hparams.threshold\n",
    "            loss = loss[loss > th]\n",
    "            if loss.nelement() > 0:\n",
    "                loss = loss.mean()\n",
    "        else:\n",
    "            loss = loss.mean()\n",
    "\n",
    "        if (\n",
    "            loss.nelement() > 0 and loss < self.hparams.loss_upper_lim\n",
    "        ):  # the fix for computational problems\n",
    "            loss.backward()\n",
    "            if self.hparams.clip_grad_norm >= 0:\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    self.modules.parameters(),\n",
    "                    self.hparams.clip_grad_norm,\n",
    "                )\n",
    "            self.optimizer.step()\n",
    "        else:\n",
    "            self.nonfinite_count += 1\n",
    "            logger.info(\n",
    "                \"infinite loss or empty loss! it happened {} times so far - skipping this batch\".format(\n",
    "                    self.nonfinite_count\n",
    "                )\n",
    "            )\n",
    "            loss.data = torch.tensor(0.0).to(self.device)\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        return loss.detach().cpu()\n",
    "\n",
    "    def evaluate_batch(self, batch, stage):\n",
    "        \"\"\"Computations needed for validation/test batches\"\"\"\n",
    "        snt_id = batch.track_id\n",
    "        mixture = batch.mix_sig\n",
    "        targets = [batch.voc_sig, batch.inst_sig]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictions, targets = self.compute_forward(mixture, targets, stage)\n",
    "            loss = self.compute_objectives(predictions, targets)\n",
    "\n",
    "        # Manage audio file saving\n",
    "        if stage == sb.Stage.TEST and self.hparams.save_audio:\n",
    "            if hasattr(self.hparams, \"n_audio_to_save\"):\n",
    "                if self.hparams.n_audio_to_save > 0:\n",
    "                    self.save_audio(snt_id[0], mixture, targets, predictions)\n",
    "                    self.hparams.n_audio_to_save += -1\n",
    "            else:\n",
    "                self.save_audio(snt_id[0], mixture, targets, predictions)\n",
    "\n",
    "        return loss.mean().detach()\n",
    "\n",
    "    def on_stage_end(self, stage, stage_loss, epoch):\n",
    "        \"\"\"Gets called at the end of a epoch.\"\"\"\n",
    "        # Compute/store important stats\n",
    "        stage_stats = {\"si-snr\": stage_loss}\n",
    "        if stage == sb.Stage.TRAIN:\n",
    "            self.train_stats = stage_stats\n",
    "\n",
    "        # Perform end-of-iteration things, like annealing, logging, etc.\n",
    "        if stage == sb.Stage.VALID:\n",
    "            # Learning rate annealing\n",
    "            if isinstance(\n",
    "                self.hparams.lr_scheduler, schedulers.ReduceLROnPlateau\n",
    "            ):\n",
    "                current_lr, next_lr = self.hparams.lr_scheduler(\n",
    "                    [self.optimizer], epoch, stage_loss\n",
    "                )\n",
    "                schedulers.update_learning_rate(self.optimizer, next_lr)\n",
    "            else:\n",
    "                # if we do not use the reducelronplateau, we do not change the lr\n",
    "                current_lr = self.hparams.optimizer.optim.param_groups[0][\"lr\"]\n",
    "\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                stats_meta={\"epoch\": epoch, \"lr\": current_lr},\n",
    "                train_stats=self.train_stats,\n",
    "                valid_stats=stage_stats,\n",
    "            )\n",
    "            self.checkpointer.save_and_keep_only(\n",
    "                meta={\"si-snr\": stage_stats[\"si-snr\"]}, min_keys=[\"si-snr\"]\n",
    "            )\n",
    "        elif stage == sb.Stage.TEST:\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                stats_meta={\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
    "                test_stats=stage_stats,\n",
    "            )\n",
    "\n",
    "\n",
    "    def cut_signals(self, mixture, targets):\n",
    "        \"\"\"This function selects a random segment of a given length within the mixture.\n",
    "        The corresponding targets are selected accordingly\"\"\"\n",
    "        randstart = torch.randint(\n",
    "            0,\n",
    "            1 + max(0, mixture.shape[1] - self.hparams.training_signal_len),\n",
    "            (1,),\n",
    "        ).item()\n",
    "        targets = targets[\n",
    "            :, randstart : randstart + self.hparams.training_signal_len, :\n",
    "        ]\n",
    "        mixture = mixture[\n",
    "            :, randstart : randstart + self.hparams.training_signal_len\n",
    "        ]\n",
    "        return mixture, targets\n",
    "\n",
    "    def reset_layer_recursively(self, layer):\n",
    "        \"\"\"Reinitializes the parameters of the neural networks\"\"\"\n",
    "        if hasattr(layer, \"reset_parameters\"):\n",
    "            layer.reset_parameters()\n",
    "        for child_layer in layer.modules():\n",
    "            if layer != child_layer:\n",
    "                self.reset_layer_recursively(child_layer)\n",
    "\n",
    "    def save_results(self, test_loader):\n",
    "        \"\"\"This script computes the SDR and SI-SNR metrics and saves\n",
    "        them into a csv file\"\"\"\n",
    "\n",
    "        # This package is required for SDR computation\n",
    "        from mir_eval.separation import bss_eval_sources\n",
    "\n",
    "        # Create folders where to store audio\n",
    "        save_file = os.path.join(self.hparams.output_folder, \"test_results.csv\")\n",
    "\n",
    "        # Variable init\n",
    "        all_sdrs = []\n",
    "        all_sdrs_i = []\n",
    "        all_sisnrs = []\n",
    "        all_sisnrs_i = []\n",
    "        csv_columns = [\"snt_id\", \"sdr\", \"sdr_i\", \"si-snr\", \"si-snr_i\"]\n",
    "\n",
    "\n",
    "        def is_silent(source, threshold=1e-6):\n",
    "            return np.max(np.abs(source[0])) < threshold or np.max(np.abs(source[1])) < threshold\n",
    "\n",
    "        with open(save_file, \"w\", newline=\"\", encoding=\"utf-8\") as results_csv:\n",
    "            writer = csv.DictWriter(results_csv, fieldnames=csv_columns)\n",
    "            writer.writeheader()\n",
    "            skip_cnt = 0\n",
    "\n",
    "            # Loop over all test sentence\n",
    "            with tqdm(test_loader, dynamic_ncols=True) as t:\n",
    "                for i, batch in enumerate(t):\n",
    "                    # Apply Separation\n",
    "                    mixture, mix_len = batch.mix_sig\n",
    "                    snt_id = batch.track_id\n",
    "                    targets = [batch.voc_sig, batch.inst_sig]\n",
    "                   \n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        predictions, targets = self.compute_forward(\n",
    "                            batch.mix_sig, targets, sb.Stage.TEST\n",
    "                        )\n",
    "\n",
    "                    # Compute SI-SNR\n",
    "                    sisnr = self.compute_objectives(predictions, targets)\n",
    "\n",
    "                    # Compute SI-SNR improvement\n",
    "                    mixture_signal = torch.stack(\n",
    "                        [mixture] * self.hparams.num_sources, dim=-1\n",
    "                    )\n",
    "                    mixture_signal = mixture_signal.to(targets.device)\n",
    "                    sisnr_baseline = self.compute_objectives(\n",
    "                        mixture_signal, targets\n",
    "                    )\n",
    "                    sisnr_i = sisnr - sisnr_baseline\n",
    "                    \n",
    "     \n",
    "                    if not is_silent(targets[0].t().cpu().numpy()) and not is_silent(predictions[0].t().detach().cpu().numpy()) and not is_silent(mixture_signal[0].t().detach().cpu().numpy()):\n",
    "                        \n",
    "                    \n",
    "                        sdr, _, _, _ = bss_eval_sources(\n",
    "                            targets[0].t().cpu().numpy(),\n",
    "                            predictions[0].t().detach().cpu().numpy(),\n",
    "                            compute_permutation=False\n",
    "                        )\n",
    "    \n",
    "                        sdr_baseline, _, _, _ = bss_eval_sources(\n",
    "                            targets[0].t().cpu().numpy(),\n",
    "                            mixture_signal[0].t().detach().cpu().numpy(),\n",
    "                            compute_permutation=False\n",
    "                        )\n",
    "    \n",
    "                        sdr_i = sdr.mean() - sdr_baseline.mean()\n",
    "    \n",
    "                        # Saving on a csv file\n",
    "                        row = {\n",
    "                            \"snt_id\": snt_id[0],\n",
    "                            \"sdr\": sdr.mean(),\n",
    "                            \"sdr_i\": sdr_i,\n",
    "                            \"si-snr\": -sisnr.item(),\n",
    "                            \"si-snr_i\": -sisnr_i.item(),\n",
    "                        }\n",
    "                        writer.writerow(row)\n",
    "    \n",
    "                        # Metric Accumulation\n",
    "                        all_sdrs.append(sdr.mean())\n",
    "                        all_sdrs_i.append(sdr_i.mean())\n",
    "                        all_sisnrs.append(-sisnr.item())\n",
    "                        all_sisnrs_i.append(-sisnr_i.item())\n",
    "                    else:\n",
    "                        skip_cnt += 1\n",
    "                        print(f\"Warning: skipping silent target, this has happened {skip_cnt} times\")\n",
    "            row = {\n",
    "                \"snt_id\": \"avg\",\n",
    "                \"sdr\": np.array(all_sdrs).mean(),\n",
    "                \"sdr_i\": np.array(all_sdrs_i).mean(),\n",
    "                \"si-snr\": np.array(all_sisnrs).mean(),\n",
    "                \"si-snr_i\": np.array(all_sisnrs_i).mean(),\n",
    "            }\n",
    "            writer.writerow(row)\n",
    "\n",
    "        logger.info(\"Mean SISNR is {}\".format(np.array(all_sisnrs).mean()))\n",
    "        logger.info(\"Mean SISNRi is {}\".format(np.array(all_sisnrs_i).mean()))\n",
    "        logger.info(\"Mean SDR is {}\".format(np.array(all_sdrs).mean()))\n",
    "        logger.info(\"Mean SDRi is {}\".format(np.array(all_sdrs_i).mean()))\n",
    "        if(self.hparams.result_file_path != \"\"):\n",
    "            with open(self.hparams.result_file_path, \"a\", newline=\"\", encoding=\"utf-8\") as metrics_csv:\n",
    "                writer = csv.DictWriter(metrics_csv, fieldnames=[\"model_name\", \"n_epochs\", \"learning_rate\", \"chunk_size\", \"sample_rate\", \"sdr\", \"sdr_i\", \"si-snr\", \"si-snr_i\"])\n",
    "                row = {\n",
    "                        \"model_name\": self.hparams.experiment_name,\n",
    "                        \"learning_rate\": self.hparams.lr,\n",
    "                        \"n_epochs\": self.hparams.N_epochs,\n",
    "                        \"chunk_size\":self.hparams.chunk_size,\n",
    "                        \"sample_rate\":self.hparams.sample_rate,\n",
    "                        \"sdr\": np.array(all_sdrs).mean(),\n",
    "                        \"sdr_i\": np.array(all_sdrs_i).mean(),\n",
    "                        \"si-snr\": np.array(all_sisnrs).mean(),\n",
    "                        \"si-snr_i\": np.array(all_sisnrs_i).mean(),\n",
    "                    }\n",
    "                writer.writerow(row)\n",
    "\n",
    "    def save_audio(self, snt_id, mixture, targets, predictions):\n",
    "        \"saves the test audio (mixture, targets, and estimated sources) on disk\"\n",
    "\n",
    "        # Create output folder\n",
    "        save_path = os.path.join(self.hparams.save_folder, \"audio_results\")\n",
    "        if not os.path.exists(save_path):\n",
    "            os.mkdir(save_path)\n",
    "\n",
    "        for ns in range(self.hparams.num_sources):\n",
    "            # Estimated source\n",
    "            signal = predictions[0, :, ns]\n",
    "            signal = signal / signal.abs().max()\n",
    "            save_file = os.path.join(\n",
    "                save_path, \"item{}_source{}hat.wav\".format(snt_id, ns + 1)\n",
    "            )\n",
    "            torchaudio.save(\n",
    "                save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n",
    "            )\n",
    "\n",
    "            # Original source\n",
    "            signal = targets[0, :, ns]\n",
    "            signal = signal / signal.abs().max()\n",
    "            save_file = os.path.join(\n",
    "                save_path, \"item{}_source{}.wav\".format(snt_id, ns + 1)\n",
    "            )\n",
    "            torchaudio.save(\n",
    "                save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n",
    "            )\n",
    "\n",
    "        # Mixture\n",
    "        signal = mixture[0][0, :]\n",
    "        signal = signal / signal.abs().max()\n",
    "        save_file = os.path.join(save_path, \"item{}_mix.wav\".format(snt_id))\n",
    "        torchaudio.save(\n",
    "            save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load hyperparameters file with command-line overrides\n",
    "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
    "    with open(hparams_file, encoding=\"utf-8\") as fin:\n",
    "        hparams = load_hyperpyyaml(fin, overrides)\n",
    "\n",
    "    # Initialize ddp (useful only for multi-GPU DDP training)\n",
    "    sb.utils.distributed.ddp_init_group(run_opts)\n",
    "\n",
    "    # Logger info\n",
    "    logger = get_logger(__name__)\n",
    "\n",
    "    # Create experiment directory\n",
    "    sb.create_experiment_directory(\n",
    "        experiment_directory=hparams[\"output_folder\"],\n",
    "        hyperparams_to_save=hparams_file,\n",
    "        overrides=overrides,\n",
    "    )\n",
    "\n",
    "    # Update precision to bf16 if the device is CPU and precision is fp16\n",
    "    if run_opts.get(\"device\") == \"cpu\" and hparams.get(\"precision\") == \"fp16\":\n",
    "        hparams[\"precision\"] = \"bf16\"\n",
    "\n",
    "   \n",
    "\n",
    "    # Brain class initialization\n",
    "    separator = Separation(\n",
    "        modules=hparams[\"modules\"],\n",
    "        opt_class=hparams[\"optimizer\"],\n",
    "        hparams=hparams,\n",
    "        run_opts=run_opts,\n",
    "        checkpointer=hparams[\"checkpointer\"],\n",
    "    )\n",
    " \n",
    "    # Training\n",
    "        \n",
    "    # Usage with SpeechBrain\n",
    "    train_data = MusDBDataset(hparams[\"db_path\"], subset=\"train\", split=\"train\", target_sr=hparams[\"sample_rate\"], chunk_size=hparams[\"chunk_size\"])\n",
    "    valid_data = MusDBDataset(hparams[\"db_path\"], subset=\"train\", split=\"valid\", target_sr=hparams[\"sample_rate\"], chunk_size=hparams[\"chunk_size\"])\n",
    "    test_data = MusDBDataset(hparams[\"db_path\"], subset=\"test\", target_sr=hparams[\"sample_rate\"], chunk_size=hparams[\"chunk_size\"])\n",
    "    \n",
    "\n",
    "    # Create DataLoader\n",
    "    train_loader = sb.dataio.dataloader.make_dataloader(\n",
    "        train_data,\n",
    "        batch_size=hparams[\"batch_size\"],\n",
    "        collate_fn=sb.dataio.batch.PaddedBatch  # Handles variable lengths\n",
    "    )\n",
    "\n",
    "    valid_loader = sb.dataio.dataloader.make_dataloader(\n",
    "        valid_data,\n",
    "        batch_size=hparams[\"batch_size\"],\n",
    "        collate_fn=sb.dataio.batch.PaddedBatch  # Handles variable lengths\n",
    "    )\n",
    "\n",
    "    test_loader = sb.dataio.dataloader.make_dataloader(\n",
    "        test_data,\n",
    "        batch_size=hparams[\"batch_size\"],\n",
    "        collate_fn=sb.dataio.batch.PaddedBatch  # Handles variable lengths\n",
    "    )\n",
    "    # print(\"STARTING FIT\")\n",
    "    separator.fit(\n",
    "        separator.hparams.epoch_counter,\n",
    "        train_loader,\n",
    "        valid_loader,\n",
    "        train_loader_kwargs=hparams[\"dataloader_opts\"],\n",
    "        valid_loader_kwargs=hparams[\"dataloader_opts\"],\n",
    "    )\n",
    "\n",
    "    # # Eval\n",
    "    separator.evaluate(test_loader, min_key=\"si-snr\")\n",
    "    separator.save_results(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T17:51:05.473442Z",
     "iopub.status.busy": "2025-04-18T17:51:05.472769Z",
     "iopub.status.idle": "2025-04-18T18:02:28.217708Z",
     "shell.execute_reply": "2025-04-18T18:02:28.216666Z",
     "shell.execute_reply.started": "2025-04-18T17:51:05.473406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speechbrain.utils.quirks - Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]\n",
      "speechbrain.utils.quirks - Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
      "speechbrain.core - Beginning experiment!\n",
      "speechbrain.core - Experiment folder: /notebooks/results/sepformer/1234\n",
      "speechbrain.core - Info: precision arg from hparam file is used\n",
      "speechbrain.core - Info: noprogressbar arg from hparam file is used\n",
      "speechbrain.core - Gradscaler enabled: `True`\n",
      "speechbrain.core - Using training precision: `--precision=fp16`\n",
      "speechbrain.core - Using evaluation precision: `--eval_precision=fp32`\n",
      "speechbrain.core - Separation Model Statistics:\n",
      "* Total Number of Trainable Parameters: 6.7M\n",
      "* Total Number of Parameters: 6.7M\n",
      "* Trainable Parameters represent 100.0000% of the total size.\n",
      "speechbrain.utils.checkpoints - Loading a checkpoint from /notebooks/results/sepformer/1234/save/CKPT+2025-04-18+06-18-25+00\n",
      "speechbrain.utils.checkpoints - Loading a checkpoint from /notebooks/results/sepformer/1234/save/CKPT+2025-04-18+05-09-21+00\n",
      "100%|███████████████████████████████████████████| 44/44 [04:45<00:00,  6.49s/it]\n",
      "speechbrain.utils.train_logger - Epoch loaded: 24 - test si-snr: 5.41\n",
      "  0%|                                                    | 0/44 [00:00<?, ?it/s]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      "  2%|█                                           | 1/44 [00:09<06:41,  9.33s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      "  5%|██                                          | 2/44 [00:17<06:10,  8.82s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      "  7%|███                                         | 3/44 [00:24<05:31,  8.08s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      "  9%|████                                        | 4/44 [00:34<05:53,  8.83s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 11%|█████                                       | 5/44 [00:42<05:25,  8.34s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 14%|██████                                      | 6/44 [00:49<04:59,  7.87s/it]Warning: skipping silent target, this has happened 1 times\n",
      " 16%|███████                                     | 7/44 [00:56<04:39,  7.56s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 18%|████████                                    | 8/44 [01:07<05:07,  8.56s/it]Warning: skipping silent target, this has happened 2 times\n",
      " 20%|█████████                                   | 9/44 [01:13<04:41,  8.04s/it]Warning: skipping silent target, this has happened 3 times\n",
      " 23%|█████████▊                                 | 10/44 [01:19<04:02,  7.15s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 25%|██████████▊                                | 11/44 [01:27<04:08,  7.53s/it]Warning: skipping silent target, this has happened 4 times\n",
      " 27%|███████████▋                               | 12/44 [01:34<03:54,  7.33s/it]Warning: skipping silent target, this has happened 5 times\n",
      " 30%|████████████▋                              | 13/44 [01:47<04:40,  9.05s/it]Warning: skipping silent target, this has happened 6 times\n",
      " 32%|█████████████▋                             | 14/44 [01:55<04:20,  8.70s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 34%|██████████████▋                            | 15/44 [02:00<03:41,  7.65s/it]Warning: skipping silent target, this has happened 7 times\n",
      " 36%|███████████████▋                           | 16/44 [02:07<03:30,  7.53s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 39%|████████████████▌                          | 17/44 [02:14<03:18,  7.34s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 41%|█████████████████▌                         | 18/44 [02:22<03:15,  7.50s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 43%|██████████████████▌                        | 19/44 [02:28<02:57,  7.11s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 45%|███████████████████▌                       | 20/44 [02:36<02:53,  7.21s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 48%|████████████████████▌                      | 21/44 [02:43<02:49,  7.39s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 50%|█████████████████████▌                     | 22/44 [02:58<03:27,  9.45s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 52%|██████████████████████▍                    | 23/44 [03:03<02:53,  8.27s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 55%|███████████████████████▍                   | 24/44 [03:07<02:17,  6.90s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 57%|████████████████████████▍                  | 25/44 [03:16<02:25,  7.66s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 59%|█████████████████████████▍                 | 26/44 [03:29<02:47,  9.28s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 61%|██████████████████████████▍                | 27/44 [03:42<02:54, 10.29s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 64%|███████████████████████████▎               | 28/44 [03:53<02:47, 10.48s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 66%|████████████████████████████▎              | 29/44 [04:02<02:31, 10.07s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 68%|█████████████████████████████▎             | 30/44 [04:11<02:17,  9.79s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 70%|██████████████████████████████▎            | 31/44 [04:18<01:54,  8.81s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 73%|███████████████████████████████▎           | 32/44 [04:33<02:07, 10.61s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 75%|████████████████████████████████▎          | 33/44 [04:41<01:50, 10.07s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 77%|█████████████████████████████████▏         | 34/44 [04:52<01:43, 10.34s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 80%|██████████████████████████████████▏        | 35/44 [05:06<01:41, 11.24s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 82%|███████████████████████████████████▏       | 36/44 [05:16<01:28, 11.07s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 84%|████████████████████████████████████▏      | 37/44 [05:24<01:09,  9.96s/it]Warning: skipping silent target, this has happened 8 times\n",
      " 86%|█████████████████████████████████████▏     | 38/44 [05:30<00:54,  9.01s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 89%|██████████████████████████████████████     | 39/44 [05:39<00:44,  8.95s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 91%|███████████████████████████████████████    | 40/44 [05:47<00:34,  8.56s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 93%|████████████████████████████████████████   | 41/44 [05:55<00:24,  8.28s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 95%|█████████████████████████████████████████  | 42/44 [06:02<00:15,  7.89s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 98%|██████████████████████████████████████████ | 43/44 [06:08<00:07,  7.48s/it]/notebooks/sepformer-train.py:266: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/sepformer-train.py:272: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      "100%|███████████████████████████████████████████| 44/44 [06:15<00:00,  8.54s/it]\n",
      "__main__ - Mean SISNR is 0.5171740754610963\n",
      "__main__ - Mean SISNRi is 2.182996593001816\n",
      "__main__ - Mean SDR is 3.326437843794955\n",
      "__main__ - Mean SDRi is 2.877482074918096\n"
     ]
    }
   ],
   "source": [
    "!python3 sepformer-train.py sepformer-hparams.yaml --data_folder=db_path --result_file_path={result_file_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demucs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T18:02:28.223592Z",
     "iopub.status.busy": "2025-04-18T18:02:28.223263Z",
     "iopub.status.idle": "2025-04-18T18:02:28.280340Z",
     "shell.execute_reply": "2025-04-18T18:02:28.279357Z",
     "shell.execute_reply.started": "2025-04-18T18:02:28.223560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting demucsModels.py\n"
     ]
    }
   ],
   "source": [
    "%%file demucsModels.py\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from speechbrain.nnet.CNN import Conv1d, ConvTranspose1d\n",
    "# from speechbrain.nnet.activations import GLU\n",
    "from speechbrain.lobes.models.beats import GLU_Linear\n",
    "from torch.nn import GLU\n",
    "from speechbrain.nnet.RNN import LSTM\n",
    "from speechbrain.nnet.linear import Linear\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = Conv1d(\n",
    "            out_channels=out_channels,\n",
    "            in_channels=in_channels,\n",
    "            kernel_size=8,\n",
    "            stride=4,\n",
    "            # default_padding=2,\n",
    "            skip_transpose=True,\n",
    "        )\n",
    "        self.glu_conv = Conv1d(\n",
    "            out_channels=2*out_channels,\n",
    "            in_channels=out_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            skip_transpose=True,\n",
    "        )\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.glu = GLU(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.size())\n",
    "        x = self.relu(self.conv(x))\n",
    "        # print(\"#########checking encoder\")\n",
    "        # print(x.size())\n",
    "        # print(self.glu_conv(x).size())\n",
    "        # print(\"#########encoder ended\")\n",
    "        x = self.glu(self.glu_conv(x))\n",
    "        # print(x.size())\n",
    "        return x\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.glu_conv = Conv1d(\n",
    "            out_channels=2*in_channels,\n",
    "            in_channels=in_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            skip_transpose=True,\n",
    "        )\n",
    "        self.conv_tr = ConvTranspose1d(\n",
    "            out_channels=out_channels,\n",
    "            in_channels=in_channels,  # After GLU split\n",
    "            kernel_size=8,\n",
    "            stride=4,\n",
    "            # padding=2,\n",
    "            # output_padding=2,\n",
    "            skip_transpose=True,\n",
    "        )\n",
    "        self.glu = GLU(dim=1)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x, skip=None):\n",
    "\n",
    "        if skip is not None:\n",
    "\n",
    "            # T changed after conv1d in encoder, fix it here\n",
    "            T_x = x.size(-1)\n",
    "            T_skip = skip.size(-1)\n",
    "\n",
    "            # # Case 1: Decoder output is longer\n",
    "            # if T_skip > T_x:\n",
    "            #     # Center-trim decoder output\n",
    "            #     start = (T_skip - T_x) // 2\n",
    "            #     skip = skip[..., start : start + T_x]\n",
    "\n",
    "            # # Case 2: Skip is longer\n",
    "            # elif T_skip < T_x:\n",
    "            #     # Center-pad decoder output\n",
    "            #     pad = T_x - T_skip\n",
    "            #     skip = nn.functional.pad(skip, (pad // 2, pad - pad // 2))\n",
    "\n",
    "            if T_skip > T_x:\n",
    "                # Trim from the end of 'skip' to match 'x'\n",
    "                skip = skip[..., :T_x]  # Keeps the first T_x samples\n",
    "\n",
    "            # Case 2: Skip is shorter than target (x)\n",
    "            elif T_skip < T_x:\n",
    "                # Pad zeros at the end of 'skip' to match 'x'\n",
    "                pad = T_x - T_skip\n",
    "                skip = nn.functional.pad(skip, (0, pad))\n",
    "\n",
    "\n",
    "            x = x + skip\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        x = self.glu(self.glu_conv(x))\n",
    "\n",
    "        x = self.relu(self.conv_tr(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SourceSeparator(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=2, num_sources=4):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            C_in: Input channels from last decoder (typically 8)\n",
    "            C_out: Output channels per source (2 for stereo)\n",
    "            num_sources: Number of sources to separate (e.g. 4 for vocals, drums, bass, other)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Final linear layer (no activation)\n",
    "        self.output_proj = Linear(\n",
    "            input_size=in_channels,\n",
    "            n_neurons=num_sources * out_channels,  # 4 sources * 2 channels = 8\n",
    "            bias=True\n",
    "        )\n",
    "        self.num_sources = num_sources\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input: [batch, C_in, time]\n",
    "        Output: [batch, num_sources, out_channels, time]\n",
    "        \"\"\"\n",
    "        # Permute to [batch, time, features]\n",
    "        # print(x.size())\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # Project to source waveforms\n",
    "        x = self.output_proj(x)  # [batch, time, num_sources*out_channels]\n",
    "        # print(x.size())\n",
    "\n",
    "        # Reshape to separated sources\n",
    "        # x = x.view(x.size(0), -1, self.num_sources, self.out_channels)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        # print(x.size())\n",
    "        # Return as [batch, sources, time]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T18:02:28.287702Z",
     "iopub.status.busy": "2025-04-18T18:02:28.287311Z",
     "iopub.status.idle": "2025-04-18T18:02:28.299517Z",
     "shell.execute_reply": "2025-04-18T18:02:28.298613Z",
     "shell.execute_reply.started": "2025-04-18T18:02:28.287667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting demucs-hparams.yaml\n"
     ]
    }
   ],
   "source": [
    "%%file demucs-hparams.yaml\n",
    "\n",
    "# ################################\n",
    "# Model: Demucs for source separation\n",
    "# https://hal.science/hal-02379796/document\n",
    "# Dataset : Musdb\n",
    "# ################################\n",
    "# Basic parameters\n",
    "seed: 1234\n",
    "__set_seed: !apply:speechbrain.utils.seed_everything [!ref <seed>]\n",
    "\n",
    "# Data params (unchanged from DPRNN)\n",
    "data_folder: !PLACEHOLDER\n",
    "result_file_path: !PLACEHOLDER\n",
    "\n",
    "experiment_name: demucs\n",
    "output_folder: !ref /notebooks/results/<experiment_name>/<seed>\n",
    "train_log: !ref <output_folder>/train_log.txt\n",
    "save_folder: !ref <output_folder>/save\n",
    "train_data: !ref <output_folder>/train.json\n",
    "valid_data: !ref <output_folder>/valid.json\n",
    "test_data: !ref <output_folder>/test.json\n",
    "skip_prep: False\n",
    "db_path: !ref /notebooks/data\n",
    "\n",
    "\n",
    "# Experiment params\n",
    "precision: fp32\n",
    "num_sources: 2\n",
    "\n",
    "instrumental_classification: False\n",
    "noprogressbar: False\n",
    "save_audio: True\n",
    "sample_rate: 8000\n",
    "n_audio_to_save: 10\n",
    "chunk_size: 30\n",
    "\n",
    "####################### Training Parameters ####################################\n",
    "\n",
    "N_epochs: 30\n",
    "batch_size: 1\n",
    "lr: 0.0005\n",
    "clip_grad_norm: 5\n",
    "loss_upper_lim: 999999\n",
    "limit_training_signal_len: False\n",
    "training_signal_len: 32000000\n",
    "\n",
    "\n",
    "# Data augmentation (unchanged)\n",
    "use_wavedrop: False\n",
    "use_rand_shift: False\n",
    "min_shift: -8000\n",
    "max_shift: 8000\n",
    "\n",
    "\n",
    "# Frequency/time drop (unchanged)\n",
    "drop_freq: !new:speechbrain.augment.time_domain.DropFreq\n",
    "    drop_freq_low: 0\n",
    "    drop_freq_high: 1\n",
    "    drop_freq_count_low: 1\n",
    "    drop_freq_count_high: 3\n",
    "    drop_freq_width: 0.05\n",
    "\n",
    "drop_chunk: !new:speechbrain.augment.time_domain.DropChunk\n",
    "    drop_length_low: 1000\n",
    "    drop_length_high: 2000\n",
    "    drop_count_low: 1\n",
    "    drop_count_high: 5\n",
    "\n",
    "threshold_byloss: True\n",
    "threshold: -30\n",
    "\n",
    "################ Demucs Specific Parameters #############################\n",
    "## for Demucs V3/4\n",
    "# # Fourier Transform Parameters\n",
    "# n_fft: 2048\n",
    "# hop_length: 512\n",
    "\n",
    "\n",
    "kernel_size: 16\n",
    "# kernel_stride: 8\n",
    "\n",
    "# Dataloader options (unchanged)\n",
    "dataloader_opts:\n",
    "    batch_size: !ref <batch_size>\n",
    "    num_workers: 3\n",
    "\n",
    "######################## Network Definition ####################################\n",
    "\n",
    "\n",
    "Encoder1: !new:demucsModels.EncoderBlock\n",
    "    in_channels: 1\n",
    "    # kernel_size: !ref <kernel_size>\n",
    "    out_channels: 64\n",
    "\n",
    "\n",
    "Encoder2: !new:demucsModels.EncoderBlock\n",
    "    in_channels: 64\n",
    "    out_channels: 128\n",
    "\n",
    "\n",
    "Encoder3: !new:demucsModels.EncoderBlock\n",
    "    in_channels: 128\n",
    "    out_channels: 256\n",
    "\n",
    "\n",
    "Encoder4: !new:demucsModels.EncoderBlock\n",
    "    in_channels: 256\n",
    "    out_channels: 512\n",
    "\n",
    "\n",
    "Encoder5: !new:demucsModels.EncoderBlock\n",
    "    in_channels: 512\n",
    "    out_channels: 1024\n",
    "\n",
    "\n",
    "Encoder6: !new:demucsModels.EncoderBlock\n",
    "    in_channels: 1024\n",
    "    out_channels: 2048\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Decoder6: !new:demucsModels.DecoderBlock\n",
    "    in_channels: 2048\n",
    "    out_channels: 1024\n",
    "\n",
    "\n",
    "Decoder5: !new:demucsModels.DecoderBlock\n",
    "    in_channels: 1024\n",
    "    out_channels: 512\n",
    "\n",
    "\n",
    "Decoder4: !new:demucsModels.DecoderBlock\n",
    "    in_channels: 512\n",
    "    out_channels: 256\n",
    "\n",
    "\n",
    "Decoder3: !new:demucsModels.DecoderBlock\n",
    "    in_channels: 256\n",
    "    out_channels: 128\n",
    "\n",
    "\n",
    "Decoder2: !new:demucsModels.DecoderBlock\n",
    "    in_channels: 128\n",
    "    out_channels: 64\n",
    "\n",
    "\n",
    "Decoder1: !new:demucsModels.DecoderBlock\n",
    "    in_channels: 64\n",
    "    out_channels: 4\n",
    "\n",
    "\n",
    "Linear: !new:speechbrain.nnet.linear.Linear\n",
    "    input_size: 4096\n",
    "    bias: False\n",
    "    n_neurons: 2048\n",
    "\n",
    "BiLSTM: !new:speechbrain.nnet.RNN.LSTM\n",
    "    hidden_size: 2048\n",
    "    input_size: 2048\n",
    "    num_layers: 2\n",
    "    bidirectional: True\n",
    "    # batch_first: True\n",
    "\n",
    "LinearSeparator: !new:demucsModels.SourceSeparator\n",
    "    in_channels: 4\n",
    "    out_channels: 1\n",
    "    num_sources: !ref <num_sources>\n",
    "\n",
    "\n",
    "######################## Remaining Config ######################################\n",
    "optimizer: !name:torch.optim.Adam\n",
    "    lr: !ref <lr>\n",
    "    weight_decay: 0\n",
    "\n",
    "# loss: !name:speechbrain.nnet.losses.mse_loss\n",
    "loss: !name:speechbrain.nnet.losses.get_si_snr_with_pitwrapper\n",
    "# loss: !name:speechbrain.nnet.losses.l1_loss\n",
    "\n",
    "\n",
    "lr_scheduler: !new:speechbrain.nnet.schedulers.ReduceLROnPlateau\n",
    "    factor: 0.5\n",
    "    patience: 2\n",
    "    dont_halve_until_epoch: 50\n",
    "\n",
    "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
    "    limit: !ref <N_epochs>\n",
    "\n",
    "modules:\n",
    "    encoder1: !ref <Encoder1>\n",
    "    encoder2: !ref <Encoder2>\n",
    "    encoder3: !ref <Encoder3>\n",
    "    encoder4: !ref <Encoder4>\n",
    "    encoder5: !ref <Encoder5>\n",
    "    encoder6: !ref <Encoder6>\n",
    "    lstm: !ref <BiLSTM>\n",
    "    linear: !ref <Linear>\n",
    "    decoder6: !ref <Decoder6>\n",
    "    decoder5: !ref <Decoder5>\n",
    "    decoder4: !ref <Decoder4>\n",
    "    decoder3: !ref <Decoder3>\n",
    "    decoder2: !ref <Decoder2>\n",
    "    decoder1: !ref <Decoder1>\n",
    "    linearSeparator: !ref <LinearSeparator>\n",
    "\n",
    "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
    "    checkpoints_dir: !ref <save_folder>\n",
    "    recoverables:\n",
    "        encoder1: !ref <Encoder1>\n",
    "        encoder2: !ref <Encoder2>\n",
    "        encoder3: !ref <Encoder3>\n",
    "        encoder4: !ref <Encoder4>\n",
    "        encoder5: !ref <Encoder5>\n",
    "        encoder6: !ref <Encoder6>\n",
    "        lstm: !ref <BiLSTM>\n",
    "        linear: !ref <Linear>\n",
    "        decoder6: !ref <Decoder6>\n",
    "        decoder5: !ref <Decoder5>\n",
    "        decoder4: !ref <Decoder4>\n",
    "        decoder3: !ref <Decoder3>\n",
    "        decoder2: !ref <Decoder2>\n",
    "        decoder1: !ref <Decoder1>\n",
    "        linearSeparator: !ref <LinearSeparator>\n",
    "        counter: !ref <epoch_counter>\n",
    "\n",
    "\n",
    "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
    "    save_file: !ref <train_log>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T18:02:28.301432Z",
     "iopub.status.busy": "2025-04-18T18:02:28.301124Z",
     "iopub.status.idle": "2025-04-18T18:02:28.320772Z",
     "shell.execute_reply": "2025-04-18T18:02:28.319990Z",
     "shell.execute_reply.started": "2025-04-18T18:02:28.301400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting demucs-train.py\n"
     ]
    }
   ],
   "source": [
    "%%file demucs-train.py\n",
    "#!/usr/bin/env/python3\n",
    "\"\"\"Recipe for training a neural speech separation system on the wsjmix\n",
    "dataset. The system employs an encoder, a decoder, and a masking network.\n",
    "\n",
    "To run this recipe, do the following:\n",
    "> python train.py hparams/sepformer.yaml\n",
    "> python train.py hparams/dualpath_rnn.yaml\n",
    "> python train.py hparams/convtasnet.yaml\n",
    "\n",
    "The experiment file is flexible enough to support different neural\n",
    "networks. By properly changing the parameter files, you can try\n",
    "different architectures. The script supports both wsj2mix and\n",
    "wsj3mix.\n",
    "\n",
    "\n",
    "Authors\n",
    " * Cem Subakan 2020\n",
    " * Mirco Ravanelli 2020\n",
    " * Samuele Cornell 2020\n",
    " * Mirko Bronzi 2020\n",
    " * Jianyuan Zhong 2020\n",
    "\"\"\"\n",
    "## CHECKPOINT\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "import speechbrain as sb\n",
    "import speechbrain.nnet.schedulers as schedulers\n",
    "from speechbrain.utils.distributed import run_on_main\n",
    "from speechbrain.utils.logger import get_logger\n",
    "from speechbrain.nnet.CNN import Conv1d, ConvTranspose1d\n",
    "# from speechbrain.nnet.activations import GLU\n",
    "from speechbrain.lobes.models.beats import GLU_Linear\n",
    "from torch.nn import GLU\n",
    "from speechbrain.nnet.RNN import LSTM\n",
    "from speechbrain.nnet.linear import Linear\n",
    "from demucsModels import EncoderBlock, DecoderBlock\n",
    "from speechbrain.nnet.losses import get_si_snr_with_pitwrapper\n",
    "from dataset import MusDBDataset\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import musdb\n",
    "np.float_ = np.float64\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define training procedure\n",
    "class DemucsSeparation(sb.Brain):\n",
    "    # def on_fit_start(self):\n",
    "\n",
    "\n",
    "    def compute_forward(self, mix, targets, stage, noise=None):\n",
    "        \"\"\"Forward computations from the mixture to the separated signals.\"\"\"\n",
    "\n",
    "        # Unpack lists and put tensors in the right device\n",
    "        mix, mix_lens = mix\n",
    "        mix, mix_lens = mix.to(self.device), mix_lens.to(self.device)\n",
    "\n",
    "        # Convert targets to tensor\n",
    "        # print([targets[i][0].size() for i in range(self.hparams.num_sources)])\n",
    "        targets = torch.cat(\n",
    "            [targets[i][0].unsqueeze(-1) for i in range(self.hparams.num_sources)],\n",
    "            dim=-1,\n",
    "        ).to(self.device)\n",
    "        \n",
    "        mix=mix.unsqueeze(1)\n",
    "        targets=targets.permute(0,2,1)\n",
    "       \n",
    "\n",
    "        mix_enc_1 = self.modules.encoder1(mix)\n",
    "        mix_enc_2 = self.modules.encoder2(mix_enc_1)\n",
    "        mix_enc_3 = self.modules.encoder3(mix_enc_2)\n",
    "        mix_enc_4 = self.modules.encoder4(mix_enc_3)\n",
    "        mix_enc_5 = self.modules.encoder5(mix_enc_4)\n",
    "        mix_enc_6 = self.modules.encoder6(mix_enc_5)\n",
    "\n",
    "        lstm_in = mix_enc_6.permute(0,2,1)\n",
    "        lstm_out, _ = self.modules.lstm(lstm_in) # outputs both -- outputs as well as hidden states -- we dont need hidden states\n",
    "        lin_out = self.modules.linear(lstm_out)\n",
    "        lin_out = lin_out.permute(0,2,1)\n",
    "\n",
    "        mix_dec_6 = self.modules.decoder6(lin_out, skip=mix_enc_6)\n",
    "        mix_dec_5 = self.modules.decoder5(mix_dec_6, skip=mix_enc_5)\n",
    "        mix_dec_4 = self.modules.decoder4(mix_dec_5, skip=mix_enc_4)\n",
    "        mix_dec_3 = self.modules.decoder3(mix_dec_4, skip=mix_enc_3)\n",
    "        mix_dec_2 = self.modules.decoder2(mix_dec_3, skip=mix_enc_2)\n",
    "        mix_dec_1 = self.modules.decoder1(mix_dec_2, skip=mix_enc_1)\n",
    "\n",
    "        mix_out = self.modules.linearSeparator(mix_dec_1)\n",
    "        est_source = mix_out\n",
    "\n",
    "\n",
    "\n",
    "        # T changed after conv1d in encoder, fix it here\n",
    "        T_origin = targets.size(2)\n",
    "        T_est = est_source.size(2)\n",
    "\n",
    "        if T_origin > T_est:\n",
    "            est_source = F.pad(est_source, (0, 0, T_origin - T_est))\n",
    "        else:\n",
    "            est_source = est_source[:, : , :T_origin]\n",
    "\n",
    "        return est_source, targets\n",
    "\n",
    "    def compute_objectives(self, predictions, targets):\n",
    "        \"\"\"Computes the sinr loss\"\"\"\n",
    "        # print(\"comp obj\")\n",
    "        targets = targets.permute(0,2,1)\n",
    "        predictions = predictions.permute(0,2,1)\n",
    "        return self.hparams.loss(targets, predictions) # for pitwrapper\n",
    "## CHECKPOINT\n",
    "    def fit_batch(self, batch):\n",
    "        \"\"\"Trains one batch\"\"\"\n",
    "\n",
    "        # Unpacking batch list\n",
    "        mixture = batch.mix_sig\n",
    "        targets = [batch.voc_sig, batch.inst_sig]\n",
    "\n",
    "        with self.training_ctx:\n",
    "            predictions, targets = self.compute_forward(\n",
    "                mixture, targets, sb.Stage.TRAIN\n",
    "            )\n",
    "\n",
    "            loss = self.compute_objectives(predictions, targets)\n",
    "\n",
    "            # hard threshold the easy dataitems\n",
    "            if self.hparams.threshold_byloss:\n",
    "                th = self.hparams.threshold\n",
    "                loss = loss[loss > th]\n",
    "                if loss.nelement() > 0:\n",
    "                    loss = loss.mean()\n",
    "            else:\n",
    "                loss = loss.mean()\n",
    "\n",
    "        if loss.nelement() > 0 and loss < self.hparams.loss_upper_lim:\n",
    "            self.scaler.scale(loss).backward()\n",
    "            if self.hparams.clip_grad_norm >= 0:\n",
    "                self.scaler.unscale_(self.optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    self.modules.parameters(),\n",
    "                    self.hparams.clip_grad_norm,\n",
    "                )\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "        else:\n",
    "            self.nonfinite_count += 1\n",
    "            logger.info(\n",
    "                \"infinite loss or empty loss! it happened {} times so far - skipping this batch\".format(\n",
    "                    self.nonfinite_count\n",
    "                )\n",
    "            )\n",
    "            loss.data = torch.tensor(0.0).to(self.device)\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        return loss.detach().cpu()\n",
    "\n",
    "    def evaluate_batch(self, batch, stage):\n",
    "        \"\"\"Computations needed for validation/test batches\"\"\"\n",
    "        snt_id = batch.track_id\n",
    "        mixture = batch.mix_sig\n",
    "        targets = [batch.voc_sig, batch.inst_sig]\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictions, targets = self.compute_forward(mixture, targets, stage)\n",
    "            loss = self.compute_objectives(predictions, targets)\n",
    "\n",
    "        # Manage audio file saving\n",
    "        if stage == sb.Stage.TEST and self.hparams.save_audio:\n",
    "            if hasattr(self.hparams, \"n_audio_to_save\"):\n",
    "                if self.hparams.n_audio_to_save > 0:\n",
    "                    self.save_audio(snt_id, mixture, targets, predictions)\n",
    "                    self.hparams.n_audio_to_save += -1\n",
    "            else:\n",
    "                self.save_audio(snt_id, mixture, targets, predictions)\n",
    "\n",
    "        return loss.mean().detach()\n",
    "\n",
    "    def on_stage_end(self, stage, stage_loss, epoch):\n",
    "        \"\"\"Gets called at the end of a epoch.\"\"\"\n",
    "        # Compute/store important stats\n",
    "        stage_stats = {\"si-snr\": stage_loss}\n",
    "        if stage == sb.Stage.TRAIN:\n",
    "            self.train_stats = stage_stats\n",
    "\n",
    "        # Perform end-of-iteration things, like annealing, logging, etc.\n",
    "        if stage == sb.Stage.VALID:\n",
    "            # Learning rate annealing\n",
    "            if isinstance(\n",
    "                self.hparams.lr_scheduler, schedulers.ReduceLROnPlateau\n",
    "            ):\n",
    "                current_lr, next_lr = self.hparams.lr_scheduler(\n",
    "                    [self.optimizer], epoch, stage_loss\n",
    "                )\n",
    "                schedulers.update_learning_rate(self.optimizer, next_lr)\n",
    "            else:\n",
    "                # if we do not use the reducelronplateau, we do not change the lr\n",
    "                current_lr = self.hparams.optimizer.optim.param_groups[0][\"lr\"]\n",
    "\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                stats_meta={\"epoch\": epoch, \"lr\": current_lr},\n",
    "                train_stats=self.train_stats,\n",
    "                valid_stats=stage_stats,\n",
    "            )\n",
    "            self.checkpointer.save_and_keep_only(\n",
    "                meta={\"si-snr\": stage_stats[\"si-snr\"]}, min_keys=[\"si-snr\"]\n",
    "            )\n",
    "        elif stage == sb.Stage.TEST:\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                stats_meta={\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
    "                test_stats=stage_stats,\n",
    "            )\n",
    "\n",
    "\n",
    "    def save_results(self, test_loader):\n",
    "        \"\"\"This script computes the SDR and SI-SNR metrics and saves\n",
    "        them into a csv file\"\"\"\n",
    "\n",
    "        # This package is required for SDR computation\n",
    "        from mir_eval.separation import bss_eval_sources\n",
    "\n",
    "        # Create folders where to store audio\n",
    "        save_file = os.path.join(self.hparams.output_folder, \"test_results.csv\")\n",
    "\n",
    "        # Variable init\n",
    "        all_sdrs = []\n",
    "        all_sdrs_i = []\n",
    "        all_sisnrs = []\n",
    "        all_sisnrs_i = []\n",
    "        csv_columns = [\"snt_id\", \"sdr\", \"sdr_i\", \"si-snr\", \"si-snr_i\"]\n",
    "\n",
    "        # test_loader = sb.dataio.dataloader.make_dataloader(\n",
    "        #     test_data, **self.hparams.dataloader_opts\n",
    "        # )\n",
    "\n",
    "        with open(save_file, \"w\", newline=\"\", encoding=\"utf-8\") as results_csv:\n",
    "            writer = csv.DictWriter(results_csv, fieldnames=csv_columns)\n",
    "            writer.writeheader()\n",
    "\n",
    "            # Loop over all test sentence\n",
    "            with tqdm(test_loader, dynamic_ncols=True) as t:\n",
    "                for i, batch in enumerate(t):\n",
    "                    # Apply Separation\n",
    "                    mixture, mix_len = batch.mix_sig\n",
    "                    snt_id = batch.track_id\n",
    "                    targets = [batch.voc_sig, batch.inst_sig]\n",
    "\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        predictions, targets = self.compute_forward(\n",
    "                            batch.mix_sig, targets, sb.Stage.TEST\n",
    "                        )\n",
    "\n",
    "                    # Compute SI-SNR\n",
    "                    predictions = predictions.permute(0,2,1)\n",
    "                    targets = targets.permute(0,2,1)\n",
    "                    print(predictions.size())\n",
    "                    print(targets.size())\n",
    "                    # sisnr = self.compute_objectives(predictions, targets)\n",
    "                    sisnr = get_si_snr_with_pitwrapper(predictions,targets)\n",
    "\n",
    "                    # Compute SI-SNR improvement\n",
    "                    mixture_signal = torch.stack(\n",
    "                        [mixture] * self.hparams.num_sources, dim=-1\n",
    "                    )\n",
    "                    print(\"---------------------\")\n",
    "                    # print(mixture.size())\n",
    "                    print(mixture_signal.size())\n",
    "\n",
    "                    mixture_signal = mixture_signal.to(targets.device)\n",
    "                    # sisnr_baseline = self.compute_objectives(\n",
    "                    #     mixture_signal, targets\n",
    "                    # )\n",
    "                    sisnr_baseline = get_si_snr_with_pitwrapper(mixture_signal, targets)\n",
    "                    sisnr_i = sisnr - sisnr_baseline\n",
    "\n",
    "                    # Compute SDR\n",
    "                    sdr, _, _, _ = bss_eval_sources(\n",
    "                        targets[0].mean(dim=1).t().cpu().numpy(),\n",
    "                        predictions[0].mean(dim=1).t().detach().cpu().numpy(),\n",
    "                    )\n",
    "\n",
    "                    sdr_baseline, _, _, _ = bss_eval_sources(\n",
    "                        targets[0].mean(dim=1).t().cpu().numpy(),\n",
    "                        mixture_signal[0].mean(dim=1).t().detach().cpu().numpy(),\n",
    "                    )\n",
    "\n",
    "                    sdr_i = sdr.mean() - sdr_baseline.mean()\n",
    "\n",
    "                    # Saving on a csv file\n",
    "                    row = {\n",
    "                        \"snt_id\": snt_id[0],\n",
    "                        \"sdr\": sdr.mean(),\n",
    "                        \"sdr_i\": sdr_i,\n",
    "                        \"si-snr\": -sisnr.item(),\n",
    "                        \"si-snr_i\": -sisnr_i.item(),\n",
    "                    }\n",
    "                    writer.writerow(row)\n",
    "\n",
    "                    # Metric Accumulation\n",
    "                    all_sdrs.append(sdr.mean())\n",
    "                    all_sdrs_i.append(sdr_i.mean())\n",
    "                    all_sisnrs.append(-sisnr.item())\n",
    "                    all_sisnrs_i.append(-sisnr_i.item())\n",
    "\n",
    "                row = {\n",
    "                    \"snt_id\": \"avg\",\n",
    "                    \"sdr\": np.array(all_sdrs).mean(),\n",
    "                    \"sdr_i\": np.array(all_sdrs_i).mean(),\n",
    "                    \"si-snr\": np.array(all_sisnrs).mean(),\n",
    "                    \"si-snr_i\": np.array(all_sisnrs_i).mean(),\n",
    "                }\n",
    "                writer.writerow(row)\n",
    "\n",
    "        logger.info(\"Mean SISNR is {}\".format(np.array(all_sisnrs).mean()))\n",
    "        logger.info(\"Mean SISNRi is {}\".format(np.array(all_sisnrs_i).mean()))\n",
    "        logger.info(\"Mean SDR is {}\".format(np.array(all_sdrs).mean()))\n",
    "        logger.info(\"Mean SDRi is {}\".format(np.array(all_sdrs_i).mean()))\n",
    "        if(self.hparams.result_file_path != \"\"):\n",
    "            with open(self.hparams.result_file_path, \"a\", newline=\"\", encoding=\"utf-8\") as metrics_csv:\n",
    "                writer = csv.DictWriter(metrics_csv, fieldnames=[\"model_name\", \"n_epochs\", \"learning_rate\", \"chunk_size\", \"sample_rate\", \"sdr\", \"sdr_i\", \"si-snr\", \"si-snr_i\"])\n",
    "                row = {\n",
    "                        \"model_name\": self.hparams.experiment_name,\n",
    "                        \"learning_rate\": self.hparams.lr,\n",
    "                        \"n_epochs\": self.hparams.N_epochs,\n",
    "                        \"chunk_size\":self.hparams.chunk_size,\n",
    "                        \"sample_rate\":self.hparams.sample_rate,\n",
    "                        \"sdr\": np.array(all_sdrs).mean(),\n",
    "                        \"sdr_i\": np.array(all_sdrs_i).mean(),\n",
    "                        \"si-snr\": np.array(all_sisnrs).mean(),\n",
    "                        \"si-snr_i\": np.array(all_sisnrs_i).mean(),\n",
    "                    }\n",
    "                writer.writerow(row)\n",
    "\n",
    "    def save_audio(self, snt_id, mixture, targets, predictions):\n",
    "        \"saves the test audio (mixture, targets, and estimated sources) on disk\"\n",
    "\n",
    "        # Create output folder\n",
    "\n",
    "        save_path = os.path.join(self.hparams.save_folder, \"audio_results\")\n",
    "        if not os.path.exists(save_path):\n",
    "            os.mkdir(save_path)\n",
    "        targets = targets.permute(0,2,1)\n",
    "        predictions = predictions.permute(0,2,1)\n",
    "        print(snt_id)\n",
    "        for ns in range(self.hparams.num_sources):\n",
    "            # Estimated source\\\n",
    "            \n",
    "            print(\"------- in here --------------\")\n",
    "            print(predictions.size())\n",
    "            signal = predictions[0, :, ns]\n",
    "            print(signal.size())\n",
    "            signal = signal / signal.abs().max()\n",
    "            # signal = signal / signal.abs().max(dim=1, keepdim=True)[0]\n",
    "            print(signal.size())\n",
    "            save_file = os.path.join(\n",
    "                save_path, \"item{}_source{}hat.wav\".format(snt_id, ns + 1)\n",
    "            )\n",
    "            torchaudio.save(\n",
    "                save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate, channels_first=True\n",
    "            )\n",
    "\n",
    "            # Original source\n",
    "            signal = targets[0, :, ns]\n",
    "            signal = signal / signal.abs().max()\n",
    "            save_file = os.path.join(\n",
    "                save_path, \"item{}_source{}.wav\".format(snt_id, ns + 1)\n",
    "            )\n",
    "            torchaudio.save(\n",
    "                save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate, channels_first=True\n",
    "            )\n",
    "\n",
    "        # Mixture\n",
    "        signal = mixture[0][0, :]\n",
    "        signal = signal / signal.abs().max()\n",
    "        print(\"here now\")\n",
    "        print(signal.size())\n",
    "        save_file = os.path.join(save_path, \"item{}_mix.wav\".format(snt_id))\n",
    "        torchaudio.save(\n",
    "            save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load hyperparameters file with command-line overrides\n",
    "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
    "    with open(hparams_file, encoding=\"utf-8\") as fin:\n",
    "        hparams = load_hyperpyyaml(fin, overrides)\n",
    "\n",
    "    # Initialize ddp (useful only for multi-GPU DDP training)\n",
    "    sb.utils.distributed.ddp_init_group(run_opts)\n",
    "\n",
    "    # Logger info\n",
    "    logger = get_logger(__name__)\n",
    "\n",
    "    # Create experiment directory\n",
    "    sb.create_experiment_directory(\n",
    "        experiment_directory=hparams[\"output_folder\"],\n",
    "        hyperparams_to_save=hparams_file,\n",
    "        overrides=overrides,\n",
    "    )\n",
    "\n",
    "    # Update precision to bf16 if the device is CPU and precision is fp16\n",
    "    if run_opts.get(\"device\") == \"cpu\" and hparams.get(\"precision\") == \"fp16\":\n",
    "        hparams[\"precision\"] = \"bf16\"\n",
    "\n",
    "\n",
    "\n",
    "        # Usage with SpeechBrain\n",
    "    train_data = MusDBDataset(hparams[\"db_path\"], subset=\"train\", split=\"train\", target_sr=hparams[\"sample_rate\"], chunk_size=hparams[\"chunk_size\"])\n",
    "    valid_data = MusDBDataset(hparams[\"db_path\"], subset=\"train\", split=\"valid\", target_sr=hparams[\"sample_rate\"], chunk_size=hparams[\"chunk_size\"])\n",
    "    test_data = MusDBDataset(hparams[\"db_path\"], subset=\"test\", target_sr=hparams[\"sample_rate\"], chunk_size=hparams[\"chunk_size\"])\n",
    "\n",
    "\n",
    "    # Create DataLoader\n",
    "    train_loader = sb.dataio.dataloader.make_dataloader(\n",
    "        train_data,\n",
    "        batch_size=hparams[\"batch_size\"],\n",
    "        collate_fn=sb.dataio.batch.PaddedBatch  # Handles variable lengths\n",
    "    )\n",
    "\n",
    "    valid_loader = sb.dataio.dataloader.make_dataloader(\n",
    "        valid_data,\n",
    "        batch_size=hparams[\"batch_size\"],\n",
    "        collate_fn=sb.dataio.batch.PaddedBatch  # Handles variable lengths\n",
    "    )\n",
    "\n",
    "    test_loader = sb.dataio.dataloader.make_dataloader(\n",
    "        test_data,\n",
    "        batch_size=hparams[\"batch_size\"],\n",
    "        collate_fn=sb.dataio.batch.PaddedBatch  # Handles variable lengths\n",
    "    )\n",
    "\n",
    "\n",
    "    # Brain class initialization\n",
    "    separator = DemucsSeparation(\n",
    "        modules=hparams[\"modules\"],\n",
    "        opt_class=hparams[\"optimizer\"],\n",
    "        hparams=hparams,\n",
    "        run_opts=run_opts,\n",
    "        checkpointer=hparams[\"checkpointer\"],\n",
    "    )\n",
    "\n",
    "\n",
    "    # Training\n",
    "    separator.fit(\n",
    "        separator.hparams.epoch_counter,\n",
    "        train_loader,\n",
    "        valid_loader,\n",
    "        train_loader_kwargs=hparams[\"dataloader_opts\"],\n",
    "        valid_loader_kwargs=hparams[\"dataloader_opts\"],\n",
    "    )\n",
    "\n",
    "    # Eval\n",
    "    separator.evaluate(test_loader, min_key=\"si-snr\")\n",
    "    separator.save_results(test_loader)\n",
    "    ## CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T18:02:28.322160Z",
     "iopub.status.busy": "2025-04-18T18:02:28.321889Z",
     "iopub.status.idle": "2025-04-18T18:52:14.179482Z",
     "shell.execute_reply": "2025-04-18T18:52:14.178706Z",
     "shell.execute_reply.started": "2025-04-18T18:02:28.322131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speechbrain.utils.quirks - Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
      "speechbrain.utils.quirks - Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
      "speechbrain.core - Beginning experiment!\n",
      "speechbrain.core - Experiment folder: /notebooks/results/demucs/1234\n",
      "speechbrain.core - Info: precision arg from hparam file is used\n",
      "speechbrain.core - Info: noprogressbar arg from hparam file is used\n",
      "speechbrain.core - Gradscaler enabled: `False`\n",
      "speechbrain.core - Using training precision: `--precision=fp32`\n",
      "speechbrain.core - Using evaluation precision: `--eval_precision=fp32`\n",
      "speechbrain.core - DemucsSeparation Model Statistics:\n",
      "* Total Number of Trainable Parameters: 243.3M\n",
      "* Total Number of Parameters: 243.3M\n",
      "* Trainable Parameters represent 100.0000% of the total size.\n",
      "speechbrain.utils.checkpoints - Loading a checkpoint from /notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-38-53+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 27\n",
      "100%|██████████████████████████| 81/81 [08:46<00:00,  6.50s/it, train_loss=3.06]\n",
      "100%|███████████████████████████████████████████| 13/13 [01:33<00:00,  7.19s/it]\n",
      "speechbrain.utils.train_logger - epoch: 27, lr: 5.00e-04 - train si-snr: 3.06 - valid si-snr: 5.29\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /notebooks/results/demucs/1234/save/CKPT+2025-04-18+18-13-22+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in /notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-38-53+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 28\n",
      "100%|██████████████████████████| 81/81 [08:04<00:00,  5.98s/it, train_loss=3.03]\n",
      "100%|███████████████████████████████████████████| 13/13 [01:27<00:00,  6.70s/it]\n",
      "speechbrain.utils.train_logger - epoch: 28, lr: 5.00e-04 - train si-snr: 3.03 - valid si-snr: 5.21\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /notebooks/results/demucs/1234/save/CKPT+2025-04-18+18-23-00+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in /notebooks/results/demucs/1234/save/CKPT+2025-04-18+18-13-22+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 29\n",
      "100%|██████████████████████████| 81/81 [08:04<00:00,  5.98s/it, train_loss=2.95]\n",
      "100%|███████████████████████████████████████████| 13/13 [01:26<00:00,  6.66s/it]\n",
      "speechbrain.utils.train_logger - epoch: 29, lr: 5.00e-04 - train si-snr: 2.95 - valid si-snr: 5.04\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /notebooks/results/demucs/1234/save/CKPT+2025-04-18+18-32-36+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in /notebooks/results/demucs/1234/save/CKPT+2025-04-18+18-23-00+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 30\n",
      "100%|██████████████████████████| 81/81 [08:05<00:00,  5.99s/it, train_loss=2.83]\n",
      "100%|███████████████████████████████████████████| 13/13 [01:25<00:00,  6.61s/it]\n",
      "speechbrain.utils.train_logger - epoch: 30, lr: 5.00e-04 - train si-snr: 2.83 - valid si-snr: 5.20\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /notebooks/results/demucs/1234/save/CKPT+2025-04-18+18-42-14+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in /notebooks/results/demucs/1234/save/CKPT+2025-04-18+18-32-36+00\n",
      "speechbrain.utils.checkpoints - Loading a checkpoint from /notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-18-57+00\n",
      "  0%|                                                    | 0/44 [00:00<?, ?it/s]['AM Contra - Heart Peripheral_0']\n",
      "------- in here --------------\n",
      "torch.Size([1, 240000, 2])\n",
      "torch.Size([240000])\n",
      "torch.Size([240000])\n",
      "------- in here --------------\n",
      "torch.Size([1, 240000, 2])\n",
      "torch.Size([240000])\n",
      "torch.Size([240000])\n",
      "here now\n",
      "torch.Size([240000])\n",
      "  2%|█                                           | 1/44 [00:05<04:08,  5.77s/it]['Al James - Schoolboy Facination_0']\n",
      "------- in here --------------\n",
      "torch.Size([1, 240000, 2])\n",
      "torch.Size([240000])\n",
      "torch.Size([240000])\n",
      "------- in here --------------\n",
      "torch.Size([1, 240000, 2])\n",
      "torch.Size([240000])\n",
      "torch.Size([240000])\n",
      "here now\n",
      "torch.Size([240000])\n",
      "  5%|██                                          | 2/44 [00:11<03:54,  5.58s/it]['Arise - Run Run Run_0']\n",
      "------- in here --------------\n",
      "torch.Size([1, 240000, 2])\n",
      "torch.Size([240000])\n",
      "torch.Size([240000])\n",
      "------- in here --------------\n",
      "torch.Size([1, 240000, 2])\n",
      "torch.Size([240000])\n",
      "torch.Size([240000])\n",
      "here now\n",
      "torch.Size([240000])\n",
      "  7%|███                                         | 3/44 [00:17<03:56,  5.77s/it]['BKS - Bulldozer_0']\n",
      "------- in here --------------\n",
      "torch.Size([1, 240000, 2])\n",
      "torch.Size([240000])\n",
      "torch.Size([240000])\n",
      "------- in here --------------\n",
      "torch.Size([1, 240000, 2])\n",
      "torch.Size([240000])\n",
      "torch.Size([240000])\n",
      "here now\n",
      "torch.Size([240000])\n",
      "  9%|████                                        | 4/44 [00:25<04:26,  6.66s/it]['BKS - Too Much_0']\n",
      "------- in here --------------\n",
      "torch.Size([1, 240000, 2])\n",
      "torch.Size([240000])\n",
      "torch.Size([240000])\n",
      "------- in here --------------\n",
      "torch.Size([1, 240000, 2])\n",
      "torch.Size([240000])\n",
      "torch.Size([240000])\n",
      "here now\n",
      "torch.Size([240000])\n",
      " 11%|█████                                       | 5/44 [00:30<04:06,  6.33s/it]['Bobby Nobody - Stitch Up_0']\n",
      "------- in here --------------\n",
      "torch.Size([1, 240000, 2])\n",
      "torch.Size([240000])\n",
      "torch.Size([240000])\n",
      "------- in here --------------\n",
      "torch.Size([1, 240000, 2])\n",
      "torch.Size([240000])\n",
      "torch.Size([240000])\n",
      "here now\n",
      "torch.Size([240000])\n",
      " 14%|██████                                      | 6/44 [00:36<03:46,  5.97s/it]['Buitraker - Revo X_0']\n",
      "------- in here --------------\n",
      "torch.Size([1, 240000, 2])\n",
      "torch.Size([240000])\n",
      "torch.Size([240000])\n",
      "------- in here --------------\n",
      "torch.Size([1, 240000, 2])\n",
      "torch.Size([240000])\n",
      "torch.Size([240000])\n",
      "here now\n",
      "torch.Size([240000])\n",
      " 16%|███████                                     | 7/44 [00:42<03:47,  6.15s/it]['Carlos Gonzalez - A Place For Us_0']\n",
      "------- in here --------------\n",
      "torch.Size([1, 240000, 2])\n",
      "torch.Size([240000])\n",
      "torch.Size([240000])\n",
      "------- in here --------------\n",
      "torch.Size([1, 240000, 2])\n",
      "torch.Size([240000])\n",
      "torch.Size([240000])\n",
      "here now\n",
      "torch.Size([240000])\n",
      " 18%|████████                                    | 8/44 [00:48<03:38,  6.07s/it]['Cristina Vane - So Easy_0']\n",
      "------- in here --------------\n",
      "torch.Size([1, 240000, 2])\n",
      "torch.Size([240000])\n",
      "torch.Size([240000])\n",
      "------- in here --------------\n",
      "torch.Size([1, 240000, 2])\n",
      "torch.Size([240000])\n",
      "torch.Size([240000])\n",
      "here now\n",
      "torch.Size([240000])\n",
      " 20%|█████████                                   | 9/44 [00:55<03:37,  6.22s/it]['Detsky Sad - Walkie Talkie_0']\n",
      "------- in here --------------\n",
      "torch.Size([1, 240000, 2])\n",
      "torch.Size([240000])\n",
      "torch.Size([240000])\n",
      "------- in here --------------\n",
      "torch.Size([1, 240000, 2])\n",
      "torch.Size([240000])\n",
      "torch.Size([240000])\n",
      "here now\n",
      "torch.Size([240000])\n",
      "100%|███████████████████████████████████████████| 44/44 [04:31<00:00,  6.17s/it]\n",
      "speechbrain.utils.train_logger - Epoch loaded: 24 - test si-snr: 6.21\n",
      "  0%|                                                    | 0/44 [00:00<?, ?it/s]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      "  2%|█                                           | 1/44 [00:05<04:06,  5.73s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      "  5%|██                                          | 2/44 [00:13<04:59,  7.14s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      "  7%|███                                         | 3/44 [00:22<05:26,  7.97s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      "  9%|████                                        | 4/44 [00:31<05:27,  8.19s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 11%|█████                                       | 5/44 [00:37<04:45,  7.33s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 14%|██████                                      | 6/44 [00:43<04:20,  6.86s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 16%|███████                                     | 7/44 [00:52<04:44,  7.69s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 18%|████████                                    | 8/44 [00:59<04:29,  7.48s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 20%|█████████                                   | 9/44 [01:06<04:14,  7.27s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 23%|█████████▊                                 | 10/44 [01:12<03:52,  6.85s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 25%|██████████▊                                | 11/44 [01:17<03:28,  6.32s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 27%|███████████▋                               | 12/44 [01:25<03:42,  6.94s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 30%|████████████▋                              | 13/44 [01:37<04:19,  8.38s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 32%|█████████████▋                             | 14/44 [01:45<04:05,  8.19s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 34%|██████████████▋                            | 15/44 [01:52<03:45,  7.79s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 36%|███████████████▋                           | 16/44 [02:00<03:43,  7.96s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 39%|████████████████▌                          | 17/44 [02:09<03:41,  8.21s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 41%|█████████████████▌                         | 18/44 [02:15<03:20,  7.72s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 43%|██████████████████▌                        | 19/44 [02:21<02:54,  6.98s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 45%|███████████████████▌                       | 20/44 [02:27<02:47,  6.96s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 48%|████████████████████▌                      | 21/44 [02:34<02:37,  6.87s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 50%|█████████████████████▌                     | 22/44 [02:42<02:39,  7.23s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 52%|██████████████████████▍                    | 23/44 [02:47<02:14,  6.38s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 55%|███████████████████████▍                   | 24/44 [02:49<01:46,  5.34s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 57%|████████████████████████▍                  | 25/44 [02:55<01:42,  5.41s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 59%|█████████████████████████▍                 | 26/44 [03:01<01:38,  5.50s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 61%|██████████████████████████▍                | 27/44 [03:08<01:43,  6.08s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 64%|███████████████████████████▎               | 28/44 [03:18<01:54,  7.18s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 66%|████████████████████████████▎              | 29/44 [03:25<01:45,  7.04s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 68%|█████████████████████████████▎             | 30/44 [03:31<01:37,  6.95s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 70%|██████████████████████████████▎            | 31/44 [03:39<01:33,  7.16s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 73%|███████████████████████████████▎           | 32/44 [03:50<01:40,  8.34s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 75%|████████████████████████████████▎          | 33/44 [03:56<01:24,  7.68s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 77%|█████████████████████████████████▏         | 34/44 [04:04<01:16,  7.66s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 80%|██████████████████████████████████▏        | 35/44 [04:12<01:10,  7.87s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 82%|███████████████████████████████████▏       | 36/44 [04:18<00:58,  7.35s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 84%|████████████████████████████████████▏      | 37/44 [04:25<00:49,  7.04s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 86%|█████████████████████████████████████▏     | 38/44 [04:33<00:43,  7.29s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 89%|██████████████████████████████████████     | 39/44 [04:41<00:38,  7.72s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 91%|███████████████████████████████████████    | 40/44 [04:48<00:30,  7.54s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 93%|████████████████████████████████████████   | 41/44 [04:53<00:20,  6.77s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 95%|█████████████████████████████████████████  | 42/44 [04:59<00:13,  6.51s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      " 98%|██████████████████████████████████████████ | 43/44 [05:05<00:06,  6.16s/it]torch.Size([1, 240000, 2])\n",
      "torch.Size([1, 240000, 2])\n",
      "---------------------\n",
      "torch.Size([1, 240000, 2])\n",
      "/notebooks/demucs-train.py:290: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr, _, _, _ = bss_eval_sources(\n",
      "/notebooks/demucs-train.py:295: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  sdr_baseline, _, _, _ = bss_eval_sources(\n",
      "100%|███████████████████████████████████████████| 44/44 [05:11<00:00,  7.07s/it]\n",
      "__main__ - Mean SISNR is -6.165016992525621\n",
      "__main__ - Mean SISNRi is -0.6643792959776792\n",
      "__main__ - Mean SDR is -15.612485624246649\n",
      "__main__ - Mean SDRi is -50.45734748010503\n"
     ]
    }
   ],
   "source": [
    "!python demucs-train.py demucs-hparams.yaml --data_folder=db_path --result_file_path={result_file_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T16:50:28.840683Z",
     "iopub.status.busy": "2025-04-18T16:50:28.840276Z",
     "iopub.status.idle": "2025-04-18T16:57:01.758361Z",
     "shell.execute_reply": "2025-04-18T16:57:01.756752Z",
     "shell.execute_reply.started": "2025-04-18T16:50:28.840643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: notebooks/results/ (stored 0%)\n",
      "  adding: notebooks/results/sepformer/ (stored 0%)\n",
      "  adding: notebooks/results/sepformer/1234/ (stored 0%)\n",
      "  adding: notebooks/results/sepformer/1234/log.txt (deflated 83%)\n",
      "  adding: notebooks/results/sepformer/1234/test_results.csv (deflated 41%)\n",
      "  adding: notebooks/results/sepformer/1234/sepformer-train.py (deflated 73%)\n",
      "  adding: notebooks/results/sepformer/1234/train_log.txt (deflated 82%)\n",
      "  adding: notebooks/results/sepformer/1234/env.log (deflated 52%)\n",
      "  adding: notebooks/results/sepformer/1234/.ipynb_checkpoints/ (stored 0%)\n",
      "  adding: notebooks/results/sepformer/1234/.ipynb_checkpoints/test_results-checkpoint.csv (deflated 41%)\n",
      "  adding: notebooks/results/sepformer/1234/.ipynb_checkpoints/train_log-checkpoint.txt (deflated 82%)\n",
      "  adding: notebooks/results/sepformer/1234/save/ (stored 0%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/ (stored 0%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemBuitraker - Revo X_0_source1hat.wav (deflated 20%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemCristina Vane - So Easy_0_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemBobby Nobody - Stitch Up_0_source2hat.wav (deflated 22%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemCristina Vane - So Easy_0_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemBKS - Bulldozer_0_source2.wav (deflated 18%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemAM Contra - Heart Peripheral_0_mix.wav (deflated 13%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemBobby Nobody - Stitch Up_0_mix.wav (deflated 22%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemBKS - Bulldozer_0_source1hat.wav (deflated 27%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemBuitraker - Revo X_0_source2hat.wav (deflated 15%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemDetsky Sad - Walkie Talkie_0_source2.wav (deflated 10%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemDetsky Sad - Walkie Talkie_0_source2hat.wav (deflated 14%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemBKS - Bulldozer_0_source1.wav (deflated 90%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemCarlos Gonzalez - A Place For Us_0_source1.wav (deflated 15%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemCarlos Gonzalez - A Place For Us_0_source2.wav (deflated 10%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemAM Contra - Heart Peripheral_0_source1.wav (deflated 55%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemBuitraker - Revo X_0_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemBKS - Too Much_0_mix.wav (deflated 6%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemCristina Vane - So Easy_0_source2.wav (deflated 16%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemAl James - Schoolboy Facination_0_mix.wav (deflated 11%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemDetsky Sad - Walkie Talkie_0_mix.wav (deflated 10%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemBKS - Too Much_0_source1hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemBKS - Too Much_0_source2hat.wav (deflated 7%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemBobby Nobody - Stitch Up_0_source1hat.wav (deflated 32%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemDetsky Sad - Walkie Talkie_0_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemDetsky Sad - Walkie Talkie_0_source1hat.wav (deflated 12%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemBobby Nobody - Stitch Up_0_source2.wav (deflated 22%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemArise - Run Run Run_0_mix.wav (deflated 5%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemBKS - Bulldozer_0_mix.wav (deflated 18%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemArise - Run Run Run_0_source2.wav (deflated 5%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemBuitraker - Revo X_0_source2.wav (deflated 14%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemCristina Vane - So Easy_0_mix.wav (deflated 16%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemCarlos Gonzalez - A Place For Us_0_source2hat.wav (deflated 10%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemArise - Run Run Run_0_source1.wav (deflated 22%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemAl James - Schoolboy Facination_0_source1hat.wav (deflated 12%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemBuitraker - Revo X_0_mix.wav (deflated 14%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemAl James - Schoolboy Facination_0_source2hat.wav (deflated 14%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemCarlos Gonzalez - A Place For Us_0_mix.wav (deflated 9%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemCristina Vane - So Easy_0_source1hat.wav (deflated 21%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemAM Contra - Heart Peripheral_0_source2hat.wav (deflated 14%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemBobby Nobody - Stitch Up_0_source1.wav (deflated 78%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemBKS - Too Much_0_source1.wav (deflated 71%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemAM Contra - Heart Peripheral_0_source1hat.wav (deflated 27%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemBKS - Bulldozer_0_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemCarlos Gonzalez - A Place For Us_0_source1hat.wav (deflated 14%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemBKS - Too Much_0_source2.wav (deflated 6%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemArise - Run Run Run_0_source1hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemAl James - Schoolboy Facination_0_source2.wav (deflated 12%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemAl James - Schoolboy Facination_0_source1.wav (deflated 28%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemArise - Run Run Run_0_source2hat.wav (deflated 6%)\n",
      "  adding: notebooks/results/sepformer/1234/save/audio_results/itemAM Contra - Heart Peripheral_0_source2.wav (deflated 13%)\n",
      "  adding: notebooks/results/sepformer/1234/save/CKPT+2025-04-18+06-18-25+00/ (stored 0%)\n",
      "  adding: notebooks/results/sepformer/1234/save/CKPT+2025-04-18+06-18-25+00/CKPT.yaml (deflated 5%)\n",
      "  adding: notebooks/results/sepformer/1234/save/CKPT+2025-04-18+06-18-25+00/decoder.ckpt (deflated 11%)\n",
      "  adding: notebooks/results/sepformer/1234/save/CKPT+2025-04-18+06-18-25+00/masknet.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/sepformer/1234/save/CKPT+2025-04-18+06-18-25+00/optimizer.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/sepformer/1234/save/CKPT+2025-04-18+06-18-25+00/encoder.ckpt (deflated 11%)\n",
      "  adding: notebooks/results/sepformer/1234/save/CKPT+2025-04-18+06-18-25+00/brain.ckpt (deflated 13%)\n",
      "  adding: notebooks/results/sepformer/1234/save/CKPT+2025-04-18+06-18-25+00/counter.ckpt (stored 0%)\n",
      "  adding: notebooks/results/sepformer/1234/save/CKPT+2025-04-18+06-18-25+00/scaler.ckpt (deflated 60%)\n",
      "  adding: notebooks/results/sepformer/1234/save/CKPT+2025-04-18+06-18-25+00/lr_scheduler.ckpt (deflated 49%)\n",
      "  adding: notebooks/results/sepformer/1234/save/CKPT+2025-04-18+05-09-21+00/ (stored 0%)\n",
      "  adding: notebooks/results/sepformer/1234/save/CKPT+2025-04-18+05-09-21+00/CKPT.yaml (deflated 5%)\n",
      "  adding: notebooks/results/sepformer/1234/save/CKPT+2025-04-18+05-09-21+00/decoder.ckpt (deflated 11%)\n",
      "  adding: notebooks/results/sepformer/1234/save/CKPT+2025-04-18+05-09-21+00/masknet.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/sepformer/1234/save/CKPT+2025-04-18+05-09-21+00/optimizer.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/sepformer/1234/save/CKPT+2025-04-18+05-09-21+00/encoder.ckpt (deflated 11%)\n",
      "  adding: notebooks/results/sepformer/1234/save/CKPT+2025-04-18+05-09-21+00/brain.ckpt (deflated 13%)\n",
      "  adding: notebooks/results/sepformer/1234/save/CKPT+2025-04-18+05-09-21+00/counter.ckpt (stored 0%)\n",
      "  adding: notebooks/results/sepformer/1234/save/CKPT+2025-04-18+05-09-21+00/scaler.ckpt (deflated 60%)\n",
      "  adding: notebooks/results/sepformer/1234/save/CKPT+2025-04-18+05-09-21+00/lr_scheduler.ckpt (deflated 50%)\n",
      "  adding: notebooks/results/sepformer/1234/hyperparams.yaml (deflated 62%)\n",
      "  adding: notebooks/results/convtasnet/ (stored 0%)\n",
      "  adding: notebooks/results/convtasnet/1234/ (stored 0%)\n",
      "  adding: notebooks/results/convtasnet/1234/log.txt (deflated 91%)\n",
      "  adding: notebooks/results/convtasnet/1234/test_results.csv (deflated 41%)\n",
      "  adding: notebooks/results/convtasnet/1234/train_log.txt (deflated 84%)\n",
      "  adding: notebooks/results/convtasnet/1234/env.log (deflated 52%)\n",
      "  adding: notebooks/results/convtasnet/1234/.ipynb_checkpoints/ (stored 0%)\n",
      "  adding: notebooks/results/convtasnet/1234/.ipynb_checkpoints/test_results-checkpoint.csv (deflated 41%)\n",
      "  adding: notebooks/results/convtasnet/1234/.ipynb_checkpoints/train_log-checkpoint.txt (deflated 83%)\n",
      "  adding: notebooks/results/convtasnet/1234/.ipynb_checkpoints/convtasnet-train-checkpoint.py (deflated 73%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/ (stored 0%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/CKPT+2025-04-17+11-37-49+00/ (stored 0%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/CKPT+2025-04-17+11-37-49+00/CKPT.yaml (deflated 4%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/CKPT+2025-04-17+11-37-49+00/decoder.ckpt (deflated 10%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/CKPT+2025-04-17+11-37-49+00/masknet.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/CKPT+2025-04-17+11-37-49+00/optimizer.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/CKPT+2025-04-17+11-37-49+00/encoder.ckpt (deflated 11%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/CKPT+2025-04-17+11-37-49+00/brain.ckpt (deflated 13%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/CKPT+2025-04-17+11-37-49+00/counter.ckpt (stored 0%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/CKPT+2025-04-17+11-37-49+00/scaler.ckpt (deflated 60%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/CKPT+2025-04-17+11-37-49+00/lr_scheduler.ckpt (deflated 50%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/ (stored 0%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemBuitraker - Revo X_0_source1hat.wav (deflated 23%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemCristina Vane - So Easy_0_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemBobby Nobody - Stitch Up_0_source2hat.wav (deflated 37%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemCristina Vane - So Easy_0_source2hat.wav (deflated 33%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemBKS - Bulldozer_0_source2.wav (deflated 23%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemAM Contra - Heart Peripheral_0_mix.wav (deflated 18%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemBobby Nobody - Stitch Up_0_mix.wav (deflated 29%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemBKS - Bulldozer_0_source1hat.wav (deflated 23%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemBuitraker - Revo X_0_source2hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemDetsky Sad - Walkie Talkie_0_source2.wav (deflated 7%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemDetsky Sad - Walkie Talkie_0_source2hat.wav (deflated 13%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemBKS - Bulldozer_0_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemCarlos Gonzalez - A Place For Us_0_source1.wav (deflated 17%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemCarlos Gonzalez - A Place For Us_0_source2.wav (deflated 9%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemAM Contra - Heart Peripheral_0_source1.wav (deflated 69%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemBuitraker - Revo X_0_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemBKS - Too Much_0_mix.wav (deflated 6%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemCristina Vane - So Easy_0_source2.wav (deflated 21%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemAl James - Schoolboy Facination_0_mix.wav (deflated 13%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemDetsky Sad - Walkie Talkie_0_mix.wav (deflated 7%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemBKS - Too Much_0_source1hat.wav (deflated 8%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemBKS - Too Much_0_source2hat.wav (deflated 13%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemBobby Nobody - Stitch Up_0_source1hat.wav (deflated 30%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemDetsky Sad - Walkie Talkie_0_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemDetsky Sad - Walkie Talkie_0_source1hat.wav (deflated 10%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemBobby Nobody - Stitch Up_0_source2.wav (deflated 29%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemArise - Run Run Run_0_mix.wav (deflated 6%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemBKS - Bulldozer_0_mix.wav (deflated 23%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemArise - Run Run Run_0_source2.wav (deflated 6%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemBuitraker - Revo X_0_source2.wav (deflated 18%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemCristina Vane - So Easy_0_mix.wav (deflated 21%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemCarlos Gonzalez - A Place For Us_0_source2hat.wav (deflated 19%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemArise - Run Run Run_0_source1.wav (deflated 30%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemAl James - Schoolboy Facination_0_source1hat.wav (deflated 13%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemBuitraker - Revo X_0_mix.wav (deflated 18%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemAl James - Schoolboy Facination_0_source2hat.wav (deflated 20%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemCarlos Gonzalez - A Place For Us_0_mix.wav (deflated 10%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemCristina Vane - So Easy_0_source1hat.wav (deflated 22%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemAM Contra - Heart Peripheral_0_source2hat.wav (deflated 34%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemBobby Nobody - Stitch Up_0_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemBKS - Too Much_0_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemAM Contra - Heart Peripheral_0_source1hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemBKS - Bulldozer_0_source2hat.wav (deflated 33%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemCarlos Gonzalez - A Place For Us_0_source1hat.wav (deflated 11%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemBKS - Too Much_0_source2.wav (deflated 6%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemArise - Run Run Run_0_source1hat.wav (deflated 6%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemAl James - Schoolboy Facination_0_source2.wav (deflated 14%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemAl James - Schoolboy Facination_0_source1.wav (deflated 33%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemArise - Run Run Run_0_source2hat.wav (deflated 28%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/audio_results/itemAM Contra - Heart Peripheral_0_source2.wav (deflated 18%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/CKPT+2025-04-17+11-14-02+00/ (stored 0%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/CKPT+2025-04-17+11-14-02+00/CKPT.yaml (deflated 4%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/CKPT+2025-04-17+11-14-02+00/decoder.ckpt (deflated 10%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/CKPT+2025-04-17+11-14-02+00/masknet.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/CKPT+2025-04-17+11-14-02+00/optimizer.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/CKPT+2025-04-17+11-14-02+00/encoder.ckpt (deflated 11%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/CKPT+2025-04-17+11-14-02+00/brain.ckpt (deflated 13%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/CKPT+2025-04-17+11-14-02+00/counter.ckpt (stored 0%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/CKPT+2025-04-17+11-14-02+00/scaler.ckpt (deflated 60%)\n",
      "  adding: notebooks/results/convtasnet/1234/save/CKPT+2025-04-17+11-14-02+00/lr_scheduler.ckpt (deflated 50%)\n",
      "  adding: notebooks/results/convtasnet/1234/hyperparams.yaml (deflated 59%)\n",
      "  adding: notebooks/results/convtasnet/1234/convtasnet-train.py (deflated 74%)\n",
      "  adding: notebooks/results/dprnn/ (stored 0%)\n",
      "  adding: notebooks/results/dprnn/1234/ (stored 0%)\n",
      "  adding: notebooks/results/dprnn/1234/log.txt (deflated 82%)\n",
      "  adding: notebooks/results/dprnn/1234/test_results.csv (deflated 41%)\n",
      "  adding: notebooks/results/dprnn/1234/dprnn-train.py (deflated 73%)\n",
      "  adding: notebooks/results/dprnn/1234/train_log.txt (deflated 82%)\n",
      "  adding: notebooks/results/dprnn/1234/env.log (deflated 52%)\n",
      "  adding: notebooks/results/dprnn/1234/.ipynb_checkpoints/ (stored 0%)\n",
      "  adding: notebooks/results/dprnn/1234/.ipynb_checkpoints/test_results-checkpoint.csv (deflated 41%)\n",
      "  adding: notebooks/results/dprnn/1234/.ipynb_checkpoints/train_log-checkpoint.txt (deflated 83%)\n",
      "  adding: notebooks/results/dprnn/1234/save/ (stored 0%)\n",
      "  adding: notebooks/results/dprnn/1234/save/CKPT+2025-04-17+15-52-56+00/ (stored 0%)\n",
      "  adding: notebooks/results/dprnn/1234/save/CKPT+2025-04-17+15-52-56+00/CKPT.yaml (deflated 5%)\n",
      "  adding: notebooks/results/dprnn/1234/save/CKPT+2025-04-17+15-52-56+00/decoder.ckpt (deflated 10%)\n",
      "  adding: notebooks/results/dprnn/1234/save/CKPT+2025-04-17+15-52-56+00/masknet.ckpt (deflated 7%)\n",
      "  adding: notebooks/results/dprnn/1234/save/CKPT+2025-04-17+15-52-56+00/optimizer.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/dprnn/1234/save/CKPT+2025-04-17+15-52-56+00/encoder.ckpt (deflated 11%)\n",
      "  adding: notebooks/results/dprnn/1234/save/CKPT+2025-04-17+15-52-56+00/brain.ckpt (deflated 13%)\n",
      "  adding: notebooks/results/dprnn/1234/save/CKPT+2025-04-17+15-52-56+00/counter.ckpt (stored 0%)\n",
      "  adding: notebooks/results/dprnn/1234/save/CKPT+2025-04-17+15-52-56+00/scaler.ckpt (deflated 60%)\n",
      "  adding: notebooks/results/dprnn/1234/save/CKPT+2025-04-17+15-52-56+00/lr_scheduler.ckpt (deflated 52%)\n",
      "  adding: notebooks/results/dprnn/1234/save/CKPT+2025-04-18+00-10-38+00/ (stored 0%)\n",
      "  adding: notebooks/results/dprnn/1234/save/CKPT+2025-04-18+00-10-38+00/CKPT.yaml (deflated 3%)\n",
      "  adding: notebooks/results/dprnn/1234/save/CKPT+2025-04-18+00-10-38+00/decoder.ckpt (deflated 10%)\n",
      "  adding: notebooks/results/dprnn/1234/save/CKPT+2025-04-18+00-10-38+00/masknet.ckpt (deflated 7%)\n",
      "  adding: notebooks/results/dprnn/1234/save/CKPT+2025-04-18+00-10-38+00/optimizer.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/dprnn/1234/save/CKPT+2025-04-18+00-10-38+00/encoder.ckpt (deflated 10%)\n",
      "  adding: notebooks/results/dprnn/1234/save/CKPT+2025-04-18+00-10-38+00/brain.ckpt (deflated 13%)\n",
      "  adding: notebooks/results/dprnn/1234/save/CKPT+2025-04-18+00-10-38+00/counter.ckpt (stored 0%)\n",
      "  adding: notebooks/results/dprnn/1234/save/CKPT+2025-04-18+00-10-38+00/scaler.ckpt (deflated 60%)\n",
      "  adding: notebooks/results/dprnn/1234/save/CKPT+2025-04-18+00-10-38+00/lr_scheduler.ckpt (deflated 50%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/ (stored 0%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemBuitraker - Revo X_0_source1hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemCristina Vane - So Easy_0_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemBobby Nobody - Stitch Up_0_source2hat.wav (deflated 35%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemCristina Vane - So Easy_0_source2hat.wav (deflated 35%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemBKS - Bulldozer_0_source2.wav (deflated 23%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemAM Contra - Heart Peripheral_0_mix.wav (deflated 18%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemBobby Nobody - Stitch Up_0_mix.wav (deflated 29%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemBKS - Bulldozer_0_source1hat.wav (deflated 23%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemBuitraker - Revo X_0_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemDetsky Sad - Walkie Talkie_0_source2.wav (deflated 7%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemDetsky Sad - Walkie Talkie_0_source2hat.wav (deflated 10%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemBKS - Bulldozer_0_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemCarlos Gonzalez - A Place For Us_0_source1.wav (deflated 17%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemCarlos Gonzalez - A Place For Us_0_source2.wav (deflated 9%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemAM Contra - Heart Peripheral_0_source1.wav (deflated 69%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemBuitraker - Revo X_0_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemBKS - Too Much_0_mix.wav (deflated 6%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemCristina Vane - So Easy_0_source2.wav (deflated 21%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemAl James - Schoolboy Facination_0_mix.wav (deflated 13%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemDetsky Sad - Walkie Talkie_0_mix.wav (deflated 7%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemBKS - Too Much_0_source1hat.wav (deflated 6%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemBKS - Too Much_0_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemBobby Nobody - Stitch Up_0_source1hat.wav (deflated 29%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemDetsky Sad - Walkie Talkie_0_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemDetsky Sad - Walkie Talkie_0_source1hat.wav (deflated 8%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemBobby Nobody - Stitch Up_0_source2.wav (deflated 29%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemArise - Run Run Run_0_mix.wav (deflated 6%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemBKS - Bulldozer_0_mix.wav (deflated 23%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemArise - Run Run Run_0_source2.wav (deflated 6%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemBuitraker - Revo X_0_source2.wav (deflated 18%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemCristina Vane - So Easy_0_mix.wav (deflated 21%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemCarlos Gonzalez - A Place For Us_0_source2hat.wav (deflated 15%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemArise - Run Run Run_0_source1.wav (deflated 30%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemAl James - Schoolboy Facination_0_source1hat.wav (deflated 13%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemBuitraker - Revo X_0_mix.wav (deflated 18%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemAl James - Schoolboy Facination_0_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemCarlos Gonzalez - A Place For Us_0_mix.wav (deflated 10%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemCristina Vane - So Easy_0_source1hat.wav (deflated 21%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemAM Contra - Heart Peripheral_0_source2hat.wav (deflated 38%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemBobby Nobody - Stitch Up_0_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemBKS - Too Much_0_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemAM Contra - Heart Peripheral_0_source1hat.wav (deflated 18%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemBKS - Bulldozer_0_source2hat.wav (deflated 27%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemCarlos Gonzalez - A Place For Us_0_source1hat.wav (deflated 12%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemBKS - Too Much_0_source2.wav (deflated 6%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemArise - Run Run Run_0_source1hat.wav (deflated 6%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemAl James - Schoolboy Facination_0_source2.wav (deflated 14%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemAl James - Schoolboy Facination_0_source1.wav (deflated 33%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemArise - Run Run Run_0_source2hat.wav (deflated 23%)\n",
      "  adding: notebooks/results/dprnn/1234/save/audio_results/itemAM Contra - Heart Peripheral_0_source2.wav (deflated 18%)\n",
      "  adding: notebooks/results/dprnn/1234/hyperparams.yaml (deflated 61%)\n",
      "  adding: notebooks/results/.ipynb_checkpoints/ (stored 0%)\n",
      "  adding: notebooks/results/demucs/ (stored 0%)\n",
      "  adding: notebooks/results/demucs/1234/ (stored 0%)\n",
      "  adding: notebooks/results/demucs/1234/log.txt (deflated 89%)\n",
      "  adding: notebooks/results/demucs/1234/test_results.csv (deflated 42%)\n",
      "  adding: notebooks/results/demucs/1234/train_log.txt (deflated 82%)\n",
      "  adding: notebooks/results/demucs/1234/demucs-train.py (deflated 74%)\n",
      "  adding: notebooks/results/demucs/1234/env.log (deflated 52%)\n",
      "  adding: notebooks/results/demucs/1234/.ipynb_checkpoints/ (stored 0%)\n",
      "  adding: notebooks/results/demucs/1234/.ipynb_checkpoints/test_results-checkpoint.csv (deflated 42%)\n",
      "  adding: notebooks/results/demucs/1234/.ipynb_checkpoints/train_log-checkpoint.txt (deflated 82%)\n",
      "  adding: notebooks/results/demucs/1234/save/ (stored 0%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-18-57+00/ (stored 0%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-18-57+00/CKPT.yaml (deflated 5%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-18-57+00/encoder2.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-18-57+00/encoder4.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-18-57+00/encoder6.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-18-57+00/decoder3.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-18-57+00/optimizer.ckpt (deflated 27%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-18-57+00/decoder5.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-18-57+00/encoder3.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-18-57+00/decoder2.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-18-57+00/lstm.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-18-57+00/encoder5.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-18-57+00/linearSeparator.ckpt (deflated 58%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-18-57+00/decoder1.ckpt (deflated 10%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-18-57+00/brain.ckpt (deflated 13%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-18-57+00/decoder6.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-18-57+00/counter.ckpt (stored 0%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-18-57+00/linear.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-18-57+00/decoder4.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-18-57+00/encoder1.ckpt (deflated 10%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/ (stored 0%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Arise - Run Run Run_0']_mix.wav (deflated 5%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['AM Contra - Heart Peripheral_0']_source1.wav (deflated 55%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['AM Contra - Heart Peripheral_0']_source2hat.wav (deflated 28%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Buitraker - Revo X_0']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Carlos Gonzalez - A Place For Us_0']_source1.wav (deflated 15%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['AM Contra - Heart Peripheral_0']_mix.wav (deflated 13%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Al James - Schoolboy Facination_0']_source1hat.wav (deflated 23%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Cristina Vane - So Easy_0']_source2hat.wav (deflated 29%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Al James - Schoolboy Facination_0']_source1.wav (deflated 28%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Al James - Schoolboy Facination_0']_mix.wav (deflated 11%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['BKS - Bulldozer_0']_source2.wav (deflated 18%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Arise - Run Run Run_0']_source1.wav (deflated 22%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Carlos Gonzalez - A Place For Us_0']_source1hat.wav (deflated 30%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Bobby Nobody - Stitch Up_0']_source2hat.wav (deflated 34%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['BKS - Too Much_0']_source1.wav (deflated 71%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Detsky Sad - Walkie Talkie_0']_mix.wav (deflated 10%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['BKS - Too Much_0']_source1hat.wav (deflated 22%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Carlos Gonzalez - A Place For Us_0']_source2.wav (deflated 10%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['BKS - Too Much_0']_source2.wav (deflated 6%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Buitraker - Revo X_0']_mix.wav (deflated 14%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['BKS - Bulldozer_0']_source2hat.wav (deflated 31%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Arise - Run Run Run_0']_source1hat.wav (deflated 20%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Cristina Vane - So Easy_0']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['BKS - Bulldozer_0']_mix.wav (deflated 18%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Buitraker - Revo X_0']_source1hat.wav (deflated 29%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Bobby Nobody - Stitch Up_0']_source2.wav (deflated 22%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Cristina Vane - So Easy_0']_source2.wav (deflated 16%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Buitraker - Revo X_0']_source2hat.wav (deflated 29%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Arise - Run Run Run_0']_source2hat.wav (deflated 17%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Buitraker - Revo X_0']_source2.wav (deflated 14%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Detsky Sad - Walkie Talkie_0']_source1.wav (deflated 100%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Carlos Gonzalez - A Place For Us_0']_mix.wav (deflated 9%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Arise - Run Run Run_0']_source2.wav (deflated 5%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['BKS - Too Much_0']_source2hat.wav (deflated 21%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['AM Contra - Heart Peripheral_0']_source2.wav (deflated 13%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Cristina Vane - So Easy_0']_source1hat.wav (deflated 30%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Detsky Sad - Walkie Talkie_0']_source2.wav (deflated 10%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['BKS - Bulldozer_0']_source1.wav (deflated 90%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Al James - Schoolboy Facination_0']_source2.wav (deflated 12%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Bobby Nobody - Stitch Up_0']_source1.wav (deflated 78%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Al James - Schoolboy Facination_0']_source2hat.wav (deflated 23%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Detsky Sad - Walkie Talkie_0']_source2hat.wav (deflated 23%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Bobby Nobody - Stitch Up_0']_source1hat.wav (deflated 35%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Bobby Nobody - Stitch Up_0']_mix.wav (deflated 22%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Cristina Vane - So Easy_0']_mix.wav (deflated 16%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Detsky Sad - Walkie Talkie_0']_source1hat.wav (deflated 23%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['BKS - Too Much_0']_mix.wav (deflated 6%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['AM Contra - Heart Peripheral_0']_source1hat.wav (deflated 30%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['Carlos Gonzalez - A Place For Us_0']_source2hat.wav (deflated 31%)\n",
      "  adding: notebooks/results/demucs/1234/save/audio_results/item['BKS - Bulldozer_0']_source1hat.wav (deflated 31%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-38-53+00/ (stored 0%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-38-53+00/CKPT.yaml (deflated 5%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-38-53+00/encoder2.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-38-53+00/encoder4.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-38-53+00/encoder6.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-38-53+00/decoder3.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-38-53+00/optimizer.ckpt (deflated 31%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-38-53+00/decoder5.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-38-53+00/encoder3.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-38-53+00/decoder2.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-38-53+00/lstm.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-38-53+00/encoder5.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-38-53+00/linearSeparator.ckpt (deflated 58%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-38-53+00/decoder1.ckpt (deflated 10%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-38-53+00/brain.ckpt (deflated 13%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-38-53+00/decoder6.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-38-53+00/counter.ckpt (stored 0%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-38-53+00/linear.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-38-53+00/decoder4.ckpt (deflated 8%)\n",
      "  adding: notebooks/results/demucs/1234/save/CKPT+2025-04-18+14-38-53+00/encoder1.ckpt (deflated 10%)\n",
      "  adding: notebooks/results/demucs/1234/hyperparams.yaml (deflated 68%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r results_30e_checkpoints.zip /notebooks/results/"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6159348,
     "sourceId": 10005918,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
